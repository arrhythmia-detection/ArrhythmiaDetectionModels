{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.005439Z",
     "start_time": "2025-01-08T15:04:51.239664Z"
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Diagnostics.xlsx data\n",
    "diagnostics_file = \"../../../../Datasets/12-lead electrocardiogram database/Diagnostics.xlsx\"\n",
    "diagnostics_df = pd.read_excel(diagnostics_file)\n",
    "\n",
    "# Rename \"SA\" to \"SI\" in the \"Rhythm\" column\n",
    "diagnostics_df[\"Rhythm\"] = diagnostics_df[\"Rhythm\"].replace(\"SA\", \"SI\")\n",
    "\n",
    "# Drop rows with any missing values\n",
    "diagnostics_df = diagnostics_df.dropna()\n",
    "\n",
    "# Encode \"Gender\" column: 0 for \"MALE\" and 1 for \"FEMALE\"\n",
    "diagnostics_df[\"Gender\"] = diagnostics_df[\"Gender\"].map({\"MALE\": 0, \"FEMALE\": 1})\n",
    "\n",
    "# Merge specified labels\n",
    "merge_mapping = {\n",
    "    \"AF\": \"AFIB\", \"AFIB\": \"AFIB\",\n",
    "    \"SVT\": \"GSVT\", \"AT\": \"GSVT\", \"SAAWR\": \"GSVT\", \"ST\": \"GSVT\", \"AVNRT\": \"GSVT\", \"AVRT\": \"GSVT\",\n",
    "    \"SB\": \"SB\",\n",
    "    \"SR\": \"SR\", \"SI\": \"SR\"\n",
    "}\n",
    "diagnostics_df[\"Rhythm\"] = diagnostics_df[\"Rhythm\"].map(merge_mapping)\n",
    "\n",
    "# Separate features and labels\n",
    "features = diagnostics_df.drop(columns=[\"FileName\", \"Rhythm\", \"Beat\"]).values\n",
    "labels = diagnostics_df[\"Rhythm\"].values  # Using \"Rhythm\" as the target variable\n",
    "\n",
    "# Convert features to float32\n",
    "features = features.astype(\"float32\")\n",
    "\n",
    "# Encode labels as one-hot with merged classes\n",
    "unique_labels = np.unique(labels)\n",
    "label_map = {label: index for index, label in enumerate(unique_labels)}\n",
    "labels_encoded = np.array([label_map[label] for label in labels])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save X_test to a file\n",
    "np.savetxt(\"X_test.txt\", X_test, fmt='%f', delimiter=' ')\n",
    "\n",
    "# Save y_test to a separate file\n",
    "np.savetxt(\"y_test.txt\", y_test, fmt='%d')  # Use '%d' if y_test contains integers"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.022420Z",
     "start_time": "2025-01-08T15:04:53.019779Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_test[1])",
   "id": "c515d459fd66a3cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 68.   0.  67. 250.  76. 482. 509.  75.  82.  11. 219. 257. 460.]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.181636Z",
     "start_time": "2025-01-08T15:04:53.082032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))"
   ],
   "id": "61a4ead506f4fd5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79352   0.81328   0.80328       482\n",
      "          SB    0.97823   0.98327   0.98074       777\n",
      "          SR    0.88009   0.87025   0.87514       447\n",
      "\n",
      "    accuracy                        0.85915      2130\n",
      "   macro avg    0.83548   0.83474   0.83504      2130\n",
      "weighted avg    0.85848   0.85915   0.85876      2130\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.201625Z",
     "start_time": "2025-01-08T15:04:53.199240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "a94d4057c2fb42da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "689\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.294485Z",
     "start_time": "2025-01-08T15:04:53.242018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "4802071b9e8a4a38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.68916   0.67453   0.68176       424\n",
      "        GSVT    0.80285   0.81950   0.81109       482\n",
      "          SB    0.97695   0.98198   0.97946       777\n",
      "          SR    0.87783   0.86801   0.87289       447\n",
      "\n",
      "    accuracy                        0.86009      2130\n",
      "   macro avg    0.83670   0.83601   0.83630      2130\n",
      "weighted avg    0.85946   0.86009   0.85974      2130\n",
      "\n",
      "24\n",
      "684\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.363355Z",
     "start_time": "2025-01-08T15:04:53.311603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "e91a85e497a616ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.68916   0.67453   0.68176       424\n",
      "        GSVT    0.80285   0.81950   0.81109       482\n",
      "          SB    0.97695   0.98198   0.97946       777\n",
      "          SR    0.87783   0.86801   0.87289       447\n",
      "\n",
      "    accuracy                        0.86009      2130\n",
      "   macro avg    0.83670   0.83601   0.83630      2130\n",
      "weighted avg    0.85946   0.86009   0.85974      2130\n",
      "\n",
      "24\n",
      "684\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.502140Z",
     "start_time": "2025-01-08T15:04:53.455293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "ca60df3365fc055c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69668   0.69340   0.69504       424\n",
      "        GSVT    0.81481   0.82158   0.81818       482\n",
      "          SB    0.97698   0.98327   0.98012       777\n",
      "          SR    0.88636   0.87248   0.87937       447\n",
      "\n",
      "    accuracy                        0.86573      2130\n",
      "   macro avg    0.84371   0.84268   0.84318      2130\n",
      "weighted avg    0.86547   0.86573   0.86558      2130\n",
      "\n",
      "24\n",
      "600\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.611177Z",
     "start_time": "2025-01-08T15:04:53.560248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "4681bff9f38fd52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72236   0.69340   0.70758       424\n",
      "        GSVT    0.82136   0.82988   0.82559       482\n",
      "          SB    0.97832   0.98713   0.98270       777\n",
      "          SR    0.88938   0.89933   0.89433       447\n",
      "\n",
      "    accuracy                        0.87465      2130\n",
      "   macro avg    0.85285   0.85243   0.85255      2130\n",
      "weighted avg    0.87318   0.87465   0.87384      2130\n",
      "\n",
      "23\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.739911Z",
     "start_time": "2025-01-08T15:04:53.702735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "2161589aa5a1fd4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73012   0.71462   0.72229       424\n",
      "        GSVT    0.84906   0.84025   0.84463       482\n",
      "          SB    0.97821   0.98198   0.98009       777\n",
      "          SR    0.89083   0.91275   0.90166       447\n",
      "\n",
      "    accuracy                        0.88216      2130\n",
      "   macro avg    0.86205   0.86240   0.86217      2130\n",
      "weighted avg    0.88126   0.88216   0.88166      2130\n",
      "\n",
      "20\n",
      "200\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.805491Z",
     "start_time": "2025-01-08T15:04:53.753715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "9bb2b2511246651d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79878   0.81535   0.80698       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.88435   0.87248   0.87838       447\n",
      "\n",
      "    accuracy                        0.86056      2130\n",
      "   macro avg    0.83724   0.83614   0.83663      2130\n",
      "weighted avg    0.85966   0.86056   0.86005      2130\n",
      "\n",
      "20\n",
      "654\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.873934Z",
     "start_time": "2025-01-08T15:04:53.822454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n"
   ],
   "id": "1741a758262bdf26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79878   0.81535   0.80698       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.88435   0.87248   0.87838       447\n",
      "\n",
      "    accuracy                        0.86056      2130\n",
      "   macro avg    0.83724   0.83614   0.83663      2130\n",
      "weighted avg    0.85966   0.86056   0.86005      2130\n",
      "\n",
      "20\n",
      "654\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.931697Z",
     "start_time": "2025-01-08T15:04:53.879758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "696991a524d3d5e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79878   0.81535   0.80698       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.88435   0.87248   0.87838       447\n",
      "\n",
      "    accuracy                        0.86056      2130\n",
      "   macro avg    0.83724   0.83614   0.83663      2130\n",
      "weighted avg    0.85966   0.86056   0.86005      2130\n",
      "\n",
      "20\n",
      "654\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:53.987429Z",
     "start_time": "2025-01-08T15:04:53.940131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n"
   ],
   "id": "6f3c57911f403807",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80041   0.81535   0.80781       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.89066   0.87472   0.88262       447\n",
      "\n",
      "    accuracy                        0.86244      2130\n",
      "   macro avg    0.83979   0.83847   0.83907      2130\n",
      "weighted avg    0.86180   0.86244   0.86207      2130\n",
      "\n",
      "20\n",
      "600\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:54.036557Z",
     "start_time": "2025-01-08T15:04:53.995366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "32b49e1c81ca4e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.71776   0.69575   0.70659       424\n",
      "        GSVT    0.82062   0.82573   0.82316       482\n",
      "          SB    0.97832   0.98713   0.98270       777\n",
      "          SR    0.89333   0.89933   0.89632       447\n",
      "\n",
      "    accuracy                        0.87418      2130\n",
      "   macro avg    0.85251   0.85198   0.85219      2130\n",
      "weighted avg    0.87293   0.87418   0.87351      2130\n",
      "\n",
      "20\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:54.287254Z",
     "start_time": "2025-01-08T15:04:54.051613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "7565f26f75b40bf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "617\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "617\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "617\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "600\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.71566   0.70047   0.70799       424\n",
      "        GSVT    0.81875   0.81535   0.81705       482\n",
      "          SB    0.97957   0.98713   0.98333       777\n",
      "          SR    0.88938   0.89933   0.89433       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.85084   0.85057   0.85067      2130\n",
      "weighted avg    0.87172   0.87277   0.87221      2130\n",
      "\n",
      "18\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:54.537627Z",
     "start_time": "2025-01-08T15:04:54.302479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "7c9d16908dd09a60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72222   0.70519   0.71360       424\n",
      "        GSVT    0.82947   0.81743   0.82341       482\n",
      "          SB    0.97954   0.98584   0.98268       777\n",
      "          SR    0.89325   0.91723   0.90508       447\n",
      "\n",
      "    accuracy                        0.87746      2130\n",
      "   macro avg    0.85612   0.85642   0.85619      2130\n",
      "weighted avg    0.87625   0.87746   0.87679      2130\n",
      "\n",
      "16\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:54.814875Z",
     "start_time": "2025-01-08T15:04:54.590307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "b15849f97c68e638",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73183   0.68868   0.70960       424\n",
      "        GSVT    0.82672   0.82158   0.82414       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.88841   0.92617   0.90690       447\n",
      "\n",
      "    accuracy                        0.87700      2130\n",
      "   macro avg    0.85538   0.85557   0.85520      2130\n",
      "weighted avg    0.87471   0.87700   0.87562      2130\n",
      "\n",
      "14\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:55.134482Z",
     "start_time": "2025-01-08T15:04:54.829306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=100)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=50)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "1806803ac0a5786a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73711   0.67453   0.70443       424\n",
      "        GSVT    0.82737   0.81535   0.82132       482\n",
      "          SB    0.97954   0.98584   0.98268       777\n",
      "          SR    0.87216   0.94631   0.90773       447\n",
      "\n",
      "    accuracy                        0.87700      2130\n",
      "   macro avg    0.85405   0.85551   0.85404      2130\n",
      "weighted avg    0.87431   0.87700   0.87505      2130\n",
      "\n",
      "12\n",
      "359\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73711   0.67453   0.70443       424\n",
      "        GSVT    0.82737   0.81535   0.82132       482\n",
      "          SB    0.97954   0.98584   0.98268       777\n",
      "          SR    0.87216   0.94631   0.90773       447\n",
      "\n",
      "    accuracy                        0.87700      2130\n",
      "   macro avg    0.85405   0.85551   0.85404      2130\n",
      "weighted avg    0.87431   0.87700   0.87505      2130\n",
      "\n",
      "12\n",
      "359\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73711   0.67453   0.70443       424\n",
      "        GSVT    0.82737   0.81535   0.82132       482\n",
      "          SB    0.97954   0.98584   0.98268       777\n",
      "          SR    0.87216   0.94631   0.90773       447\n",
      "\n",
      "    accuracy                        0.87700      2130\n",
      "   macro avg    0.85405   0.85551   0.85404      2130\n",
      "weighted avg    0.87431   0.87700   0.87505      2130\n",
      "\n",
      "12\n",
      "359\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73711   0.67453   0.70443       424\n",
      "        GSVT    0.82737   0.81535   0.82132       482\n",
      "          SB    0.97954   0.98584   0.98268       777\n",
      "          SR    0.87216   0.94631   0.90773       447\n",
      "\n",
      "    accuracy                        0.87700      2130\n",
      "   macro avg    0.85405   0.85551   0.85404      2130\n",
      "weighted avg    0.87431   0.87700   0.87505      2130\n",
      "\n",
      "12\n",
      "359\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73711   0.67453   0.70443       424\n",
      "        GSVT    0.82737   0.81535   0.82132       482\n",
      "          SB    0.97954   0.98584   0.98268       777\n",
      "          SR    0.87216   0.94631   0.90773       447\n",
      "\n",
      "    accuracy                        0.87700      2130\n",
      "   macro avg    0.85405   0.85551   0.85404      2130\n",
      "weighted avg    0.87431   0.87700   0.87505      2130\n",
      "\n",
      "12\n",
      "359\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.74372   0.69811   0.72019       424\n",
      "        GSVT    0.84648   0.82365   0.83491       482\n",
      "          SB    0.97949   0.98327   0.98137       777\n",
      "          SR    0.88199   0.95302   0.91613       447\n",
      "\n",
      "    accuracy                        0.88404      2130\n",
      "   macro avg    0.86292   0.86451   0.86315      2130\n",
      "weighted avg    0.88200   0.88404   0.88255      2130\n",
      "\n",
      "12\n",
      "200\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.77487   0.69811   0.73449       424\n",
      "        GSVT    0.85504   0.84440   0.84969       482\n",
      "          SB    0.97580   0.98584   0.98079       777\n",
      "          SR    0.88090   0.95973   0.91863       447\n",
      "\n",
      "    accuracy                        0.89108      2130\n",
      "   macro avg    0.87165   0.87202   0.87090      2130\n",
      "weighted avg    0.88856   0.89108   0.88905      2130\n",
      "\n",
      "12\n",
      "100\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.80886   0.68868   0.74395       424\n",
      "        GSVT    0.83497   0.88174   0.85772       482\n",
      "          SB    0.97959   0.98842   0.98398       777\n",
      "          SR    0.89496   0.95302   0.92308       447\n",
      "\n",
      "    accuracy                        0.89718      2130\n",
      "   macro avg    0.87960   0.87796   0.87718      2130\n",
      "weighted avg    0.89512   0.89718   0.89485      2130\n",
      "\n",
      "11\n",
      "50\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T15:04:55.474284Z",
     "start_time": "2025-01-08T15:04:55.149250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=100)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=50)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=25)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=12)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "958b0490d7198338",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.75862   0.67453   0.71411       424\n",
      "        GSVT    0.83402   0.84440   0.83918       482\n",
      "          SB    0.97686   0.97812   0.97749       777\n",
      "          SR    0.88501   0.96421   0.92291       447\n",
      "\n",
      "    accuracy                        0.88451      2130\n",
      "   macro avg    0.86363   0.86531   0.86342      2130\n",
      "weighted avg    0.88182   0.88451   0.88231      2130\n",
      "\n",
      "10\n",
      "229\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.75862   0.67453   0.71411       424\n",
      "        GSVT    0.83402   0.84440   0.83918       482\n",
      "          SB    0.97686   0.97812   0.97749       777\n",
      "          SR    0.88501   0.96421   0.92291       447\n",
      "\n",
      "    accuracy                        0.88451      2130\n",
      "   macro avg    0.86363   0.86531   0.86342      2130\n",
      "weighted avg    0.88182   0.88451   0.88231      2130\n",
      "\n",
      "10\n",
      "229\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.75862   0.67453   0.71411       424\n",
      "        GSVT    0.83402   0.84440   0.83918       482\n",
      "          SB    0.97686   0.97812   0.97749       777\n",
      "          SR    0.88501   0.96421   0.92291       447\n",
      "\n",
      "    accuracy                        0.88451      2130\n",
      "   macro avg    0.86363   0.86531   0.86342      2130\n",
      "weighted avg    0.88182   0.88451   0.88231      2130\n",
      "\n",
      "10\n",
      "229\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.75862   0.67453   0.71411       424\n",
      "        GSVT    0.83402   0.84440   0.83918       482\n",
      "          SB    0.97686   0.97812   0.97749       777\n",
      "          SR    0.88501   0.96421   0.92291       447\n",
      "\n",
      "    accuracy                        0.88451      2130\n",
      "   macro avg    0.86363   0.86531   0.86342      2130\n",
      "weighted avg    0.88182   0.88451   0.88231      2130\n",
      "\n",
      "10\n",
      "229\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.75862   0.67453   0.71411       424\n",
      "        GSVT    0.83402   0.84440   0.83918       482\n",
      "          SB    0.97686   0.97812   0.97749       777\n",
      "          SR    0.88501   0.96421   0.92291       447\n",
      "\n",
      "    accuracy                        0.88451      2130\n",
      "   macro avg    0.86363   0.86531   0.86342      2130\n",
      "weighted avg    0.88182   0.88451   0.88231      2130\n",
      "\n",
      "10\n",
      "229\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.77105   0.69104   0.72886       424\n",
      "        GSVT    0.83918   0.84440   0.84178       482\n",
      "          SB    0.97698   0.98327   0.98012       777\n",
      "          SR    0.89234   0.96421   0.92688       447\n",
      "\n",
      "    accuracy                        0.88967      2130\n",
      "   macro avg    0.86989   0.87073   0.86941      2130\n",
      "weighted avg    0.88704   0.88967   0.88762      2130\n",
      "\n",
      "10\n",
      "200\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.78400   0.69340   0.73592       424\n",
      "        GSVT    0.84631   0.85685   0.85155       482\n",
      "          SB    0.97826   0.98456   0.98140       777\n",
      "          SR    0.88866   0.96421   0.92489       447\n",
      "\n",
      "    accuracy                        0.89343      2130\n",
      "   macro avg    0.87431   0.87475   0.87344      2130\n",
      "weighted avg    0.89093   0.89343   0.89129      2130\n",
      "\n",
      "10\n",
      "100\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.81096   0.69811   0.75032       424\n",
      "        GSVT    0.83826   0.88174   0.85945       482\n",
      "          SB    0.97959   0.98842   0.98398       777\n",
      "          SR    0.90084   0.95526   0.92725       447\n",
      "\n",
      "    accuracy                        0.89953      2130\n",
      "   macro avg    0.88241   0.88088   0.88025      2130\n",
      "weighted avg    0.89752   0.89953   0.89738      2130\n",
      "\n",
      "10\n",
      "50\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73039   0.70283   0.71635       424\n",
      "        GSVT    0.85270   0.85270   0.85270       482\n",
      "          SB    0.97592   0.99099   0.98340       777\n",
      "          SR    0.88027   0.88814   0.88419       447\n",
      "\n",
      "    accuracy                        0.88075      2130\n",
      "   macro avg    0.85982   0.85867   0.85916      2130\n",
      "weighted avg    0.87909   0.88075   0.87984      2130\n",
      "\n",
      "8\n",
      "25\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73860   0.57311   0.64542       424\n",
      "        GSVT    0.81404   0.89004   0.85035       482\n",
      "          SB    0.97592   0.99099   0.98340       777\n",
      "          SR    0.82887   0.89933   0.86266       447\n",
      "\n",
      "    accuracy                        0.86573      2130\n",
      "   macro avg    0.83936   0.83837   0.83546      2130\n",
      "weighted avg    0.86119   0.86573   0.86067      2130\n",
      "\n",
      "5\n",
      "12\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
