{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-24T04:28:04.656306Z",
     "start_time": "2024-12-24T04:28:03.230826Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Randomly seeding\n",
    "tf.random.set_seed(6950)\n",
    "# Constants\n",
    "SAMPLING_RATE = 500  # Hz\n",
    "ecg_folder = \"../../../Datasets/12-lead electrocardiogram database/ECGData\"\n",
    "diagnostics_file = \"../../../Datasets/12-lead electrocardiogram database/Diagnostics.xlsx\"\n",
    "# Label mapping\n",
    "# Basically to reduce 11 label to 4 for better performance on chapmanecg dataset\n",
    "rhythm_mapping = {\n",
    "    'AFIB': 'AFIB',\n",
    "    'AF': 'AFIB',\n",
    "    'SVT': 'GSVT',\n",
    "    'AT': 'GSVT',\n",
    "    'SAAWR': 'GSVT',\n",
    "    'ST': 'GSVT',\n",
    "    'AVNRT': 'GSVT',\n",
    "    'AVRT': 'GSVT',\n",
    "    'SB': 'SB',\n",
    "    'SR': 'SR',\n",
    "    'SA': 'SR'\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 10:28:03.516720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-24 10:28:03.527522: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-24 10:28:03.530940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-24 10:28:03.539934: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-24 10:28:04.087117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T04:29:09.553215Z",
     "start_time": "2024-12-24T04:28:04.690731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hamilton_tompkins_qrs_detector(ecg_signal, sampling_rate=500):\n",
    "    \"\"\"\n",
    "    Implementation of Hamilton-Tompkins QRS detection algorithm\n",
    "\n",
    "    Args:\n",
    "        ecg_signal: Raw ECG signal\n",
    "        sampling_rate: Sampling frequency in Hz\n",
    "\n",
    "    Returns:\n",
    "        qrs_peaks: Array of QRS peak locations\n",
    "        filtered_ecg: Filtered ECG signal for further analysis\n",
    "    \"\"\"\n",
    "    # Bandpass filter (5-15 Hz)\n",
    "    nyquist_freq = sampling_rate / 2\n",
    "    low = 5 / nyquist_freq\n",
    "    high = 15 / nyquist_freq\n",
    "    b, a = signal.butter(3, [low, high], btype='band')\n",
    "    filtered_ecg = signal.filtfilt(b, a, ecg_signal)\n",
    "\n",
    "    # Derivative\n",
    "    derivative = np.diff(filtered_ecg)\n",
    "\n",
    "    # Squaring\n",
    "    squared = derivative ** 2\n",
    "\n",
    "    # Moving window integration\n",
    "    window_size = int(0.150 * sampling_rate)  # 150 ms window\n",
    "    window = np.ones(window_size) / window_size\n",
    "    integrated = np.convolve(squared, window, mode='same')\n",
    "\n",
    "    # Adaptive thresholding\n",
    "    peak_threshold = 0.3 * np.max(integrated)\n",
    "\n",
    "    # Find peaks\n",
    "    qrs_peaks, _ = signal.find_peaks(integrated, height=peak_threshold, distance=sampling_rate//2)\n",
    "\n",
    "    return qrs_peaks, filtered_ecg\n",
    "\n",
    "def detect_p_t_waves(filtered_ecg, qrs_peaks, sampling_rate=500):\n",
    "    \"\"\"\n",
    "    Detect P and T waves in the ECG signal\n",
    "\n",
    "    Args:\n",
    "        filtered_ecg: Filtered ECG signal\n",
    "        qrs_peaks: QRS peak locations\n",
    "        sampling_rate: Sampling frequency in Hz\n",
    "\n",
    "    Returns:\n",
    "        p_peaks: Array of P wave peak locations\n",
    "        t_peaks: Array of T wave peak locations\n",
    "    \"\"\"\n",
    "    p_peaks = []\n",
    "    t_peaks = []\n",
    "\n",
    "    for qrs_peak in qrs_peaks:\n",
    "        # Search window for P wave (200ms before QRS)\n",
    "        p_search_start = max(0, qrs_peak - int(0.2 * sampling_rate))\n",
    "        p_search_end = qrs_peak\n",
    "        p_window = filtered_ecg[p_search_start:p_search_end]\n",
    "        if len(p_window) > 0:\n",
    "            p_peak = p_search_start + np.argmax(p_window)\n",
    "            p_peaks.append(p_peak)\n",
    "\n",
    "        # Search window for T wave (400ms after QRS)\n",
    "        t_search_start = qrs_peak\n",
    "        t_search_end = min(len(filtered_ecg), qrs_peak + int(0.4 * sampling_rate))\n",
    "        t_window = filtered_ecg[t_search_start:t_search_end]\n",
    "        if len(t_window) > 0:\n",
    "            t_peak = t_search_start + np.argmax(t_window)\n",
    "            t_peaks.append(t_peak)\n",
    "\n",
    "    return np.array(p_peaks), np.array(t_peaks)\n",
    "\n",
    "def calculate_axis(ecg_data):\n",
    "    \"\"\"\n",
    "    Calculate R and T axis (simplified approximation)\n",
    "    \"\"\"\n",
    "    # This is a simplified calculation - in practice, you'd need multiple leads\n",
    "    r_axis = np.mean(np.arctan2(ecg_data[:, 1], ecg_data[:, 0])) * 180 / np.pi\n",
    "    t_axis = r_axis + np.random.normal(0, 15)  # Simplified approximation\n",
    "    return r_axis, t_axis\n",
    "\n",
    "def extract_features(ecg_data, sampling_rate=500):\n",
    "    \"\"\"\n",
    "    Extract all features from ECG signal\n",
    "\n",
    "    Args:\n",
    "        ecg_data: Raw ECG data (lead II is in column 1, after header row)\n",
    "        sampling_rate: Sampling frequency in Hz\n",
    "\n",
    "    Returns:\n",
    "        features: Dictionary containing all extracted features\n",
    "    \"\"\"\n",
    "    # Get lead II data\n",
    "    lead_II = ecg_data[:, 1]\n",
    "\n",
    "    # Get QRS peaks and filtered signal\n",
    "    qrs_peaks, filtered_ecg = hamilton_tompkins_qrs_detector(lead_II, sampling_rate)\n",
    "\n",
    "    # Get P and T waves\n",
    "    p_peaks, t_peaks = detect_p_t_waves(filtered_ecg, qrs_peaks, sampling_rate)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Ventricular rate (bpm)\n",
    "    if len(qrs_peaks) > 1:\n",
    "        rr_intervals = np.diff(qrs_peaks) / sampling_rate\n",
    "        features['VentricularRate'] = 60 / np.mean(rr_intervals)\n",
    "    else:\n",
    "        features['VentricularRate'] = 0\n",
    "\n",
    "    # Atrial rate (bpm)\n",
    "    if len(p_peaks) > 1:\n",
    "        pp_intervals = np.diff(p_peaks) / sampling_rate\n",
    "        features['AtrialRate'] = 60 / np.mean(pp_intervals)\n",
    "    else:\n",
    "        features['AtrialRate'] = 0\n",
    "\n",
    "    # QRS duration\n",
    "    qrs_duration = []\n",
    "    for peak in qrs_peaks:\n",
    "        # Find QRS onset and offset\n",
    "        start = max(0, peak - int(0.1 * sampling_rate))\n",
    "        end = min(len(filtered_ecg), peak + int(0.1 * sampling_rate))\n",
    "        qrs_window = filtered_ecg[start:end]\n",
    "        if len(qrs_window) > 0:\n",
    "            # Use threshold crossing to estimate duration\n",
    "            threshold = 0.1 * np.max(qrs_window)\n",
    "            above_threshold = qrs_window > threshold\n",
    "            if np.any(above_threshold):\n",
    "                first_cross = np.where(above_threshold)[0][0]\n",
    "                last_cross = np.where(above_threshold)[0][-1]\n",
    "                qrs_duration.append((last_cross - first_cross) / sampling_rate * 1000)  # in ms\n",
    "\n",
    "    features['QRSDuration'] = np.mean(qrs_duration) if qrs_duration else 0\n",
    "\n",
    "    # QT interval\n",
    "    qt_intervals = []\n",
    "    for qrs, t in zip(qrs_peaks[:len(t_peaks)], t_peaks):\n",
    "        qt_intervals.append((t - qrs) / sampling_rate * 1000)  # in ms\n",
    "\n",
    "    features['QTInterval'] = np.mean(qt_intervals) if qt_intervals else 0\n",
    "\n",
    "    # QTc using Bazett's formula\n",
    "    if features['VentricularRate'] > 0:\n",
    "        features['QTCorrected'] = features['QTInterval'] * np.sqrt(60 / features['VentricularRate'])\n",
    "    else:\n",
    "        features['QTCorrected'] = 0\n",
    "\n",
    "    # Calculate R and T axis\n",
    "    features['RAxis'], features['TAxis'] = calculate_axis(ecg_data)\n",
    "\n",
    "    # QRS Count\n",
    "    features['QRSCount'] = len(qrs_peaks)\n",
    "\n",
    "    # Q wave timing features\n",
    "    if len(qrs_peaks) > 0:\n",
    "        features['QOnset'] = qrs_peaks[0] / sampling_rate * 1000  # in ms\n",
    "        features['QOffset'] = (qrs_peaks[0] + features['QRSDuration'] * sampling_rate / 1000) / sampling_rate * 1000\n",
    "    else:\n",
    "        features['QOnset'] = 0\n",
    "        features['QOffset'] = 0\n",
    "\n",
    "    # T wave offset\n",
    "    if len(t_peaks) > 0:\n",
    "        features['TOffset'] = t_peaks[-1] / sampling_rate * 1000  # in ms\n",
    "    else:\n",
    "        features['TOffset'] = 0\n",
    "\n",
    "    return features\n",
    "\n",
    "def load_and_preprocess_data(ecg_folder, diagnostics_file, rhythm_mapping):\n",
    "    \"\"\"\n",
    "    Load and preprocess the ECG data and diagnostics\n",
    "    \"\"\"\n",
    "    # Read diagnostics file\n",
    "    diagnostics = pd.read_excel(diagnostics_file)\n",
    "\n",
    "    # Filter relevant columns and map rhythms\n",
    "    diagnostics['Rhythm'] = diagnostics['Rhythm'].map(rhythm_mapping)\n",
    "\n",
    "    # Initialize lists for features and labels\n",
    "    all_features = []\n",
    "    labels = []\n",
    "\n",
    "    # Process each ECG file\n",
    "    for idx, row in diagnostics.iterrows():\n",
    "        file_path = os.path.join(ecg_folder, row['FileName'] + '.csv')\n",
    "        if os.path.exists(file_path):\n",
    "            # Load ECG data, skip header row\n",
    "            ecg_data = np.loadtxt(file_path, delimiter=',', skiprows=1)\n",
    "\n",
    "            # Extract features\n",
    "            features = extract_features(ecg_data)\n",
    "\n",
    "            # Create feature vector in the same order as diagnostics\n",
    "            feature_vector = [\n",
    "                features['VentricularRate'],\n",
    "                features['AtrialRate'],\n",
    "                features['QRSDuration'],\n",
    "                features['QTInterval'],\n",
    "                features['QTCorrected'],\n",
    "                features['RAxis'],\n",
    "                features['TAxis'],\n",
    "                features['QRSCount'],\n",
    "                features['QOnset'],\n",
    "                features['QOffset'],\n",
    "                features['TOffset']\n",
    "            ]\n",
    "\n",
    "            all_features.append(feature_vector)\n",
    "            labels.append(row['Rhythm'])\n",
    "\n",
    "    return np.array(all_features), np.array(labels)\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a simple MLP model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load and preprocess data\n",
    "X, y = load_and_preprocess_data(ecg_folder, diagnostics_file, rhythm_mapping)\n",
    "\n",
    "# Convert labels to numerical\n",
    "label_to_id = {label: idx for idx, label in enumerate(np.unique(y))}\n",
    "y_encoded = np.array([label_to_id[label] for label in y])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train model\n",
    "model = create_model(X_train.shape[1], len(label_to_id))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    # callbacks=[\n",
    "    #     tf.keras.callbacks.EarlyStopping(\n",
    "    #         monitor='val_loss',\n",
    "    #         patience=5,\n",
    "    #         restore_best_weights=True\n",
    "    #     )\n",
    "    # ]\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = np.argmax(model.predict(X_test_scaled), axis=1)\n",
    "\n",
    "# Convert numerical labels back to original classes\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "y_test_original = [id_to_label[y] for y in y_test]\n",
    "y_pred_original = [id_to_label[y] for y in y_pred]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_original, y_pred_original))\n"
   ],
   "id": "4f4511164db60c9d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735014527.143128  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.175317  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.177100  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.180484  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.182458  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.184105  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.295242  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.296527  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735014527.298031  463645 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-24 10:28:47.299239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5256 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735014527.986538  464186 service.cc:146] XLA service 0x79e45c00c2f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735014527.986577  464186 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-12-24 10:28:48.005558: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-24 10:28:48.103009: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 1/54\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1:39\u001B[0m 2s/step - accuracy: 0.2188 - loss: 1.4721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735014529.303731  464186 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 82ms/step - accuracy: 0.4068 - loss: 1.2843 - val_accuracy: 0.6238 - val_loss: 0.8784\n",
      "Epoch 2/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6269 - loss: 0.8754 - val_accuracy: 0.6942 - val_loss: 0.7604\n",
      "Epoch 3/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6686 - loss: 0.7947 - val_accuracy: 0.7160 - val_loss: 0.7191\n",
      "Epoch 4/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7012 - loss: 0.7428 - val_accuracy: 0.7342 - val_loss: 0.6829\n",
      "Epoch 5/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7035 - loss: 0.7109 - val_accuracy: 0.7330 - val_loss: 0.6740\n",
      "Epoch 6/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7156 - loss: 0.6965 - val_accuracy: 0.7400 - val_loss: 0.6550\n",
      "Epoch 7/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7153 - loss: 0.6824 - val_accuracy: 0.7353 - val_loss: 0.6444\n",
      "Epoch 8/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7263 - loss: 0.6677 - val_accuracy: 0.7347 - val_loss: 0.6419\n",
      "Epoch 9/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7271 - loss: 0.6600 - val_accuracy: 0.7353 - val_loss: 0.6400\n",
      "Epoch 10/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 937us/step - accuracy: 0.7281 - loss: 0.6559 - val_accuracy: 0.7453 - val_loss: 0.6271\n",
      "Epoch 11/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 957us/step - accuracy: 0.7422 - loss: 0.6354 - val_accuracy: 0.7465 - val_loss: 0.6211\n",
      "Epoch 12/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 958us/step - accuracy: 0.7341 - loss: 0.6350 - val_accuracy: 0.7465 - val_loss: 0.6231\n",
      "Epoch 13/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 953us/step - accuracy: 0.7436 - loss: 0.6238 - val_accuracy: 0.7482 - val_loss: 0.6110\n",
      "Epoch 14/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 934us/step - accuracy: 0.7414 - loss: 0.6188 - val_accuracy: 0.7518 - val_loss: 0.6092\n",
      "Epoch 15/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 942us/step - accuracy: 0.7438 - loss: 0.6156 - val_accuracy: 0.7547 - val_loss: 0.6022\n",
      "Epoch 16/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 934us/step - accuracy: 0.7481 - loss: 0.6139 - val_accuracy: 0.7565 - val_loss: 0.6017\n",
      "Epoch 17/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 983us/step - accuracy: 0.7524 - loss: 0.6004 - val_accuracy: 0.7553 - val_loss: 0.5949\n",
      "Epoch 18/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 910us/step - accuracy: 0.7540 - loss: 0.5989 - val_accuracy: 0.7576 - val_loss: 0.5906\n",
      "Epoch 19/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 997us/step - accuracy: 0.7567 - loss: 0.6027 - val_accuracy: 0.7582 - val_loss: 0.5932\n",
      "Epoch 20/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 981us/step - accuracy: 0.7584 - loss: 0.5921 - val_accuracy: 0.7623 - val_loss: 0.5887\n",
      "Epoch 21/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7547 - loss: 0.5897 - val_accuracy: 0.7617 - val_loss: 0.5863\n",
      "Epoch 22/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7626 - loss: 0.5853 - val_accuracy: 0.7641 - val_loss: 0.5810\n",
      "Epoch 23/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7690 - loss: 0.5737 - val_accuracy: 0.7688 - val_loss: 0.5790\n",
      "Epoch 24/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7674 - loss: 0.5888 - val_accuracy: 0.7688 - val_loss: 0.5796\n",
      "Epoch 25/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7649 - loss: 0.5781 - val_accuracy: 0.7717 - val_loss: 0.5778\n",
      "Epoch 26/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7667 - loss: 0.5788 - val_accuracy: 0.7717 - val_loss: 0.5725\n",
      "Epoch 27/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7727 - loss: 0.5711 - val_accuracy: 0.7688 - val_loss: 0.5771\n",
      "Epoch 28/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7723 - loss: 0.5636 - val_accuracy: 0.7758 - val_loss: 0.5810\n",
      "Epoch 29/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7779 - loss: 0.5646 - val_accuracy: 0.7705 - val_loss: 0.5762\n",
      "Epoch 30/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7753 - loss: 0.5549 - val_accuracy: 0.7770 - val_loss: 0.5703\n",
      "Epoch 31/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7685 - loss: 0.5593 - val_accuracy: 0.7717 - val_loss: 0.5787\n",
      "Epoch 32/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7732 - loss: 0.5551 - val_accuracy: 0.7758 - val_loss: 0.5706\n",
      "Epoch 33/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7791 - loss: 0.5553 - val_accuracy: 0.7776 - val_loss: 0.5662\n",
      "Epoch 34/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7773 - loss: 0.5507 - val_accuracy: 0.7788 - val_loss: 0.5630\n",
      "Epoch 35/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7774 - loss: 0.5562 - val_accuracy: 0.7770 - val_loss: 0.5790\n",
      "Epoch 36/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 970us/step - accuracy: 0.7763 - loss: 0.5540 - val_accuracy: 0.7729 - val_loss: 0.5756\n",
      "Epoch 37/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 951us/step - accuracy: 0.7783 - loss: 0.5549 - val_accuracy: 0.7782 - val_loss: 0.5647\n",
      "Epoch 38/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7760 - loss: 0.5397 - val_accuracy: 0.7752 - val_loss: 0.5800\n",
      "Epoch 39/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 976us/step - accuracy: 0.7812 - loss: 0.5541 - val_accuracy: 0.7776 - val_loss: 0.5686\n",
      "Epoch 40/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 979us/step - accuracy: 0.7806 - loss: 0.5468 - val_accuracy: 0.7776 - val_loss: 0.5662\n",
      "Epoch 41/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 985us/step - accuracy: 0.7886 - loss: 0.5429 - val_accuracy: 0.7752 - val_loss: 0.5678\n",
      "Epoch 42/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 966us/step - accuracy: 0.7826 - loss: 0.5467 - val_accuracy: 0.7805 - val_loss: 0.5645\n",
      "Epoch 43/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 948us/step - accuracy: 0.7830 - loss: 0.5361 - val_accuracy: 0.7799 - val_loss: 0.5611\n",
      "Epoch 44/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 947us/step - accuracy: 0.7846 - loss: 0.5413 - val_accuracy: 0.7764 - val_loss: 0.5637\n",
      "Epoch 45/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 972us/step - accuracy: 0.7851 - loss: 0.5375 - val_accuracy: 0.7811 - val_loss: 0.5603\n",
      "Epoch 46/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 955us/step - accuracy: 0.7876 - loss: 0.5323 - val_accuracy: 0.7729 - val_loss: 0.5670\n",
      "Epoch 47/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7804 - loss: 0.5400 - val_accuracy: 0.7752 - val_loss: 0.5648\n",
      "Epoch 48/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 961us/step - accuracy: 0.7877 - loss: 0.5386 - val_accuracy: 0.7776 - val_loss: 0.5651\n",
      "Epoch 49/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926us/step - accuracy: 0.7855 - loss: 0.5374 - val_accuracy: 0.7823 - val_loss: 0.5619\n",
      "Epoch 50/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 948us/step - accuracy: 0.7819 - loss: 0.5248 - val_accuracy: 0.7805 - val_loss: 0.5591\n",
      "Epoch 51/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 955us/step - accuracy: 0.7862 - loss: 0.5334 - val_accuracy: 0.7746 - val_loss: 0.5666\n",
      "Epoch 52/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 934us/step - accuracy: 0.7892 - loss: 0.5299 - val_accuracy: 0.7799 - val_loss: 0.5582\n",
      "Epoch 53/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7810 - loss: 0.5415 - val_accuracy: 0.7788 - val_loss: 0.5695\n",
      "Epoch 54/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7858 - loss: 0.5300 - val_accuracy: 0.7799 - val_loss: 0.5578\n",
      "Epoch 55/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7870 - loss: 0.5337 - val_accuracy: 0.7805 - val_loss: 0.5618\n",
      "Epoch 56/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7845 - loss: 0.5302 - val_accuracy: 0.7793 - val_loss: 0.5699\n",
      "Epoch 57/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7865 - loss: 0.5318 - val_accuracy: 0.7835 - val_loss: 0.5523\n",
      "Epoch 58/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7871 - loss: 0.5298 - val_accuracy: 0.7782 - val_loss: 0.5597\n",
      "Epoch 59/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7861 - loss: 0.5310 - val_accuracy: 0.7788 - val_loss: 0.5609\n",
      "Epoch 60/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7863 - loss: 0.5322 - val_accuracy: 0.7823 - val_loss: 0.5561\n",
      "Epoch 61/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7882 - loss: 0.5322 - val_accuracy: 0.7811 - val_loss: 0.5561\n",
      "Epoch 62/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7893 - loss: 0.5298 - val_accuracy: 0.7805 - val_loss: 0.5560\n",
      "Epoch 63/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7907 - loss: 0.5243 - val_accuracy: 0.7846 - val_loss: 0.5538\n",
      "Epoch 64/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7864 - loss: 0.5268 - val_accuracy: 0.7817 - val_loss: 0.5533\n",
      "Epoch 65/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7895 - loss: 0.5221 - val_accuracy: 0.7835 - val_loss: 0.5557\n",
      "Epoch 66/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 923us/step - accuracy: 0.7867 - loss: 0.5205 - val_accuracy: 0.7805 - val_loss: 0.5528\n",
      "Epoch 67/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7928 - loss: 0.5152 - val_accuracy: 0.7835 - val_loss: 0.5563\n",
      "Epoch 68/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7926 - loss: 0.5196 - val_accuracy: 0.7858 - val_loss: 0.5550\n",
      "Epoch 69/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7888 - loss: 0.5183 - val_accuracy: 0.7840 - val_loss: 0.5520\n",
      "Epoch 70/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7945 - loss: 0.5204 - val_accuracy: 0.7846 - val_loss: 0.5564\n",
      "Epoch 71/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7945 - loss: 0.5139 - val_accuracy: 0.7811 - val_loss: 0.5566\n",
      "Epoch 72/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7884 - loss: 0.5236 - val_accuracy: 0.7840 - val_loss: 0.5495\n",
      "Epoch 73/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7869 - loss: 0.5268 - val_accuracy: 0.7817 - val_loss: 0.5496\n",
      "Epoch 74/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7871 - loss: 0.5305 - val_accuracy: 0.7835 - val_loss: 0.5535\n",
      "Epoch 75/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7967 - loss: 0.5123 - val_accuracy: 0.7864 - val_loss: 0.5533\n",
      "Epoch 76/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7917 - loss: 0.5194 - val_accuracy: 0.7840 - val_loss: 0.5541\n",
      "Epoch 77/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7911 - loss: 0.5185 - val_accuracy: 0.7846 - val_loss: 0.5537\n",
      "Epoch 78/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7890 - loss: 0.5137 - val_accuracy: 0.7864 - val_loss: 0.5536\n",
      "Epoch 79/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7936 - loss: 0.5150 - val_accuracy: 0.7881 - val_loss: 0.5532\n",
      "Epoch 80/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7899 - loss: 0.5156 - val_accuracy: 0.7840 - val_loss: 0.5519\n",
      "Epoch 81/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7962 - loss: 0.5131 - val_accuracy: 0.7870 - val_loss: 0.5501\n",
      "Epoch 82/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7959 - loss: 0.5171 - val_accuracy: 0.7858 - val_loss: 0.5528\n",
      "Epoch 83/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7956 - loss: 0.5171 - val_accuracy: 0.7852 - val_loss: 0.5476\n",
      "Epoch 84/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7949 - loss: 0.5149 - val_accuracy: 0.7852 - val_loss: 0.5504\n",
      "Epoch 85/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 917us/step - accuracy: 0.7961 - loss: 0.5075 - val_accuracy: 0.7835 - val_loss: 0.5482\n",
      "Epoch 86/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 994us/step - accuracy: 0.7983 - loss: 0.5089 - val_accuracy: 0.7876 - val_loss: 0.5515\n",
      "Epoch 87/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 940us/step - accuracy: 0.7962 - loss: 0.5147 - val_accuracy: 0.7840 - val_loss: 0.5561\n",
      "Epoch 88/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 966us/step - accuracy: 0.7952 - loss: 0.5082 - val_accuracy: 0.7870 - val_loss: 0.5435\n",
      "Epoch 89/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7965 - loss: 0.5120 - val_accuracy: 0.7799 - val_loss: 0.5556\n",
      "Epoch 90/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7972 - loss: 0.5131 - val_accuracy: 0.7864 - val_loss: 0.5471\n",
      "Epoch 91/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7967 - loss: 0.5155 - val_accuracy: 0.7870 - val_loss: 0.5538\n",
      "Epoch 92/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7934 - loss: 0.5115 - val_accuracy: 0.7870 - val_loss: 0.5495\n",
      "Epoch 93/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7959 - loss: 0.5060 - val_accuracy: 0.7905 - val_loss: 0.5504\n",
      "Epoch 94/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 976us/step - accuracy: 0.8004 - loss: 0.4985 - val_accuracy: 0.7870 - val_loss: 0.5554\n",
      "Epoch 95/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 984us/step - accuracy: 0.7937 - loss: 0.5078 - val_accuracy: 0.7864 - val_loss: 0.5587\n",
      "Epoch 96/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 941us/step - accuracy: 0.7987 - loss: 0.5132 - val_accuracy: 0.7881 - val_loss: 0.5454\n",
      "Epoch 97/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 924us/step - accuracy: 0.7978 - loss: 0.4977 - val_accuracy: 0.7905 - val_loss: 0.5491\n",
      "Epoch 98/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 969us/step - accuracy: 0.7989 - loss: 0.5062 - val_accuracy: 0.7840 - val_loss: 0.5500\n",
      "Epoch 99/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 987us/step - accuracy: 0.7988 - loss: 0.5023 - val_accuracy: 0.7846 - val_loss: 0.5488\n",
      "Epoch 100/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8054 - loss: 0.4966 - val_accuracy: 0.7852 - val_loss: 0.5521\n",
      "Epoch 101/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 954us/step - accuracy: 0.7958 - loss: 0.5105 - val_accuracy: 0.7858 - val_loss: 0.5491\n",
      "Epoch 102/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8012 - loss: 0.5032 - val_accuracy: 0.7840 - val_loss: 0.5525\n",
      "Epoch 103/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 960us/step - accuracy: 0.8004 - loss: 0.5074 - val_accuracy: 0.7823 - val_loss: 0.5456\n",
      "Epoch 104/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 972us/step - accuracy: 0.8004 - loss: 0.4950 - val_accuracy: 0.7846 - val_loss: 0.5465\n",
      "Epoch 105/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8034 - loss: 0.5031 - val_accuracy: 0.7864 - val_loss: 0.5516\n",
      "Epoch 106/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 976us/step - accuracy: 0.7999 - loss: 0.5035 - val_accuracy: 0.7917 - val_loss: 0.5478\n",
      "Epoch 107/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7934 - loss: 0.5110 - val_accuracy: 0.7905 - val_loss: 0.5483\n",
      "Epoch 108/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8018 - loss: 0.4937 - val_accuracy: 0.7870 - val_loss: 0.5499\n",
      "Epoch 109/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8006 - loss: 0.5000 - val_accuracy: 0.7876 - val_loss: 0.5492\n",
      "Epoch 110/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7984 - loss: 0.5007 - val_accuracy: 0.7870 - val_loss: 0.5558\n",
      "Epoch 111/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7984 - loss: 0.5071 - val_accuracy: 0.7905 - val_loss: 0.5503\n",
      "Epoch 112/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8002 - loss: 0.4909 - val_accuracy: 0.7864 - val_loss: 0.5546\n",
      "Epoch 113/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7964 - loss: 0.5054 - val_accuracy: 0.7852 - val_loss: 0.5506\n",
      "Epoch 114/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 994us/step - accuracy: 0.7985 - loss: 0.5019 - val_accuracy: 0.7917 - val_loss: 0.5502\n",
      "Epoch 115/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 942us/step - accuracy: 0.8010 - loss: 0.4986 - val_accuracy: 0.7934 - val_loss: 0.5513\n",
      "Epoch 116/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 947us/step - accuracy: 0.8016 - loss: 0.4948 - val_accuracy: 0.7899 - val_loss: 0.5533\n",
      "Epoch 117/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7952 - loss: 0.4931 - val_accuracy: 0.7876 - val_loss: 0.5547\n",
      "Epoch 118/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7983 - loss: 0.4906 - val_accuracy: 0.7899 - val_loss: 0.5507\n",
      "Epoch 119/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8008 - loss: 0.4967 - val_accuracy: 0.7876 - val_loss: 0.5512\n",
      "Epoch 120/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8001 - loss: 0.4979 - val_accuracy: 0.7917 - val_loss: 0.5437\n",
      "Epoch 121/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7954 - loss: 0.4955 - val_accuracy: 0.7928 - val_loss: 0.5431\n",
      "Epoch 122/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8065 - loss: 0.4923 - val_accuracy: 0.7905 - val_loss: 0.5518\n",
      "Epoch 123/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8013 - loss: 0.4939 - val_accuracy: 0.7876 - val_loss: 0.5503\n",
      "Epoch 124/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8044 - loss: 0.4930 - val_accuracy: 0.7870 - val_loss: 0.5472\n",
      "Epoch 125/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7985 - loss: 0.4912 - val_accuracy: 0.7899 - val_loss: 0.5515\n",
      "Epoch 126/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8025 - loss: 0.4957 - val_accuracy: 0.7893 - val_loss: 0.5527\n",
      "Epoch 127/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8004 - loss: 0.4838 - val_accuracy: 0.7911 - val_loss: 0.5483\n",
      "Epoch 128/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7989 - loss: 0.4933 - val_accuracy: 0.7946 - val_loss: 0.5471\n",
      "Epoch 129/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7956 - loss: 0.5016 - val_accuracy: 0.7899 - val_loss: 0.5432\n",
      "Epoch 130/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8000 - loss: 0.4916 - val_accuracy: 0.7934 - val_loss: 0.5495\n",
      "Epoch 131/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8061 - loss: 0.4919 - val_accuracy: 0.7923 - val_loss: 0.5501\n",
      "Epoch 132/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8001 - loss: 0.4950 - val_accuracy: 0.7911 - val_loss: 0.5457\n",
      "Epoch 133/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8035 - loss: 0.4930 - val_accuracy: 0.7911 - val_loss: 0.5463\n",
      "Epoch 134/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8018 - loss: 0.4980 - val_accuracy: 0.7946 - val_loss: 0.5428\n",
      "Epoch 135/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8066 - loss: 0.4898 - val_accuracy: 0.7958 - val_loss: 0.5395\n",
      "Epoch 136/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7994 - loss: 0.4875 - val_accuracy: 0.7905 - val_loss: 0.5484\n",
      "Epoch 137/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8051 - loss: 0.4855 - val_accuracy: 0.7881 - val_loss: 0.5464\n",
      "Epoch 138/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8072 - loss: 0.4854 - val_accuracy: 0.7881 - val_loss: 0.5509\n",
      "Epoch 139/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8009 - loss: 0.4949 - val_accuracy: 0.7887 - val_loss: 0.5497\n",
      "Epoch 140/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7996 - loss: 0.4883 - val_accuracy: 0.7917 - val_loss: 0.5497\n",
      "Epoch 141/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8061 - loss: 0.4831 - val_accuracy: 0.7923 - val_loss: 0.5480\n",
      "Epoch 142/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 969us/step - accuracy: 0.8075 - loss: 0.4808 - val_accuracy: 0.7958 - val_loss: 0.5450\n",
      "Epoch 143/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8036 - loss: 0.4851 - val_accuracy: 0.7917 - val_loss: 0.5458\n",
      "Epoch 144/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8091 - loss: 0.4793 - val_accuracy: 0.7893 - val_loss: 0.5494\n",
      "Epoch 145/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8027 - loss: 0.4872 - val_accuracy: 0.7934 - val_loss: 0.5476\n",
      "Epoch 146/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8044 - loss: 0.4821 - val_accuracy: 0.7952 - val_loss: 0.5478\n",
      "Epoch 147/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8037 - loss: 0.4910 - val_accuracy: 0.7905 - val_loss: 0.5477\n",
      "Epoch 148/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8046 - loss: 0.4858 - val_accuracy: 0.7923 - val_loss: 0.5457\n",
      "Epoch 149/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8015 - loss: 0.4887 - val_accuracy: 0.7923 - val_loss: 0.5448\n",
      "Epoch 150/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8040 - loss: 0.4813 - val_accuracy: 0.7899 - val_loss: 0.5467\n",
      "Epoch 151/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8008 - loss: 0.4950 - val_accuracy: 0.7934 - val_loss: 0.5441\n",
      "Epoch 152/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8037 - loss: 0.4736 - val_accuracy: 0.7940 - val_loss: 0.5480\n",
      "Epoch 153/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8095 - loss: 0.4854 - val_accuracy: 0.7911 - val_loss: 0.5470\n",
      "Epoch 154/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8036 - loss: 0.4884 - val_accuracy: 0.7923 - val_loss: 0.5427\n",
      "Epoch 155/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8006 - loss: 0.4772 - val_accuracy: 0.7864 - val_loss: 0.5440\n",
      "Epoch 156/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8043 - loss: 0.4817 - val_accuracy: 0.7905 - val_loss: 0.5400\n",
      "Epoch 157/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 947us/step - accuracy: 0.8045 - loss: 0.4843 - val_accuracy: 0.7905 - val_loss: 0.5529\n",
      "Epoch 158/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8047 - loss: 0.4873 - val_accuracy: 0.7934 - val_loss: 0.5414\n",
      "Epoch 159/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8029 - loss: 0.4941 - val_accuracy: 0.7881 - val_loss: 0.5430\n",
      "Epoch 160/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8077 - loss: 0.4813 - val_accuracy: 0.7881 - val_loss: 0.5424\n",
      "Epoch 161/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8033 - loss: 0.4869 - val_accuracy: 0.7905 - val_loss: 0.5483\n",
      "Epoch 162/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8031 - loss: 0.4864 - val_accuracy: 0.7887 - val_loss: 0.5469\n",
      "Epoch 163/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8073 - loss: 0.4805 - val_accuracy: 0.7881 - val_loss: 0.5457\n",
      "Epoch 164/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8068 - loss: 0.4824 - val_accuracy: 0.7893 - val_loss: 0.5457\n",
      "Epoch 165/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8086 - loss: 0.4792 - val_accuracy: 0.7893 - val_loss: 0.5455\n",
      "Epoch 166/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8030 - loss: 0.4821 - val_accuracy: 0.7876 - val_loss: 0.5489\n",
      "Epoch 167/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8046 - loss: 0.4819 - val_accuracy: 0.7905 - val_loss: 0.5465\n",
      "Epoch 168/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8101 - loss: 0.4831 - val_accuracy: 0.7893 - val_loss: 0.5451\n",
      "Epoch 169/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8042 - loss: 0.4779 - val_accuracy: 0.7899 - val_loss: 0.5471\n",
      "Epoch 170/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8069 - loss: 0.4917 - val_accuracy: 0.7917 - val_loss: 0.5384\n",
      "Epoch 171/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8093 - loss: 0.4830 - val_accuracy: 0.7928 - val_loss: 0.5461\n",
      "Epoch 172/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8101 - loss: 0.4797 - val_accuracy: 0.7881 - val_loss: 0.5478\n",
      "Epoch 173/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8032 - loss: 0.4808 - val_accuracy: 0.7905 - val_loss: 0.5418\n",
      "Epoch 174/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8010 - loss: 0.4804 - val_accuracy: 0.7917 - val_loss: 0.5504\n",
      "Epoch 175/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8078 - loss: 0.4720 - val_accuracy: 0.7887 - val_loss: 0.5395\n",
      "Epoch 176/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8088 - loss: 0.4876 - val_accuracy: 0.7846 - val_loss: 0.5462\n",
      "Epoch 177/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8079 - loss: 0.4719 - val_accuracy: 0.7870 - val_loss: 0.5470\n",
      "Epoch 178/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8157 - loss: 0.4770 - val_accuracy: 0.7887 - val_loss: 0.5445\n",
      "Epoch 179/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8017 - loss: 0.4817 - val_accuracy: 0.7911 - val_loss: 0.5448\n",
      "Epoch 180/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8108 - loss: 0.4767 - val_accuracy: 0.7905 - val_loss: 0.5436\n",
      "Epoch 181/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8125 - loss: 0.4747 - val_accuracy: 0.7893 - val_loss: 0.5427\n",
      "Epoch 182/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8055 - loss: 0.4739 - val_accuracy: 0.7870 - val_loss: 0.5520\n",
      "Epoch 183/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 943us/step - accuracy: 0.8008 - loss: 0.4729 - val_accuracy: 0.7887 - val_loss: 0.5482\n",
      "Epoch 184/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8112 - loss: 0.4771 - val_accuracy: 0.7899 - val_loss: 0.5468\n",
      "Epoch 185/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7987 - loss: 0.4783 - val_accuracy: 0.7928 - val_loss: 0.5406\n",
      "Epoch 186/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8078 - loss: 0.4734 - val_accuracy: 0.7928 - val_loss: 0.5475\n",
      "Epoch 187/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8082 - loss: 0.4724 - val_accuracy: 0.7899 - val_loss: 0.5416\n",
      "Epoch 188/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8137 - loss: 0.4751 - val_accuracy: 0.7881 - val_loss: 0.5426\n",
      "Epoch 189/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8084 - loss: 0.4789 - val_accuracy: 0.7893 - val_loss: 0.5476\n",
      "Epoch 190/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8049 - loss: 0.4830 - val_accuracy: 0.7864 - val_loss: 0.5437\n",
      "Epoch 191/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8037 - loss: 0.4707 - val_accuracy: 0.7870 - val_loss: 0.5526\n",
      "Epoch 192/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8068 - loss: 0.4740 - val_accuracy: 0.7881 - val_loss: 0.5462\n",
      "Epoch 193/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8046 - loss: 0.4719 - val_accuracy: 0.7858 - val_loss: 0.5476\n",
      "Epoch 194/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8130 - loss: 0.4699 - val_accuracy: 0.7858 - val_loss: 0.5464\n",
      "Epoch 195/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8078 - loss: 0.4831 - val_accuracy: 0.7876 - val_loss: 0.5449\n",
      "Epoch 196/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8048 - loss: 0.4741 - val_accuracy: 0.7870 - val_loss: 0.5457\n",
      "Epoch 197/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8075 - loss: 0.4741 - val_accuracy: 0.7905 - val_loss: 0.5480\n",
      "Epoch 198/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8056 - loss: 0.4697 - val_accuracy: 0.7899 - val_loss: 0.5455\n",
      "Epoch 199/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8051 - loss: 0.4741 - val_accuracy: 0.7887 - val_loss: 0.5456\n",
      "Epoch 200/200\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8076 - loss: 0.4794 - val_accuracy: 0.7887 - val_loss: 0.5511\n",
      "\u001B[1m67/67\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB       0.57      0.54      0.55       424\n",
      "        GSVT       0.84      0.70      0.76       482\n",
      "          SB       0.93      0.99      0.96       777\n",
      "          SR       0.69      0.77      0.73       447\n",
      "\n",
      "    accuracy                           0.79      2130\n",
      "   macro avg       0.76      0.75      0.75      2130\n",
      "weighted avg       0.79      0.79      0.79      2130\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
