{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T11:52:40.273794Z",
     "start_time": "2024-10-29T11:52:38.664757Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('GeneratedTfLiteFiles', exist_ok=True)\n",
    "os.makedirs('GeneratedCHeaderFiles', exist_ok=True)\n",
    "\n",
    "# Generate a synthetic multi-class dataset\n",
    "X, y = make_classification(n_samples=2000,\n",
    "                           n_features=10,\n",
    "                           n_classes=5,\n",
    "                           n_clusters_per_class=1,\n",
    "                           n_informative=8,\n",
    "                           random_state=42)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:52:38.864968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-29 17:52:38.876204: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-29 17:52:38.879752: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 17:52:38.888935: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 17:52:39.468201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10) (1600,)\n",
      "[ 0.78458113 -2.008503    0.49006759 -0.6243383  -0.23459859  0.72880479\n",
      " -0.09425547  0.40643254 -0.0243661   0.45048382]\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:52:47.583467Z",
     "start_time": "2024-10-29T11:52:40.284593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a simple MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(10,)),\n",
    "    tf.keras.layers.BatchNormalization(), # training only\n",
    "    tf.keras.layers.Dropout(0.3), # training only\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Total two ops -> Dense (FULLY_CONNECTED: Composite ops)\n",
    "# Finally SOFTMAX\n",
    "\n",
    "# Number of Input -> 10, output -> 4 (total 5)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the original model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"\\nOriginal Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, digits=5))"
   ],
   "id": "67a95f9eca4863eb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730202760.457479  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.499324  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.502924  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.506944  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.509293  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.511535  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.616293  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.617563  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730202760.618859  654643 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-29 17:52:40.619927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5533 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730202761.761910  654796 service.cc:146] XLA service 0x2a9607c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730202761.761940  654796 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-10-29 17:52:41.808690: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-29 17:52:41.961803: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m36/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.2699 - loss: 1.7483 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730202763.185990  654796 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - accuracy: 0.2772 - loss: 1.7319 - val_accuracy: 0.4781 - val_loss: 1.5271\n",
      "Epoch 2/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5739 - loss: 1.2153 - val_accuracy: 0.5781 - val_loss: 1.4167\n",
      "Epoch 3/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6601 - loss: 0.9978 - val_accuracy: 0.6750 - val_loss: 1.2364\n",
      "Epoch 4/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7087 - loss: 0.8841 - val_accuracy: 0.7375 - val_loss: 1.0348\n",
      "Epoch 5/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7478 - loss: 0.7324 - val_accuracy: 0.7937 - val_loss: 0.8347\n",
      "Epoch 6/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7583 - loss: 0.6928 - val_accuracy: 0.8250 - val_loss: 0.6885\n",
      "Epoch 7/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7641 - loss: 0.6470 - val_accuracy: 0.8469 - val_loss: 0.5752\n",
      "Epoch 8/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7957 - loss: 0.5662 - val_accuracy: 0.8625 - val_loss: 0.4882\n",
      "Epoch 9/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8157 - loss: 0.5499 - val_accuracy: 0.8719 - val_loss: 0.4342\n",
      "Epoch 10/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8048 - loss: 0.5455 - val_accuracy: 0.8656 - val_loss: 0.4122\n",
      "Epoch 11/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8297 - loss: 0.4964 - val_accuracy: 0.8594 - val_loss: 0.3990\n",
      "Epoch 12/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8259 - loss: 0.4811 - val_accuracy: 0.8687 - val_loss: 0.3692\n",
      "Epoch 13/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8432 - loss: 0.4487 - val_accuracy: 0.8687 - val_loss: 0.3675\n",
      "Epoch 14/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8051 - loss: 0.5239 - val_accuracy: 0.8906 - val_loss: 0.3376\n",
      "Epoch 15/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8550 - loss: 0.4173 - val_accuracy: 0.8875 - val_loss: 0.3244\n",
      "Epoch 16/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8352 - loss: 0.4483 - val_accuracy: 0.8969 - val_loss: 0.3115\n",
      "Epoch 17/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8223 - loss: 0.4357 - val_accuracy: 0.8844 - val_loss: 0.3188\n",
      "Epoch 18/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8546 - loss: 0.3931 - val_accuracy: 0.8906 - val_loss: 0.3155\n",
      "Epoch 19/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8389 - loss: 0.4360 - val_accuracy: 0.8906 - val_loss: 0.3163\n",
      "Epoch 20/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8751 - loss: 0.3810 - val_accuracy: 0.9000 - val_loss: 0.2847\n",
      "Epoch 21/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8704 - loss: 0.3634 - val_accuracy: 0.8938 - val_loss: 0.2858\n",
      "Epoch 22/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8563 - loss: 0.3803 - val_accuracy: 0.9031 - val_loss: 0.2880\n",
      "Epoch 23/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8559 - loss: 0.4087 - val_accuracy: 0.8906 - val_loss: 0.2853\n",
      "Epoch 24/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8738 - loss: 0.3635 - val_accuracy: 0.8906 - val_loss: 0.2775\n",
      "Epoch 25/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8680 - loss: 0.3493 - val_accuracy: 0.8875 - val_loss: 0.2754\n",
      "Epoch 26/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8718 - loss: 0.3788 - val_accuracy: 0.9094 - val_loss: 0.2570\n",
      "Epoch 27/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8816 - loss: 0.3301 - val_accuracy: 0.9125 - val_loss: 0.2515\n",
      "Epoch 28/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8631 - loss: 0.3662 - val_accuracy: 0.9125 - val_loss: 0.2474\n",
      "Epoch 29/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8714 - loss: 0.3493 - val_accuracy: 0.9094 - val_loss: 0.2492\n",
      "Epoch 30/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8762 - loss: 0.3259 - val_accuracy: 0.9156 - val_loss: 0.2415\n",
      "Epoch 31/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8925 - loss: 0.3077 - val_accuracy: 0.9062 - val_loss: 0.2527\n",
      "Epoch 32/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8873 - loss: 0.3023 - val_accuracy: 0.9312 - val_loss: 0.2472\n",
      "Epoch 33/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8917 - loss: 0.3099 - val_accuracy: 0.9312 - val_loss: 0.2470\n",
      "Epoch 34/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8843 - loss: 0.3075 - val_accuracy: 0.9250 - val_loss: 0.2418\n",
      "Epoch 35/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9036 - loss: 0.2914 - val_accuracy: 0.9031 - val_loss: 0.2480\n",
      "Epoch 36/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8743 - loss: 0.3296 - val_accuracy: 0.9156 - val_loss: 0.2309\n",
      "Epoch 37/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8895 - loss: 0.3090 - val_accuracy: 0.9312 - val_loss: 0.2264\n",
      "Epoch 38/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8975 - loss: 0.3294 - val_accuracy: 0.9344 - val_loss: 0.2260\n",
      "Epoch 39/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8979 - loss: 0.2896 - val_accuracy: 0.9187 - val_loss: 0.2360\n",
      "Epoch 40/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8785 - loss: 0.3231 - val_accuracy: 0.9281 - val_loss: 0.2317\n",
      "Epoch 41/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8815 - loss: 0.3142 - val_accuracy: 0.9375 - val_loss: 0.2274\n",
      "Epoch 42/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9064 - loss: 0.2636 - val_accuracy: 0.9187 - val_loss: 0.2267\n",
      "Epoch 43/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8932 - loss: 0.3019 - val_accuracy: 0.9062 - val_loss: 0.2566\n",
      "Epoch 44/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9114 - loss: 0.2682 - val_accuracy: 0.9219 - val_loss: 0.2379\n",
      "Epoch 45/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9107 - loss: 0.2633 - val_accuracy: 0.9250 - val_loss: 0.2219\n",
      "Epoch 46/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9173 - loss: 0.2594 - val_accuracy: 0.9281 - val_loss: 0.2256\n",
      "Epoch 47/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9080 - loss: 0.2543 - val_accuracy: 0.9187 - val_loss: 0.2183\n",
      "Epoch 48/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9002 - loss: 0.2859 - val_accuracy: 0.9250 - val_loss: 0.2188\n",
      "Epoch 49/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9027 - loss: 0.2664 - val_accuracy: 0.9375 - val_loss: 0.2170\n",
      "Epoch 50/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9073 - loss: 0.2646 - val_accuracy: 0.9281 - val_loss: 0.2062\n",
      "Epoch 51/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9051 - loss: 0.2525 - val_accuracy: 0.9219 - val_loss: 0.2115\n",
      "Epoch 52/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8992 - loss: 0.2658 - val_accuracy: 0.9344 - val_loss: 0.2092\n",
      "Epoch 53/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9038 - loss: 0.2718 - val_accuracy: 0.9187 - val_loss: 0.2268\n",
      "Epoch 54/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9147 - loss: 0.2562 - val_accuracy: 0.9250 - val_loss: 0.2285\n",
      "Epoch 55/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9265 - loss: 0.2045 - val_accuracy: 0.9125 - val_loss: 0.2440\n",
      "Epoch 56/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9076 - loss: 0.2356 - val_accuracy: 0.9219 - val_loss: 0.2333\n",
      "Epoch 57/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8968 - loss: 0.2679 - val_accuracy: 0.9312 - val_loss: 0.2132\n",
      "Epoch 58/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9037 - loss: 0.2672 - val_accuracy: 0.9375 - val_loss: 0.2165\n",
      "Epoch 59/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9036 - loss: 0.3010 - val_accuracy: 0.9281 - val_loss: 0.2212\n",
      "Epoch 60/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9131 - loss: 0.2572 - val_accuracy: 0.9375 - val_loss: 0.2112\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n",
      "\n",
      "Original Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.86957   0.86957   0.86957        69\n",
      "           1    0.95181   0.91860   0.93491        86\n",
      "           2    0.83516   0.93827   0.88372        81\n",
      "           3    0.89333   0.85897   0.87582        78\n",
      "           4    0.91463   0.87209   0.89286        86\n",
      "\n",
      "    accuracy                        0.89250       400\n",
      "   macro avg    0.89290   0.89150   0.89137       400\n",
      "weighted avg    0.89461   0.89250   0.89271       400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:52:48.273827Z",
     "start_time": "2024-10-29T11:52:47.631821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate input statistics for quantization\n",
    "def get_input_statistics():\n",
    "    \"\"\"Calculate input statistics for quantization calibration\"\"\"\n",
    "    # Use training data to compute input statistics\n",
    "    input_data = X_train.astype(np.float32)\n",
    "\n",
    "    # Calculate min, max, and mean for each feature\n",
    "    input_min = np.min(input_data, axis=0)\n",
    "    input_max = np.max(input_data, axis=0)\n",
    "    input_mean = np.mean(input_data, axis=0)\n",
    "    input_std = np.std(input_data, axis=0)\n",
    "\n",
    "    return input_min, input_max, input_mean, input_std\n",
    "\n",
    "input_min, input_max, input_mean, input_std = get_input_statistics()\n",
    "\n",
    "# Representative dataset generator with input statistics\n",
    "def representative_dataset():\n",
    "    \"\"\"Generate representative dataset for quantization with input statistics\"\"\"\n",
    "    for i in range(500):  # Using 500 samples for calibration\n",
    "        data = X_train[i:i+1].astype(np.float32)\n",
    "        # Ensure the data is within the calculated ranges\n",
    "        data = np.clip(data, input_min, input_max)\n",
    "        yield [data]\n",
    "\n",
    "# Convert to TensorFlow Lite with proper quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Set input/output statistics for quantization\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Important: Disable per-channel quantization for dense layers else ggwp\n",
    "converter._experimental_disable_per_channel_quantization_for_dense_layers = True\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "tflite_model_path = os.path.join('GeneratedTfLiteFiles', 'model.tflite')\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Convert TFLite model to C header using xxd\n",
    "header_file = os.path.join('GeneratedCHeaderFiles', 'model.h')\n",
    "subprocess.run(['xxd', '-i', tflite_model_path, header_file])\n",
    "\n",
    "# Read and modify the header file\n",
    "with open(header_file, 'r') as f:\n",
    "    header_content = f.read()\n",
    "\n",
    "# Modify header content\n",
    "header_content = header_content.replace(\n",
    "    'unsigned char GeneratedTfLiteFiles_model_tflite[] = {',\n",
    "    'const unsigned char g_model[] = {'\n",
    ")\n",
    "header_content = header_content.replace(\n",
    "    'unsigned int GeneratedTfLiteFiles_model_tflite_len',\n",
    "    'const unsigned int g_model_len'\n",
    ")\n",
    "\n",
    "# Write the modified header file with added input statistics\n",
    "with open(header_file, 'w') as f:\n",
    "    f.write(\"// Generated TensorFlow Lite model header for multi-class classification\\n\")\n",
    "    f.write(\"#ifndef MODEL_H_\\n#define MODEL_H_\\n\\n\")\n",
    "\n",
    "    # Add input statistics as constants\n",
    "    f.write(\"// Input statistics for quantization\\n\")\n",
    "    for i in range(len(input_mean)):\n",
    "        f.write(f\"#define INPUT_MEAN_{i} {input_mean[i]}f\\n\")\n",
    "        f.write(f\"#define INPUT_STD_{i} {input_std[i]}f\\n\")\n",
    "\n",
    "    f.write(\"\\n\")\n",
    "    f.write(header_content)\n",
    "    f.write(\"\\n#endif  // MODEL_H_\")\n"
   ],
   "id": "cf17716396ad7834",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7bc363z2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7bc363z2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp7bc363z2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  130308660454224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660457920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660626704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660628992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660625648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660627760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660630224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660632512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660630752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660633216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660626352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660631808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660631104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660637264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660637088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660637968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660630928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660636560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660638848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660639200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660639024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130308660635680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1730202768.144797  654643 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1730202768.144809  654643 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-10-29 17:52:48.145014: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp7bc363z2\n",
      "2024-10-29 17:52:48.145904: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-29 17:52:48.145914: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp7bc363z2\n",
      "2024-10-29 17:52:48.152544: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-10-29 17:52:48.153678: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-29 17:52:48.189673: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp7bc363z2\n",
      "2024-10-29 17:52:48.199639: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 54627 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:52:48.304686Z",
     "start_time": "2024-10-29T11:52:48.281248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get quantization parameters\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "output_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "# Test the TFLite model with proper quantization\n",
    "y_tflite_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    # Quantize the input using the calculated statistics\n",
    "    input_data = X_test[i].reshape(1, 10)\n",
    "    # Clip input data to the range used during calibration\n",
    "    input_data = np.clip(input_data, input_min, input_max)\n",
    "    input_data_quantized = np.round(input_data / input_scale + input_zero_point)\n",
    "    input_data_quantized = input_data_quantized.astype(np.int8)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data_quantized)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output and dequantize it\n",
    "    # Only need to do it here. TFLM not needed, we can use the max value to find the class.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data_dequantized = (output_data.astype(np.float32) - output_zero_point) * output_scale\n",
    "\n",
    "    y_tflite_pred.append(np.argmax(output_data_dequantized))\n",
    "\n",
    "y_tflite_pred = np.array(y_tflite_pred)\n",
    "\n",
    "print(\"\\nTFLite Model Classification Report:\")\n",
    "print(classification_report(y_test, y_tflite_pred, digits=5))\n",
    "\n",
    "# Save detailed results including input statistics\n",
    "results_file = os.path.join('GeneratedTfLiteFiles', 'model_evaluation.txt')\n",
    "with open(results_file, 'w') as f:\n",
    "    f.write(\"Multi-class Classification Model Evaluation\\n\")\n",
    "    f.write(\"=========================================\\n\\n\")\n",
    "\n",
    "    f.write(\"Input Statistics:\\n\")\n",
    "    f.write(f\"Mean: {input_mean}\\n\")\n",
    "    f.write(f\"Std: {input_std}\\n\")\n",
    "    f.write(f\"Min: {input_min}\\n\")\n",
    "    f.write(f\"Max: {input_max}\\n\\n\")\n",
    "\n",
    "    f.write(\"Quantization Parameters:\\n\")\n",
    "    f.write(f\"Input Scale: {input_scale}\\n\")\n",
    "    f.write(f\"Input Zero Point: {input_zero_point}\\n\")\n",
    "    f.write(f\"Output Scale: {output_scale}\\n\")\n",
    "    f.write(f\"Output Zero Point: {output_zero_point}\\n\\n\")\n",
    "\n",
    "    f.write(\"Original Model Classification Report:\\n\")\n",
    "    f.write(classification_report(y_test, y_pred_classes, digits=5))\n",
    "\n",
    "    f.write(\"\\nTFLite Model Classification Report:\\n\")\n",
    "    f.write(classification_report(y_test, y_tflite_pred, digits=5))\n",
    "\n",
    "print(f\"\\nDetailed evaluation results saved to: {results_file}\")\n",
    "\n",
    "# Print summary of quantization parameters\n",
    "print(\"\\nQuantization Parameters Summary:\")\n",
    "print(f\"Input Scale: {input_scale}\")\n",
    "print(f\"Input Zero Point: {input_zero_point}\")\n",
    "print(f\"Output Scale: {output_scale}\")\n",
    "print(f\"Output Zero Point: {output_zero_point}\")\n",
    "\n",
    "# Print input statistics summary\n",
    "print(\"\\nInput Statistics Summary:\")\n",
    "print(f\"Mean Range: [{np.min(input_mean):.4f}, {np.max(input_mean):.4f}]\")\n",
    "print(f\"Std Range: [{np.min(input_std):.4f}, {np.max(input_std):.4f}]\")\n",
    "print(f\"Input Range: [{np.min(input_min):.4f}, {np.max(input_max):.4f}]\")"
   ],
   "id": "ab0bfe25596302c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TFLite Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.86765   0.85507   0.86131        69\n",
      "           1    0.94048   0.91860   0.92941        86\n",
      "           2    0.83516   0.93827   0.88372        81\n",
      "           3    0.88000   0.84615   0.86275        78\n",
      "           4    0.91463   0.87209   0.89286        86\n",
      "\n",
      "    accuracy                        0.88750       400\n",
      "   macro avg    0.88758   0.88604   0.88601       400\n",
      "weighted avg    0.88924   0.88750   0.88755       400\n",
      "\n",
      "\n",
      "Detailed evaluation results saved to: GeneratedTfLiteFiles/model_evaluation.txt\n",
      "\n",
      "Quantization Parameters Summary:\n",
      "Input Scale: 0.028471175581216812\n",
      "Input Zero Point: 2\n",
      "Output Scale: 0.00390625\n",
      "Output Zero Point: -128\n",
      "\n",
      "Input Statistics Summary:\n",
      "Mean Range: [-0.0118, 0.0335]\n",
      "Std Range: [0.9939, 1.0103]\n",
      "Input Range: [-4.0525, 3.9369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
