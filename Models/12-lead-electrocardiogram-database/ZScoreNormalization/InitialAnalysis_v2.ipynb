{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-25T22:24:32.882754Z",
     "start_time": "2024-12-25T22:24:30.879772Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='ecg_processing.log', level=logging.INFO,\n",
    "                   format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "# Constants\n",
    "SAMPLING_RATE = 500  # Hz\n",
    "SEQUENCE_LENGTH = 5000  # 10 seconds * 500 Hz\n",
    "N_LEADS = 12\n",
    "\n",
    "\n",
    "ecg_folder = \"../../../Datasets/12-lead electrocardiogram database/ECGData\"\n",
    "diagnostics_file = \"../../../Datasets/12-lead electrocardiogram database/Diagnostics.xlsx\"\n",
    "\n",
    "# Rhythm Mapping\n",
    "rhythm_mapping = {\n",
    "    'AFIB': 'AFIB',\n",
    "    'AF': 'AFIB',\n",
    "    'SVT': 'GSVT',\n",
    "    'AT': 'GSVT',\n",
    "    'SAAWR': 'GSVT',\n",
    "    'ST': 'GSVT',\n",
    "    'AVNRT': 'GSVT',\n",
    "    'AVRT': 'GSVT',\n",
    "    'SB': 'SB',\n",
    "    'SR': 'SR',\n",
    "    'SA': 'SR'\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 04:24:31.279237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-26 04:24:31.290806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-26 04:24:31.294341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-26 04:24:31.304210: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-26 04:24:32.068482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T22:41:55.293504Z",
     "start_time": "2024-12-25T22:24:32.925939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_data(ecg_folder, diagnostics_file, rhythm_mapping):\n",
    "    \"\"\"Load and preprocess ECG data and labels.\"\"\"\n",
    "    # Load diagnostics data\n",
    "    diagnostics = pd.read_excel(diagnostics_file)\n",
    "\n",
    "    # Map rhythms to reduced set of labels\n",
    "    diagnostics['Rhythm'] = diagnostics['Rhythm'].map(rhythm_mapping)\n",
    "\n",
    "    valid_files = []\n",
    "    valid_data = []\n",
    "    valid_labels = []\n",
    "\n",
    "    # Process each ECG file\n",
    "    for idx, row in diagnostics.iterrows():\n",
    "        file_path = os.path.join(ecg_folder, row['FileName'] + \".csv\")\n",
    "\n",
    "        try:\n",
    "            # Load ECG data\n",
    "            ecg_data = pd.read_csv(file_path, header=0)\n",
    "\n",
    "            # Check for missing or zero values\n",
    "            if ecg_data.isnull().any().any() or (ecg_data == 0).all().any():\n",
    "                logging.warning(f\"File {row['FileName']} contains null or all-zero leads - skipped\")\n",
    "                continue\n",
    "\n",
    "            # Check if data has expected length\n",
    "            if len(ecg_data) != SEQUENCE_LENGTH:\n",
    "                logging.warning(f\"File {row['FileName']} has unexpected length {len(ecg_data)} - skipped\")\n",
    "                continue\n",
    "\n",
    "            # Store valid data\n",
    "            valid_files.append(row['FileName'])\n",
    "            valid_data.append(ecg_data.values)\n",
    "            valid_labels.append(row['Rhythm'])\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {row['FileName']}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(valid_data)\n",
    "    y = np.array(valid_labels)\n",
    "\n",
    "    return X, y, valid_files\n",
    "\n",
    "def prepare_data(X, y, use_single_lead=False):\n",
    "    \"\"\"Prepare data for training - normalize and split.\"\"\"\n",
    "    # Reshape data if using single lead\n",
    "    if use_single_lead:\n",
    "        X = X[:, :, 1:2]  # Keep only second lead\n",
    "\n",
    "    # Reshape for preprocessing\n",
    "    original_shape = X.shape\n",
    "    X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "    # Normalize using z-score\n",
    "    scaler = StandardScaler()\n",
    "    X_normalized = scaler.fit_transform(X_reshaped)\n",
    "    X = X_normalized.reshape(original_shape)\n",
    "\n",
    "    # Convert string labels to integer indices\n",
    "    label_encoder = tf.keras.preprocessing.text.Tokenizer()\n",
    "    label_encoder.fit_on_texts(y)\n",
    "    y_encoded = label_encoder.texts_to_sequences(y)\n",
    "    y_encoded = np.array(y_encoded).reshape(-1)\n",
    "\n",
    "    # Convert to one-hot encoding\n",
    "    num_classes = len(label_encoder.word_index)\n",
    "    y_onehot = tf.keras.utils.to_categorical(y_encoded - 1, num_classes)  # Subtract 1 since word_index starts from 1\n",
    "\n",
    "    # Get class names in order\n",
    "    classes = [k for k, v in sorted(label_encoder.word_index.items(), key=lambda x: x[1])]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_onehot, test_size=0.3, random_state=42, stratify=y_onehot\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, classes\n",
    "\n",
    "def create_mlp_model(input_shape, num_classes):\n",
    "    \"\"\"Create MLP model.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"Create CNN model.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(32, 5, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, classes, model_name):\n",
    "    \"\"\"Train model and print evaluation metrics.\"\"\"\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test_classes, y_pred_classes,\n",
    "                                target_names=classes, digits=5))\n",
    "\n",
    "    return history\n",
    "\n",
    "# Load and preprocess data\n",
    "X, y, valid_files = load_and_preprocess_data(ecg_folder, diagnostics_file, rhythm_mapping)\n",
    "logging.info(f\"Successfully processed {len(valid_files)} files\")\n",
    "\n",
    "# Train and evaluate models using all leads\n",
    "print(\"\\nTraining models with all leads:\")\n",
    "X_train, X_test, y_train, y_test, classes = prepare_data(X, y, use_single_lead=False)\n",
    "\n",
    "# Train MLP\n",
    "# mlp_model = create_mlp_model((SEQUENCE_LENGTH, N_LEADS), len(classes))\n",
    "# mlp_history = train_and_evaluate(mlp_model, X_train, X_test, y_train, y_test,\n",
    "#                                  classes, \"MLP (All Leads)\")\n",
    "\n",
    "# Train CNN\n",
    "cnn_model = create_cnn_model((SEQUENCE_LENGTH, N_LEADS), len(classes))\n",
    "cnn_history = train_and_evaluate(cnn_model, X_train, X_test, y_train, y_test,\n",
    "                                 classes, \"CNN (All Leads)\")\n",
    "\n",
    "# Train and evaluate models using single lead\n",
    "print(\"\\nTraining models with single lead:\")\n",
    "X_train, X_test, y_train, y_test, classes = prepare_data(X, y, use_single_lead=True)\n",
    "\n",
    "# Train MLP\n",
    "# mlp_model_single = create_mlp_model((SEQUENCE_LENGTH, 1), len(classes))\n",
    "# mlp_history_single = train_and_evaluate(mlp_model_single, X_train, X_test,\n",
    "#                                         y_train, y_test, classes, \"MLP (Single Lead)\")\n",
    "\n",
    "# Train CNN\n",
    "cnn_model_single = create_cnn_model((SEQUENCE_LENGTH, 1), len(classes))\n",
    "cnn_history_single = train_and_evaluate(cnn_model_single, X_train, X_test,\n",
    "                                        y_train, y_test, classes, \"CNN (Single Lead)\")\n"
   ],
   "id": "7e72e8d7ae5d05b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models with all leads:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735165547.418528  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.453757  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.455727  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.459059  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.460973  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.462624  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.570859  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.572058  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1735165547.573132  151252 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-26 04:25:47.574147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5406 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n",
      "2024-12-26 04:25:48.048335: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1428480000 exceeds 10% of free system memory.\n",
      "2024-12-26 04:25:48.862408: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1428480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735165550.170294  152075 service.cc:146] XLA service 0x77b038003e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735165550.170327  152075 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-12-26 04:25:50.204745: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-26 04:25:50.320599: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 13/186\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.2834 - loss: 1.3944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735165554.111579  152075 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 22ms/step - accuracy: 0.3990 - loss: 1.2921 - val_accuracy: 0.5753 - val_loss: 0.9687\n",
      "Epoch 2/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.6220 - loss: 0.9354 - val_accuracy: 0.6472 - val_loss: 0.8401\n",
      "Epoch 3/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.6499 - loss: 0.8437 - val_accuracy: 0.6888 - val_loss: 0.7782\n",
      "Epoch 4/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.6982 - loss: 0.7598 - val_accuracy: 0.7103 - val_loss: 0.7425\n",
      "Epoch 5/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.7144 - loss: 0.7345 - val_accuracy: 0.7238 - val_loss: 0.6957\n",
      "Epoch 6/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.7334 - loss: 0.6929 - val_accuracy: 0.7258 - val_loss: 0.6971\n",
      "Epoch 7/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.7276 - loss: 0.7060 - val_accuracy: 0.7292 - val_loss: 0.6849\n",
      "Epoch 8/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 16ms/step - accuracy: 0.7386 - loss: 0.6688 - val_accuracy: 0.7413 - val_loss: 0.6523\n",
      "Epoch 9/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7659 - loss: 0.6265 - val_accuracy: 0.7372 - val_loss: 0.6679\n",
      "Epoch 10/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.7682 - loss: 0.6005 - val_accuracy: 0.7581 - val_loss: 0.6042\n",
      "Epoch 11/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 16ms/step - accuracy: 0.7775 - loss: 0.5842 - val_accuracy: 0.7641 - val_loss: 0.6051\n",
      "Epoch 12/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.7797 - loss: 0.5823 - val_accuracy: 0.7681 - val_loss: 0.5850\n",
      "Epoch 13/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.7937 - loss: 0.5543 - val_accuracy: 0.7473 - val_loss: 0.6192\n",
      "Epoch 14/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8021 - loss: 0.5287 - val_accuracy: 0.7460 - val_loss: 0.6558\n",
      "Epoch 15/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.7862 - loss: 0.5499 - val_accuracy: 0.7957 - val_loss: 0.5333\n",
      "Epoch 16/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8091 - loss: 0.4927 - val_accuracy: 0.7991 - val_loss: 0.5242\n",
      "Epoch 17/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8217 - loss: 0.4874 - val_accuracy: 0.7930 - val_loss: 0.5477\n",
      "Epoch 18/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8248 - loss: 0.4656 - val_accuracy: 0.7453 - val_loss: 0.6400\n",
      "Epoch 19/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8242 - loss: 0.4760 - val_accuracy: 0.8051 - val_loss: 0.5272\n",
      "Epoch 20/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8259 - loss: 0.4517 - val_accuracy: 0.8044 - val_loss: 0.5106\n",
      "Epoch 21/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8328 - loss: 0.4439 - val_accuracy: 0.7944 - val_loss: 0.5397\n",
      "Epoch 22/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8394 - loss: 0.4318 - val_accuracy: 0.8313 - val_loss: 0.4558\n",
      "Epoch 23/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8523 - loss: 0.4053 - val_accuracy: 0.8058 - val_loss: 0.5108\n",
      "Epoch 24/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8358 - loss: 0.4439 - val_accuracy: 0.8199 - val_loss: 0.4722\n",
      "Epoch 25/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8444 - loss: 0.4037 - val_accuracy: 0.8185 - val_loss: 0.4785\n",
      "Epoch 26/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8536 - loss: 0.3843 - val_accuracy: 0.8306 - val_loss: 0.4666\n",
      "Epoch 27/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8671 - loss: 0.3692 - val_accuracy: 0.8367 - val_loss: 0.4313\n",
      "Epoch 28/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8571 - loss: 0.3650 - val_accuracy: 0.8286 - val_loss: 0.4698\n",
      "Epoch 29/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8755 - loss: 0.3531 - val_accuracy: 0.8333 - val_loss: 0.4626\n",
      "Epoch 30/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8559 - loss: 0.3908 - val_accuracy: 0.8528 - val_loss: 0.4143\n",
      "Epoch 31/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8784 - loss: 0.3541 - val_accuracy: 0.8360 - val_loss: 0.4343\n",
      "Epoch 32/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8879 - loss: 0.3142 - val_accuracy: 0.8226 - val_loss: 0.4630\n",
      "Epoch 33/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8964 - loss: 0.3119 - val_accuracy: 0.8448 - val_loss: 0.4184\n",
      "Epoch 34/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8872 - loss: 0.3216 - val_accuracy: 0.8273 - val_loss: 0.4844\n",
      "Epoch 35/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8857 - loss: 0.2992 - val_accuracy: 0.8542 - val_loss: 0.4121\n",
      "Epoch 36/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8878 - loss: 0.3198 - val_accuracy: 0.8253 - val_loss: 0.5044\n",
      "Epoch 37/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8788 - loss: 0.3199 - val_accuracy: 0.8575 - val_loss: 0.3975\n",
      "Epoch 38/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8883 - loss: 0.3076 - val_accuracy: 0.8468 - val_loss: 0.4311\n",
      "Epoch 39/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8970 - loss: 0.2881 - val_accuracy: 0.8414 - val_loss: 0.4459\n",
      "Epoch 40/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.8994 - loss: 0.2881 - val_accuracy: 0.8427 - val_loss: 0.4584\n",
      "Epoch 41/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8967 - loss: 0.2798 - val_accuracy: 0.8609 - val_loss: 0.3974\n",
      "Epoch 42/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8947 - loss: 0.2786 - val_accuracy: 0.8165 - val_loss: 0.4886\n",
      "Epoch 43/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8917 - loss: 0.3027 - val_accuracy: 0.8313 - val_loss: 0.4817\n",
      "Epoch 44/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.8906 - loss: 0.2907 - val_accuracy: 0.8468 - val_loss: 0.4233\n",
      "Epoch 45/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9147 - loss: 0.2486 - val_accuracy: 0.8609 - val_loss: 0.4241\n",
      "Epoch 46/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9056 - loss: 0.2574 - val_accuracy: 0.8555 - val_loss: 0.4510\n",
      "Epoch 47/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9154 - loss: 0.2326 - val_accuracy: 0.8535 - val_loss: 0.4505\n",
      "Epoch 48/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9051 - loss: 0.2600 - val_accuracy: 0.8461 - val_loss: 0.4423\n",
      "Epoch 49/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9080 - loss: 0.2556 - val_accuracy: 0.8609 - val_loss: 0.4176\n",
      "Epoch 50/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9154 - loss: 0.2410 - val_accuracy: 0.8589 - val_loss: 0.4472\n",
      "Epoch 51/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9173 - loss: 0.2374 - val_accuracy: 0.8407 - val_loss: 0.4709\n",
      "Epoch 52/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9074 - loss: 0.2513 - val_accuracy: 0.8501 - val_loss: 0.4636\n",
      "Epoch 53/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9187 - loss: 0.2217 - val_accuracy: 0.8569 - val_loss: 0.4242\n",
      "Epoch 54/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9235 - loss: 0.2140 - val_accuracy: 0.8656 - val_loss: 0.4100\n",
      "Epoch 55/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9162 - loss: 0.2315 - val_accuracy: 0.8562 - val_loss: 0.4838\n",
      "Epoch 56/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9179 - loss: 0.2208 - val_accuracy: 0.8508 - val_loss: 0.4836\n",
      "Epoch 57/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9275 - loss: 0.2039 - val_accuracy: 0.8522 - val_loss: 0.4633\n",
      "Epoch 58/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9144 - loss: 0.2312 - val_accuracy: 0.8629 - val_loss: 0.4421\n",
      "Epoch 59/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9279 - loss: 0.1955 - val_accuracy: 0.8582 - val_loss: 0.4340\n",
      "Epoch 60/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9314 - loss: 0.1937 - val_accuracy: 0.8548 - val_loss: 0.4459\n",
      "Epoch 61/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9280 - loss: 0.2027 - val_accuracy: 0.8474 - val_loss: 0.5012\n",
      "Epoch 62/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9405 - loss: 0.1747 - val_accuracy: 0.8589 - val_loss: 0.4581\n",
      "Epoch 63/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9330 - loss: 0.1922 - val_accuracy: 0.8495 - val_loss: 0.5094\n",
      "Epoch 64/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9275 - loss: 0.2027 - val_accuracy: 0.8595 - val_loss: 0.4959\n",
      "Epoch 65/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9321 - loss: 0.1881 - val_accuracy: 0.8636 - val_loss: 0.4744\n",
      "Epoch 66/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9367 - loss: 0.1743 - val_accuracy: 0.8582 - val_loss: 0.4326\n",
      "Epoch 67/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9417 - loss: 0.1636 - val_accuracy: 0.8535 - val_loss: 0.4791\n",
      "Epoch 68/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9428 - loss: 0.1642 - val_accuracy: 0.8609 - val_loss: 0.4537\n",
      "Epoch 69/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9326 - loss: 0.1963 - val_accuracy: 0.8575 - val_loss: 0.5249\n",
      "Epoch 70/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9428 - loss: 0.1598 - val_accuracy: 0.8454 - val_loss: 0.4966\n",
      "Epoch 71/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9312 - loss: 0.1918 - val_accuracy: 0.8629 - val_loss: 0.5110\n",
      "Epoch 72/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9500 - loss: 0.1459 - val_accuracy: 0.8582 - val_loss: 0.5628\n",
      "Epoch 73/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9468 - loss: 0.1472 - val_accuracy: 0.8421 - val_loss: 0.5587\n",
      "Epoch 74/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9341 - loss: 0.1689 - val_accuracy: 0.8589 - val_loss: 0.4857\n",
      "Epoch 75/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9499 - loss: 0.1491 - val_accuracy: 0.8542 - val_loss: 0.5149\n",
      "Epoch 76/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9399 - loss: 0.1675 - val_accuracy: 0.8548 - val_loss: 0.5297\n",
      "Epoch 77/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9389 - loss: 0.1726 - val_accuracy: 0.8636 - val_loss: 0.5189\n",
      "Epoch 78/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9422 - loss: 0.1485 - val_accuracy: 0.8575 - val_loss: 0.5472\n",
      "Epoch 79/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9484 - loss: 0.1432 - val_accuracy: 0.8535 - val_loss: 0.5523\n",
      "Epoch 80/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9469 - loss: 0.1517 - val_accuracy: 0.8542 - val_loss: 0.5906\n",
      "Epoch 81/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9383 - loss: 0.1738 - val_accuracy: 0.8535 - val_loss: 0.5970\n",
      "Epoch 82/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9447 - loss: 0.1608 - val_accuracy: 0.8246 - val_loss: 0.6987\n",
      "Epoch 83/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9491 - loss: 0.1454 - val_accuracy: 0.8528 - val_loss: 0.5673\n",
      "Epoch 84/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9396 - loss: 0.1695 - val_accuracy: 0.8535 - val_loss: 0.6750\n",
      "Epoch 85/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9489 - loss: 0.1480 - val_accuracy: 0.8488 - val_loss: 0.5600\n",
      "Epoch 86/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9570 - loss: 0.1266 - val_accuracy: 0.8454 - val_loss: 0.6446\n",
      "Epoch 87/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9464 - loss: 0.1481 - val_accuracy: 0.8589 - val_loss: 0.5311\n",
      "Epoch 88/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9471 - loss: 0.1421 - val_accuracy: 0.8535 - val_loss: 0.5618\n",
      "Epoch 89/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9526 - loss: 0.1315 - val_accuracy: 0.8642 - val_loss: 0.5959\n",
      "Epoch 90/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9539 - loss: 0.1245 - val_accuracy: 0.8448 - val_loss: 0.6230\n",
      "Epoch 91/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9653 - loss: 0.1049 - val_accuracy: 0.8401 - val_loss: 0.6690\n",
      "Epoch 92/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9574 - loss: 0.1177 - val_accuracy: 0.8535 - val_loss: 0.5886\n",
      "Epoch 93/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9619 - loss: 0.1101 - val_accuracy: 0.8602 - val_loss: 0.5836\n",
      "Epoch 94/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9510 - loss: 0.1264 - val_accuracy: 0.8622 - val_loss: 0.6363\n",
      "Epoch 95/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9580 - loss: 0.1160 - val_accuracy: 0.8306 - val_loss: 0.6685\n",
      "Epoch 96/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9585 - loss: 0.1154 - val_accuracy: 0.8656 - val_loss: 0.5423\n",
      "Epoch 97/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9613 - loss: 0.1094 - val_accuracy: 0.8535 - val_loss: 0.6224\n",
      "Epoch 98/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9659 - loss: 0.0947 - val_accuracy: 0.8387 - val_loss: 0.7338\n",
      "Epoch 99/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9570 - loss: 0.1173 - val_accuracy: 0.8380 - val_loss: 0.7348\n",
      "Epoch 100/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9620 - loss: 0.1066 - val_accuracy: 0.8380 - val_loss: 0.7807\n",
      "Epoch 101/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9567 - loss: 0.1217 - val_accuracy: 0.8495 - val_loss: 0.6823\n",
      "Epoch 102/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9577 - loss: 0.1197 - val_accuracy: 0.8401 - val_loss: 0.8254\n",
      "Epoch 103/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9580 - loss: 0.1158 - val_accuracy: 0.8548 - val_loss: 0.6217\n",
      "Epoch 104/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9672 - loss: 0.0944 - val_accuracy: 0.8454 - val_loss: 0.6218\n",
      "Epoch 105/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9669 - loss: 0.0983 - val_accuracy: 0.8380 - val_loss: 0.6828\n",
      "Epoch 106/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9667 - loss: 0.0935 - val_accuracy: 0.8582 - val_loss: 0.6396\n",
      "Epoch 107/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9622 - loss: 0.1074 - val_accuracy: 0.8454 - val_loss: 0.6832\n",
      "Epoch 108/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9652 - loss: 0.0969 - val_accuracy: 0.8112 - val_loss: 0.8232\n",
      "Epoch 109/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9591 - loss: 0.1106 - val_accuracy: 0.8542 - val_loss: 0.6626\n",
      "Epoch 110/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9675 - loss: 0.0854 - val_accuracy: 0.8434 - val_loss: 0.7197\n",
      "Epoch 111/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9621 - loss: 0.1008 - val_accuracy: 0.8206 - val_loss: 0.9459\n",
      "Epoch 112/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9615 - loss: 0.1118 - val_accuracy: 0.8515 - val_loss: 0.6423\n",
      "Epoch 113/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9682 - loss: 0.0930 - val_accuracy: 0.8427 - val_loss: 0.7448\n",
      "Epoch 114/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9627 - loss: 0.1047 - val_accuracy: 0.8387 - val_loss: 0.7399\n",
      "Epoch 115/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9673 - loss: 0.0941 - val_accuracy: 0.8555 - val_loss: 0.7263\n",
      "Epoch 116/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9711 - loss: 0.0885 - val_accuracy: 0.8421 - val_loss: 0.7069\n",
      "Epoch 117/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9667 - loss: 0.0924 - val_accuracy: 0.8508 - val_loss: 0.7907\n",
      "Epoch 118/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9743 - loss: 0.0827 - val_accuracy: 0.8495 - val_loss: 0.7571\n",
      "Epoch 119/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9659 - loss: 0.0961 - val_accuracy: 0.8293 - val_loss: 0.9346\n",
      "Epoch 120/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9702 - loss: 0.0904 - val_accuracy: 0.8535 - val_loss: 0.6782\n",
      "Epoch 121/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9696 - loss: 0.0829 - val_accuracy: 0.8515 - val_loss: 0.7592\n",
      "Epoch 122/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9738 - loss: 0.0758 - val_accuracy: 0.8515 - val_loss: 0.8057\n",
      "Epoch 123/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9733 - loss: 0.0791 - val_accuracy: 0.8528 - val_loss: 0.7946\n",
      "Epoch 124/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9709 - loss: 0.0792 - val_accuracy: 0.8394 - val_loss: 0.8225\n",
      "Epoch 125/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9724 - loss: 0.0818 - val_accuracy: 0.8589 - val_loss: 0.7929\n",
      "Epoch 126/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9681 - loss: 0.0925 - val_accuracy: 0.8488 - val_loss: 0.7908\n",
      "Epoch 127/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9750 - loss: 0.0627 - val_accuracy: 0.8548 - val_loss: 0.7456\n",
      "Epoch 128/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9769 - loss: 0.0684 - val_accuracy: 0.8454 - val_loss: 0.7794\n",
      "Epoch 129/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9742 - loss: 0.0740 - val_accuracy: 0.8508 - val_loss: 0.7536\n",
      "Epoch 130/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9747 - loss: 0.0731 - val_accuracy: 0.8394 - val_loss: 0.8822\n",
      "Epoch 131/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9461 - loss: 0.1460 - val_accuracy: 0.8616 - val_loss: 0.6652\n",
      "Epoch 132/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9713 - loss: 0.0778 - val_accuracy: 0.8481 - val_loss: 0.7534\n",
      "Epoch 133/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9706 - loss: 0.0889 - val_accuracy: 0.8528 - val_loss: 0.7543\n",
      "Epoch 134/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9758 - loss: 0.0704 - val_accuracy: 0.8481 - val_loss: 0.7885\n",
      "Epoch 135/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9755 - loss: 0.0673 - val_accuracy: 0.8622 - val_loss: 0.7089\n",
      "Epoch 136/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9735 - loss: 0.0719 - val_accuracy: 0.8595 - val_loss: 0.7574\n",
      "Epoch 137/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9798 - loss: 0.0592 - val_accuracy: 0.8253 - val_loss: 0.8624\n",
      "Epoch 138/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9663 - loss: 0.0941 - val_accuracy: 0.8407 - val_loss: 0.9102\n",
      "Epoch 139/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9621 - loss: 0.0997 - val_accuracy: 0.8474 - val_loss: 0.8087\n",
      "Epoch 140/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9868 - loss: 0.0438 - val_accuracy: 0.8555 - val_loss: 0.6919\n",
      "Epoch 141/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9741 - loss: 0.0713 - val_accuracy: 0.8468 - val_loss: 0.9400\n",
      "Epoch 142/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9763 - loss: 0.0630 - val_accuracy: 0.8522 - val_loss: 0.8422\n",
      "Epoch 143/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9820 - loss: 0.0557 - val_accuracy: 0.8468 - val_loss: 0.8065\n",
      "Epoch 144/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9619 - loss: 0.1029 - val_accuracy: 0.8528 - val_loss: 0.8477\n",
      "Epoch 145/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9770 - loss: 0.0705 - val_accuracy: 0.8474 - val_loss: 0.8713\n",
      "Epoch 146/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9756 - loss: 0.0673 - val_accuracy: 0.8495 - val_loss: 0.8492\n",
      "Epoch 147/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9807 - loss: 0.0645 - val_accuracy: 0.8535 - val_loss: 0.7779\n",
      "Epoch 148/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9767 - loss: 0.0628 - val_accuracy: 0.8569 - val_loss: 0.8022\n",
      "Epoch 149/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9833 - loss: 0.0508 - val_accuracy: 0.8353 - val_loss: 1.1148\n",
      "Epoch 150/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9769 - loss: 0.0612 - val_accuracy: 0.8414 - val_loss: 0.8428\n",
      "Epoch 151/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9729 - loss: 0.0749 - val_accuracy: 0.8542 - val_loss: 0.9157\n",
      "Epoch 152/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9825 - loss: 0.0494 - val_accuracy: 0.8488 - val_loss: 0.9257\n",
      "Epoch 153/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9780 - loss: 0.0699 - val_accuracy: 0.8427 - val_loss: 0.8643\n",
      "Epoch 154/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9762 - loss: 0.0692 - val_accuracy: 0.8481 - val_loss: 0.9073\n",
      "Epoch 155/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9812 - loss: 0.0532 - val_accuracy: 0.8286 - val_loss: 0.9898\n",
      "Epoch 156/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9765 - loss: 0.0620 - val_accuracy: 0.8407 - val_loss: 0.8906\n",
      "Epoch 157/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9765 - loss: 0.0557 - val_accuracy: 0.8273 - val_loss: 1.0320\n",
      "Epoch 158/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9661 - loss: 0.0922 - val_accuracy: 0.8488 - val_loss: 0.9365\n",
      "Epoch 159/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9807 - loss: 0.0542 - val_accuracy: 0.8380 - val_loss: 0.9813\n",
      "Epoch 160/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9781 - loss: 0.0659 - val_accuracy: 0.8495 - val_loss: 1.0283\n",
      "Epoch 161/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9714 - loss: 0.0755 - val_accuracy: 0.8495 - val_loss: 0.9564\n",
      "Epoch 162/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9765 - loss: 0.0605 - val_accuracy: 0.8367 - val_loss: 1.0523\n",
      "Epoch 163/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9824 - loss: 0.0472 - val_accuracy: 0.8468 - val_loss: 0.9577\n",
      "Epoch 164/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9783 - loss: 0.0620 - val_accuracy: 0.8468 - val_loss: 1.2300\n",
      "Epoch 165/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9689 - loss: 0.0833 - val_accuracy: 0.8414 - val_loss: 1.0076\n",
      "Epoch 166/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9711 - loss: 0.0835 - val_accuracy: 0.8474 - val_loss: 0.9687\n",
      "Epoch 167/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9829 - loss: 0.0493 - val_accuracy: 0.8461 - val_loss: 1.0106\n",
      "Epoch 168/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9909 - loss: 0.0301 - val_accuracy: 0.8387 - val_loss: 1.1337\n",
      "Epoch 169/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9824 - loss: 0.0510 - val_accuracy: 0.8367 - val_loss: 1.1001\n",
      "Epoch 170/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9827 - loss: 0.0512 - val_accuracy: 0.8548 - val_loss: 0.9838\n",
      "Epoch 171/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9861 - loss: 0.0377 - val_accuracy: 0.8488 - val_loss: 1.0919\n",
      "Epoch 172/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9889 - loss: 0.0328 - val_accuracy: 0.8441 - val_loss: 1.2877\n",
      "Epoch 173/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9768 - loss: 0.0678 - val_accuracy: 0.8508 - val_loss: 0.8956\n",
      "Epoch 174/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9678 - loss: 0.0859 - val_accuracy: 0.8501 - val_loss: 0.9123\n",
      "Epoch 175/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9823 - loss: 0.0498 - val_accuracy: 0.8481 - val_loss: 1.0388\n",
      "Epoch 176/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9888 - loss: 0.0385 - val_accuracy: 0.8320 - val_loss: 1.2342\n",
      "Epoch 177/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9773 - loss: 0.0724 - val_accuracy: 0.8474 - val_loss: 0.9669\n",
      "Epoch 178/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9857 - loss: 0.0401 - val_accuracy: 0.8501 - val_loss: 1.0559\n",
      "Epoch 179/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - accuracy: 0.9820 - loss: 0.0591 - val_accuracy: 0.8474 - val_loss: 1.0130\n",
      "Epoch 180/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9847 - loss: 0.0422 - val_accuracy: 0.8434 - val_loss: 1.0543\n",
      "Epoch 181/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9808 - loss: 0.0600 - val_accuracy: 0.8387 - val_loss: 0.9851\n",
      "Epoch 182/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9701 - loss: 0.0861 - val_accuracy: 0.8374 - val_loss: 1.0912\n",
      "Epoch 183/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9787 - loss: 0.0651 - val_accuracy: 0.8427 - val_loss: 0.9893\n",
      "Epoch 184/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9865 - loss: 0.0364 - val_accuracy: 0.8461 - val_loss: 1.0300\n",
      "Epoch 185/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9692 - loss: 0.0809 - val_accuracy: 0.8367 - val_loss: 1.0868\n",
      "Epoch 186/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9820 - loss: 0.0537 - val_accuracy: 0.8495 - val_loss: 0.9027\n",
      "Epoch 187/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9850 - loss: 0.0429 - val_accuracy: 0.8508 - val_loss: 0.9885\n",
      "Epoch 188/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9773 - loss: 0.0741 - val_accuracy: 0.8569 - val_loss: 0.8279\n",
      "Epoch 189/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9867 - loss: 0.0426 - val_accuracy: 0.8421 - val_loss: 1.1711\n",
      "Epoch 190/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9895 - loss: 0.0323 - val_accuracy: 0.8374 - val_loss: 1.0281\n",
      "Epoch 191/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9808 - loss: 0.0546 - val_accuracy: 0.8427 - val_loss: 1.1643\n",
      "Epoch 192/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9826 - loss: 0.0503 - val_accuracy: 0.8461 - val_loss: 0.8035\n",
      "Epoch 193/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9780 - loss: 0.0667 - val_accuracy: 0.8360 - val_loss: 1.1321\n",
      "Epoch 194/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9808 - loss: 0.0583 - val_accuracy: 0.8401 - val_loss: 1.2543\n",
      "Epoch 195/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9861 - loss: 0.0401 - val_accuracy: 0.8427 - val_loss: 1.1755\n",
      "Epoch 196/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9878 - loss: 0.0377 - val_accuracy: 0.8434 - val_loss: 1.0840\n",
      "Epoch 197/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9827 - loss: 0.0447 - val_accuracy: 0.8374 - val_loss: 1.2765\n",
      "Epoch 198/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9888 - loss: 0.0290 - val_accuracy: 0.8320 - val_loss: 1.3769\n",
      "Epoch 199/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9756 - loss: 0.0716 - val_accuracy: 0.8414 - val_loss: 1.0807\n",
      "Epoch 200/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9839 - loss: 0.0426 - val_accuracy: 0.8401 - val_loss: 1.3481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 04:34:24.736476: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 765360000 exceeds 10% of free system memory.\n",
      "2024-12-26 04:34:25.197929: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 765360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step\n",
      "\n",
      "Classification Report for CNN (All Leads):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          sb    0.91339   0.89460   0.90390      1167\n",
      "        gsvt    0.81519   0.82464   0.81988       690\n",
      "          sr    0.76369   0.79460   0.77884       667\n",
      "        afib    0.84557   0.83158   0.83851       665\n",
      "\n",
      "    accuracy                        0.84541      3189\n",
      "   macro avg    0.83446   0.83636   0.83528      3189\n",
      "weighted avg    0.84669   0.84541   0.84593      3189\n",
      "\n",
      "\n",
      "Training models with single lead:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 18ms/step - accuracy: 0.3804 - loss: 1.3381 - val_accuracy: 0.5081 - val_loss: 1.1130\n",
      "Epoch 2/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.5219 - loss: 1.1045 - val_accuracy: 0.5753 - val_loss: 0.9960\n",
      "Epoch 3/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.5727 - loss: 1.0229 - val_accuracy: 0.6116 - val_loss: 0.9412\n",
      "Epoch 4/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.5920 - loss: 0.9664 - val_accuracy: 0.6492 - val_loss: 0.8783\n",
      "Epoch 5/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.6267 - loss: 0.9189 - val_accuracy: 0.6734 - val_loss: 0.8346\n",
      "Epoch 6/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.6402 - loss: 0.8673 - val_accuracy: 0.6915 - val_loss: 0.7885\n",
      "Epoch 7/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.6631 - loss: 0.8382 - val_accuracy: 0.7070 - val_loss: 0.7570\n",
      "Epoch 8/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.6867 - loss: 0.7893 - val_accuracy: 0.6868 - val_loss: 0.7798\n",
      "Epoch 9/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.6930 - loss: 0.7639 - val_accuracy: 0.7191 - val_loss: 0.7251\n",
      "Epoch 10/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.6987 - loss: 0.7544 - val_accuracy: 0.6902 - val_loss: 0.7508\n",
      "Epoch 11/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.7057 - loss: 0.7286 - val_accuracy: 0.7359 - val_loss: 0.6881\n",
      "Epoch 12/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7252 - loss: 0.7084 - val_accuracy: 0.7392 - val_loss: 0.6681\n",
      "Epoch 13/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7339 - loss: 0.6730 - val_accuracy: 0.7634 - val_loss: 0.6427\n",
      "Epoch 14/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7544 - loss: 0.6510 - val_accuracy: 0.7621 - val_loss: 0.6306\n",
      "Epoch 15/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.7296 - loss: 0.6846 - val_accuracy: 0.7702 - val_loss: 0.6235\n",
      "Epoch 16/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7480 - loss: 0.6509 - val_accuracy: 0.7695 - val_loss: 0.6044\n",
      "Epoch 17/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.7614 - loss: 0.6221 - val_accuracy: 0.7433 - val_loss: 0.6478\n",
      "Epoch 18/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.7440 - loss: 0.6458 - val_accuracy: 0.7419 - val_loss: 0.6529\n",
      "Epoch 19/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7583 - loss: 0.6113 - val_accuracy: 0.7816 - val_loss: 0.5917\n",
      "Epoch 20/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7757 - loss: 0.5950 - val_accuracy: 0.7876 - val_loss: 0.5603\n",
      "Epoch 21/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7699 - loss: 0.5912 - val_accuracy: 0.7903 - val_loss: 0.5515\n",
      "Epoch 22/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7724 - loss: 0.5870 - val_accuracy: 0.7466 - val_loss: 0.6436\n",
      "Epoch 23/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7863 - loss: 0.5726 - val_accuracy: 0.7749 - val_loss: 0.5822\n",
      "Epoch 24/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7747 - loss: 0.5764 - val_accuracy: 0.7997 - val_loss: 0.5259\n",
      "Epoch 25/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.7836 - loss: 0.5699 - val_accuracy: 0.7903 - val_loss: 0.5488\n",
      "Epoch 26/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.7890 - loss: 0.5497 - val_accuracy: 0.7984 - val_loss: 0.5154\n",
      "Epoch 27/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8017 - loss: 0.5355 - val_accuracy: 0.7681 - val_loss: 0.6026\n",
      "Epoch 28/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7946 - loss: 0.5342 - val_accuracy: 0.7245 - val_loss: 0.6863\n",
      "Epoch 29/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7753 - loss: 0.5658 - val_accuracy: 0.7944 - val_loss: 0.5538\n",
      "Epoch 30/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7995 - loss: 0.5164 - val_accuracy: 0.8165 - val_loss: 0.5026\n",
      "Epoch 31/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.7855 - loss: 0.5468 - val_accuracy: 0.7849 - val_loss: 0.5325\n",
      "Epoch 32/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7905 - loss: 0.5360 - val_accuracy: 0.8219 - val_loss: 0.4909\n",
      "Epoch 33/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8009 - loss: 0.5236 - val_accuracy: 0.7742 - val_loss: 0.5699\n",
      "Epoch 34/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7990 - loss: 0.5253 - val_accuracy: 0.8212 - val_loss: 0.4976\n",
      "Epoch 35/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7991 - loss: 0.5084 - val_accuracy: 0.7970 - val_loss: 0.5200\n",
      "Epoch 36/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7941 - loss: 0.5221 - val_accuracy: 0.7991 - val_loss: 0.5381\n",
      "Epoch 37/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8185 - loss: 0.4964 - val_accuracy: 0.8058 - val_loss: 0.4998\n",
      "Epoch 38/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8062 - loss: 0.5035 - val_accuracy: 0.8172 - val_loss: 0.4831\n",
      "Epoch 39/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8108 - loss: 0.4932 - val_accuracy: 0.8347 - val_loss: 0.4561\n",
      "Epoch 40/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8106 - loss: 0.4899 - val_accuracy: 0.8306 - val_loss: 0.4818\n",
      "Epoch 41/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8192 - loss: 0.4839 - val_accuracy: 0.7950 - val_loss: 0.5424\n",
      "Epoch 42/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8075 - loss: 0.4951 - val_accuracy: 0.8058 - val_loss: 0.5069\n",
      "Epoch 43/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7981 - loss: 0.5209 - val_accuracy: 0.8172 - val_loss: 0.5001\n",
      "Epoch 44/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8066 - loss: 0.4792 - val_accuracy: 0.8327 - val_loss: 0.4780\n",
      "Epoch 45/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8093 - loss: 0.4857 - val_accuracy: 0.8313 - val_loss: 0.4778\n",
      "Epoch 46/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8174 - loss: 0.4722 - val_accuracy: 0.7876 - val_loss: 0.5347\n",
      "Epoch 47/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.7930 - loss: 0.5067 - val_accuracy: 0.8266 - val_loss: 0.5197\n",
      "Epoch 48/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8171 - loss: 0.4788 - val_accuracy: 0.8488 - val_loss: 0.4523\n",
      "Epoch 49/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8215 - loss: 0.4661 - val_accuracy: 0.8259 - val_loss: 0.4801\n",
      "Epoch 50/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8213 - loss: 0.4751 - val_accuracy: 0.8333 - val_loss: 0.4614\n",
      "Epoch 51/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8090 - loss: 0.4794 - val_accuracy: 0.8152 - val_loss: 0.4944\n",
      "Epoch 52/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.8137 - loss: 0.4810 - val_accuracy: 0.8555 - val_loss: 0.4460\n",
      "Epoch 53/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8279 - loss: 0.4420 - val_accuracy: 0.8286 - val_loss: 0.4715\n",
      "Epoch 54/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8283 - loss: 0.4509 - val_accuracy: 0.8239 - val_loss: 0.4953\n",
      "Epoch 55/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8314 - loss: 0.4466 - val_accuracy: 0.8347 - val_loss: 0.4564\n",
      "Epoch 56/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8304 - loss: 0.4438 - val_accuracy: 0.7997 - val_loss: 0.5480\n",
      "Epoch 57/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8210 - loss: 0.4732 - val_accuracy: 0.8360 - val_loss: 0.5006\n",
      "Epoch 58/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8245 - loss: 0.4506 - val_accuracy: 0.8421 - val_loss: 0.4499\n",
      "Epoch 59/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8356 - loss: 0.4526 - val_accuracy: 0.8380 - val_loss: 0.4639\n",
      "Epoch 60/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8189 - loss: 0.4767 - val_accuracy: 0.8461 - val_loss: 0.4613\n",
      "Epoch 61/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8400 - loss: 0.4372 - val_accuracy: 0.8145 - val_loss: 0.4792\n",
      "Epoch 62/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8219 - loss: 0.4499 - val_accuracy: 0.8474 - val_loss: 0.4470\n",
      "Epoch 63/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8319 - loss: 0.4408 - val_accuracy: 0.8535 - val_loss: 0.4281\n",
      "Epoch 64/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8356 - loss: 0.4343 - val_accuracy: 0.8448 - val_loss: 0.4440\n",
      "Epoch 65/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8322 - loss: 0.4644 - val_accuracy: 0.8185 - val_loss: 0.4758\n",
      "Epoch 66/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8196 - loss: 0.4615 - val_accuracy: 0.8333 - val_loss: 0.4697\n",
      "Epoch 67/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8405 - loss: 0.4345 - val_accuracy: 0.8474 - val_loss: 0.4362\n",
      "Epoch 68/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8308 - loss: 0.4417 - val_accuracy: 0.8327 - val_loss: 0.4694\n",
      "Epoch 69/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8322 - loss: 0.4475 - val_accuracy: 0.8441 - val_loss: 0.4401\n",
      "Epoch 70/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8425 - loss: 0.4288 - val_accuracy: 0.8333 - val_loss: 0.4661\n",
      "Epoch 71/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8355 - loss: 0.4228 - val_accuracy: 0.8239 - val_loss: 0.4782\n",
      "Epoch 72/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8354 - loss: 0.4376 - val_accuracy: 0.8138 - val_loss: 0.5117\n",
      "Epoch 73/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8324 - loss: 0.4441 - val_accuracy: 0.8387 - val_loss: 0.4535\n",
      "Epoch 74/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8398 - loss: 0.4271 - val_accuracy: 0.8374 - val_loss: 0.4698\n",
      "Epoch 75/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8460 - loss: 0.4276 - val_accuracy: 0.8266 - val_loss: 0.4524\n",
      "Epoch 76/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8338 - loss: 0.4288 - val_accuracy: 0.8340 - val_loss: 0.4706\n",
      "Epoch 77/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8466 - loss: 0.4178 - val_accuracy: 0.8454 - val_loss: 0.4441\n",
      "Epoch 78/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8400 - loss: 0.4181 - val_accuracy: 0.8589 - val_loss: 0.4260\n",
      "Epoch 79/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8425 - loss: 0.4193 - val_accuracy: 0.8508 - val_loss: 0.4283\n",
      "Epoch 80/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8476 - loss: 0.4152 - val_accuracy: 0.8454 - val_loss: 0.4307\n",
      "Epoch 81/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8335 - loss: 0.4455 - val_accuracy: 0.8165 - val_loss: 0.5166\n",
      "Epoch 82/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8324 - loss: 0.4425 - val_accuracy: 0.8508 - val_loss: 0.4233\n",
      "Epoch 83/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8428 - loss: 0.4086 - val_accuracy: 0.8374 - val_loss: 0.4418\n",
      "Epoch 84/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8281 - loss: 0.4322 - val_accuracy: 0.8266 - val_loss: 0.4954\n",
      "Epoch 85/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8428 - loss: 0.4287 - val_accuracy: 0.8145 - val_loss: 0.4872\n",
      "Epoch 86/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8369 - loss: 0.4083 - val_accuracy: 0.8528 - val_loss: 0.4332\n",
      "Epoch 87/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8548 - loss: 0.4085 - val_accuracy: 0.8488 - val_loss: 0.4293\n",
      "Epoch 88/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8448 - loss: 0.4172 - val_accuracy: 0.8501 - val_loss: 0.4537\n",
      "Epoch 89/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8398 - loss: 0.4109 - val_accuracy: 0.8515 - val_loss: 0.4446\n",
      "Epoch 90/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8550 - loss: 0.4076 - val_accuracy: 0.8474 - val_loss: 0.4374\n",
      "Epoch 91/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8409 - loss: 0.4051 - val_accuracy: 0.8347 - val_loss: 0.4560\n",
      "Epoch 92/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8308 - loss: 0.4292 - val_accuracy: 0.8515 - val_loss: 0.4379\n",
      "Epoch 93/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8402 - loss: 0.4169 - val_accuracy: 0.8522 - val_loss: 0.4521\n",
      "Epoch 94/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8334 - loss: 0.4300 - val_accuracy: 0.8468 - val_loss: 0.4376\n",
      "Epoch 95/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8374 - loss: 0.4360 - val_accuracy: 0.8528 - val_loss: 0.4292\n",
      "Epoch 96/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8382 - loss: 0.4111 - val_accuracy: 0.8609 - val_loss: 0.4206\n",
      "Epoch 97/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8452 - loss: 0.4040 - val_accuracy: 0.8132 - val_loss: 0.4993\n",
      "Epoch 98/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8410 - loss: 0.3985 - val_accuracy: 0.8481 - val_loss: 0.4560\n",
      "Epoch 99/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8415 - loss: 0.4222 - val_accuracy: 0.8535 - val_loss: 0.4380\n",
      "Epoch 100/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8535 - loss: 0.3967 - val_accuracy: 0.8515 - val_loss: 0.4346\n",
      "Epoch 101/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8506 - loss: 0.3912 - val_accuracy: 0.8562 - val_loss: 0.4426\n",
      "Epoch 102/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8463 - loss: 0.4106 - val_accuracy: 0.8474 - val_loss: 0.4516\n",
      "Epoch 103/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8453 - loss: 0.4033 - val_accuracy: 0.8407 - val_loss: 0.4618\n",
      "Epoch 104/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8478 - loss: 0.3983 - val_accuracy: 0.8401 - val_loss: 0.4662\n",
      "Epoch 105/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8504 - loss: 0.4121 - val_accuracy: 0.8488 - val_loss: 0.4450\n",
      "Epoch 106/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8317 - loss: 0.4228 - val_accuracy: 0.8441 - val_loss: 0.4487\n",
      "Epoch 107/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8581 - loss: 0.3807 - val_accuracy: 0.8300 - val_loss: 0.5014\n",
      "Epoch 108/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8515 - loss: 0.3900 - val_accuracy: 0.8226 - val_loss: 0.4773\n",
      "Epoch 109/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8510 - loss: 0.3812 - val_accuracy: 0.8374 - val_loss: 0.4532\n",
      "Epoch 110/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8535 - loss: 0.3762 - val_accuracy: 0.8454 - val_loss: 0.4591\n",
      "Epoch 111/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8489 - loss: 0.4003 - val_accuracy: 0.8548 - val_loss: 0.4304\n",
      "Epoch 112/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8513 - loss: 0.3913 - val_accuracy: 0.8387 - val_loss: 0.4797\n",
      "Epoch 113/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8429 - loss: 0.4051 - val_accuracy: 0.8609 - val_loss: 0.4431\n",
      "Epoch 114/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8571 - loss: 0.3801 - val_accuracy: 0.8542 - val_loss: 0.4304\n",
      "Epoch 115/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8574 - loss: 0.3888 - val_accuracy: 0.8259 - val_loss: 0.4864\n",
      "Epoch 116/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8582 - loss: 0.3874 - val_accuracy: 0.8535 - val_loss: 0.4388\n",
      "Epoch 117/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8573 - loss: 0.3867 - val_accuracy: 0.8548 - val_loss: 0.4376\n",
      "Epoch 118/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8546 - loss: 0.3728 - val_accuracy: 0.8569 - val_loss: 0.4297\n",
      "Epoch 119/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8542 - loss: 0.3764 - val_accuracy: 0.8340 - val_loss: 0.4665\n",
      "Epoch 120/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8485 - loss: 0.3928 - val_accuracy: 0.8414 - val_loss: 0.4508\n",
      "Epoch 121/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8600 - loss: 0.3839 - val_accuracy: 0.8454 - val_loss: 0.4449\n",
      "Epoch 122/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8606 - loss: 0.3744 - val_accuracy: 0.8602 - val_loss: 0.4402\n",
      "Epoch 123/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8612 - loss: 0.3828 - val_accuracy: 0.8427 - val_loss: 0.4431\n",
      "Epoch 124/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8538 - loss: 0.3811 - val_accuracy: 0.8461 - val_loss: 0.4670\n",
      "Epoch 125/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8625 - loss: 0.3654 - val_accuracy: 0.8380 - val_loss: 0.4833\n",
      "Epoch 126/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8570 - loss: 0.3762 - val_accuracy: 0.8649 - val_loss: 0.4303\n",
      "Epoch 127/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8586 - loss: 0.3663 - val_accuracy: 0.8676 - val_loss: 0.4065\n",
      "Epoch 128/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8606 - loss: 0.3743 - val_accuracy: 0.8595 - val_loss: 0.4205\n",
      "Epoch 129/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8605 - loss: 0.3810 - val_accuracy: 0.8555 - val_loss: 0.4161\n",
      "Epoch 130/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8550 - loss: 0.3863 - val_accuracy: 0.8522 - val_loss: 0.4434\n",
      "Epoch 131/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8702 - loss: 0.3427 - val_accuracy: 0.8313 - val_loss: 0.4813\n",
      "Epoch 132/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8494 - loss: 0.3864 - val_accuracy: 0.8481 - val_loss: 0.4531\n",
      "Epoch 133/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8618 - loss: 0.3686 - val_accuracy: 0.8515 - val_loss: 0.4591\n",
      "Epoch 134/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8587 - loss: 0.3759 - val_accuracy: 0.8542 - val_loss: 0.4393\n",
      "Epoch 135/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8524 - loss: 0.3854 - val_accuracy: 0.8481 - val_loss: 0.4887\n",
      "Epoch 136/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8502 - loss: 0.3948 - val_accuracy: 0.8562 - val_loss: 0.4189\n",
      "Epoch 137/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8548 - loss: 0.3856 - val_accuracy: 0.8582 - val_loss: 0.4380\n",
      "Epoch 138/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8637 - loss: 0.3757 - val_accuracy: 0.8461 - val_loss: 0.4625\n",
      "Epoch 139/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8578 - loss: 0.3730 - val_accuracy: 0.8427 - val_loss: 0.4354\n",
      "Epoch 140/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8599 - loss: 0.3627 - val_accuracy: 0.8582 - val_loss: 0.4228\n",
      "Epoch 141/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8742 - loss: 0.3399 - val_accuracy: 0.8582 - val_loss: 0.4359\n",
      "Epoch 142/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8625 - loss: 0.3742 - val_accuracy: 0.8535 - val_loss: 0.4402\n",
      "Epoch 143/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8658 - loss: 0.3696 - val_accuracy: 0.8542 - val_loss: 0.4427\n",
      "Epoch 144/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8669 - loss: 0.3536 - val_accuracy: 0.8501 - val_loss: 0.4708\n",
      "Epoch 145/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8577 - loss: 0.3690 - val_accuracy: 0.8468 - val_loss: 0.4261\n",
      "Epoch 146/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8502 - loss: 0.3977 - val_accuracy: 0.8589 - val_loss: 0.4274\n",
      "Epoch 147/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8549 - loss: 0.3773 - val_accuracy: 0.8589 - val_loss: 0.4408\n",
      "Epoch 148/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8618 - loss: 0.3607 - val_accuracy: 0.8595 - val_loss: 0.4095\n",
      "Epoch 149/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8600 - loss: 0.3617 - val_accuracy: 0.8696 - val_loss: 0.4021\n",
      "Epoch 150/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8642 - loss: 0.3531 - val_accuracy: 0.8582 - val_loss: 0.4374\n",
      "Epoch 151/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8669 - loss: 0.3540 - val_accuracy: 0.8508 - val_loss: 0.4535\n",
      "Epoch 152/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8719 - loss: 0.3288 - val_accuracy: 0.8616 - val_loss: 0.4148\n",
      "Epoch 153/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8709 - loss: 0.3409 - val_accuracy: 0.8730 - val_loss: 0.4188\n",
      "Epoch 154/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8682 - loss: 0.3544 - val_accuracy: 0.8555 - val_loss: 0.4241\n",
      "Epoch 155/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8719 - loss: 0.3385 - val_accuracy: 0.8609 - val_loss: 0.4330\n",
      "Epoch 156/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8694 - loss: 0.3342 - val_accuracy: 0.8569 - val_loss: 0.4287\n",
      "Epoch 157/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8654 - loss: 0.3537 - val_accuracy: 0.8468 - val_loss: 0.4570\n",
      "Epoch 158/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8644 - loss: 0.3475 - val_accuracy: 0.8716 - val_loss: 0.4065\n",
      "Epoch 159/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8767 - loss: 0.3281 - val_accuracy: 0.8690 - val_loss: 0.4289\n",
      "Epoch 160/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8715 - loss: 0.3381 - val_accuracy: 0.8488 - val_loss: 0.4672\n",
      "Epoch 161/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8655 - loss: 0.3429 - val_accuracy: 0.8595 - val_loss: 0.4543\n",
      "Epoch 162/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8666 - loss: 0.3410 - val_accuracy: 0.8461 - val_loss: 0.4669\n",
      "Epoch 163/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8718 - loss: 0.3382 - val_accuracy: 0.8575 - val_loss: 0.4248\n",
      "Epoch 164/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8756 - loss: 0.3314 - val_accuracy: 0.8690 - val_loss: 0.4277\n",
      "Epoch 165/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8791 - loss: 0.3331 - val_accuracy: 0.8589 - val_loss: 0.4327\n",
      "Epoch 166/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8656 - loss: 0.3420 - val_accuracy: 0.8656 - val_loss: 0.4188\n",
      "Epoch 167/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8814 - loss: 0.3175 - val_accuracy: 0.8575 - val_loss: 0.4434\n",
      "Epoch 168/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8753 - loss: 0.3350 - val_accuracy: 0.8656 - val_loss: 0.4327\n",
      "Epoch 169/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8711 - loss: 0.3377 - val_accuracy: 0.8649 - val_loss: 0.4083\n",
      "Epoch 170/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8741 - loss: 0.3482 - val_accuracy: 0.8730 - val_loss: 0.4147\n",
      "Epoch 171/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8717 - loss: 0.3298 - val_accuracy: 0.8595 - val_loss: 0.4252\n",
      "Epoch 172/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8671 - loss: 0.3564 - val_accuracy: 0.8656 - val_loss: 0.4456\n",
      "Epoch 173/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8745 - loss: 0.3439 - val_accuracy: 0.8548 - val_loss: 0.4442\n",
      "Epoch 174/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8715 - loss: 0.3353 - val_accuracy: 0.8669 - val_loss: 0.4232\n",
      "Epoch 175/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8769 - loss: 0.3302 - val_accuracy: 0.8683 - val_loss: 0.4217\n",
      "Epoch 176/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8705 - loss: 0.3352 - val_accuracy: 0.8569 - val_loss: 0.4166\n",
      "Epoch 177/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8712 - loss: 0.3264 - val_accuracy: 0.8542 - val_loss: 0.4440\n",
      "Epoch 178/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8733 - loss: 0.3297 - val_accuracy: 0.8757 - val_loss: 0.4102\n",
      "Epoch 179/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8692 - loss: 0.3318 - val_accuracy: 0.8407 - val_loss: 0.4681\n",
      "Epoch 180/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8669 - loss: 0.3340 - val_accuracy: 0.8622 - val_loss: 0.4094\n",
      "Epoch 181/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8774 - loss: 0.3281 - val_accuracy: 0.8535 - val_loss: 0.4454\n",
      "Epoch 182/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8806 - loss: 0.3260 - val_accuracy: 0.8535 - val_loss: 0.4456\n",
      "Epoch 183/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8752 - loss: 0.3199 - val_accuracy: 0.8535 - val_loss: 0.4448\n",
      "Epoch 184/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8775 - loss: 0.3222 - val_accuracy: 0.8542 - val_loss: 0.4349\n",
      "Epoch 185/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8762 - loss: 0.3366 - val_accuracy: 0.8636 - val_loss: 0.4259\n",
      "Epoch 186/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8796 - loss: 0.3218 - val_accuracy: 0.8683 - val_loss: 0.4205\n",
      "Epoch 187/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8790 - loss: 0.3168 - val_accuracy: 0.8676 - val_loss: 0.4146\n",
      "Epoch 188/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8731 - loss: 0.3296 - val_accuracy: 0.8582 - val_loss: 0.4310\n",
      "Epoch 189/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8812 - loss: 0.3298 - val_accuracy: 0.8454 - val_loss: 0.4533\n",
      "Epoch 190/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8683 - loss: 0.3451 - val_accuracy: 0.8730 - val_loss: 0.4119\n",
      "Epoch 191/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8848 - loss: 0.3280 - val_accuracy: 0.8683 - val_loss: 0.4162\n",
      "Epoch 192/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8842 - loss: 0.3015 - val_accuracy: 0.8629 - val_loss: 0.4468\n",
      "Epoch 193/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8804 - loss: 0.3184 - val_accuracy: 0.8649 - val_loss: 0.4423\n",
      "Epoch 194/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8820 - loss: 0.3122 - val_accuracy: 0.8696 - val_loss: 0.4204\n",
      "Epoch 195/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8799 - loss: 0.3228 - val_accuracy: 0.8683 - val_loss: 0.4173\n",
      "Epoch 196/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8787 - loss: 0.3177 - val_accuracy: 0.8710 - val_loss: 0.3984\n",
      "Epoch 197/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8765 - loss: 0.3090 - val_accuracy: 0.8737 - val_loss: 0.3934\n",
      "Epoch 198/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8737 - loss: 0.3360 - val_accuracy: 0.8690 - val_loss: 0.4331\n",
      "Epoch 199/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8785 - loss: 0.3225 - val_accuracy: 0.8730 - val_loss: 0.3957\n",
      "Epoch 200/200\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.8813 - loss: 0.3155 - val_accuracy: 0.8548 - val_loss: 0.4322\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step\n",
      "\n",
      "Classification Report for CNN (Single Lead):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          sb    0.91098   0.93830   0.92444      1167\n",
      "        gsvt    0.87273   0.76522   0.81544       690\n",
      "          sr    0.81898   0.84108   0.82988       667\n",
      "        afib    0.78192   0.81955   0.80029       665\n",
      "\n",
      "    accuracy                        0.85575      3189\n",
      "   macro avg    0.84615   0.84104   0.84252      3189\n",
      "weighted avg    0.85655   0.85575   0.85519      3189\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
