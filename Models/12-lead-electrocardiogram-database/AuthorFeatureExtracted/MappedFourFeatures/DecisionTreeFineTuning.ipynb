{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.201558Z",
     "start_time": "2025-01-07T17:41:20.670283Z"
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Diagnostics.xlsx data\n",
    "diagnostics_file = \"../../../../Datasets/12-lead electrocardiogram database/Diagnostics.xlsx\"\n",
    "diagnostics_df = pd.read_excel(diagnostics_file)\n",
    "\n",
    "# Rename \"SA\" to \"SI\" in the \"Rhythm\" column\n",
    "diagnostics_df[\"Rhythm\"] = diagnostics_df[\"Rhythm\"].replace(\"SA\", \"SI\")\n",
    "\n",
    "# Drop rows with any missing values\n",
    "diagnostics_df = diagnostics_df.dropna()\n",
    "\n",
    "# Encode \"Gender\" column: 0 for \"MALE\" and 1 for \"FEMALE\"\n",
    "diagnostics_df[\"Gender\"] = diagnostics_df[\"Gender\"].map({\"MALE\": 0, \"FEMALE\": 1})\n",
    "\n",
    "# Merge specified labels\n",
    "merge_mapping = {\n",
    "    \"AF\": \"AFIB\", \"AFIB\": \"AFIB\",\n",
    "    \"SVT\": \"GSVT\", \"AT\": \"GSVT\", \"SAAWR\": \"GSVT\", \"ST\": \"GSVT\", \"AVNRT\": \"GSVT\", \"AVRT\": \"GSVT\",\n",
    "    \"SB\": \"SB\",\n",
    "    \"SR\": \"SR\", \"SI\": \"SR\"\n",
    "}\n",
    "diagnostics_df[\"Rhythm\"] = diagnostics_df[\"Rhythm\"].map(merge_mapping)\n",
    "\n",
    "# Separate features and labels\n",
    "features = diagnostics_df.drop(columns=[\"FileName\", \"Rhythm\", \"Beat\"]).values\n",
    "labels = diagnostics_df[\"Rhythm\"].values  # Using \"Rhythm\" as the target variable\n",
    "\n",
    "# Convert features to float32\n",
    "features = features.astype(\"float32\")\n",
    "\n",
    "# Encode labels as one-hot with merged classes\n",
    "unique_labels = np.unique(labels)\n",
    "label_map = {label: index for index, label in enumerate(unique_labels)}\n",
    "labels_encoded = np.array([label_map[label] for label in labels])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save X_test to a file\n",
    "np.savetxt(\"X_test.txt\", X_test, fmt='%f', delimiter=' ')\n",
    "\n",
    "# Save y_test to a separate file\n",
    "np.savetxt(\"y_test.txt\", y_test, fmt='%d')  # Use '%d' if y_test contains integers"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.213114Z",
     "start_time": "2025-01-07T17:41:22.209933Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_test[1])",
   "id": "c515d459fd66a3cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 68.   0.  67. 250.  76. 482. 509.  75.  82.  11. 219. 257. 460.]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.336091Z",
     "start_time": "2025-01-07T17:41:22.260115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))"
   ],
   "id": "61a4ead506f4fd5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79352   0.81328   0.80328       482\n",
      "          SB    0.97823   0.98327   0.98074       777\n",
      "          SR    0.88009   0.87025   0.87514       447\n",
      "\n",
      "    accuracy                        0.85915      2130\n",
      "   macro avg    0.83548   0.83474   0.83504      2130\n",
      "weighted avg    0.85848   0.85915   0.85876      2130\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.348505Z",
     "start_time": "2025-01-07T17:41:22.345822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "a94d4057c2fb42da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "689\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.441446Z",
     "start_time": "2025-01-07T17:41:22.389436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "4802071b9e8a4a38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.68916   0.67453   0.68176       424\n",
      "        GSVT    0.80285   0.81950   0.81109       482\n",
      "          SB    0.97695   0.98198   0.97946       777\n",
      "          SR    0.87783   0.86801   0.87289       447\n",
      "\n",
      "    accuracy                        0.86009      2130\n",
      "   macro avg    0.83670   0.83601   0.83630      2130\n",
      "weighted avg    0.85946   0.86009   0.85974      2130\n",
      "\n",
      "24\n",
      "684\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.500390Z",
     "start_time": "2025-01-07T17:41:22.449789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "e91a85e497a616ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.68916   0.67453   0.68176       424\n",
      "        GSVT    0.80285   0.81950   0.81109       482\n",
      "          SB    0.97695   0.98198   0.97946       777\n",
      "          SR    0.87783   0.86801   0.87289       447\n",
      "\n",
      "    accuracy                        0.86009      2130\n",
      "   macro avg    0.83670   0.83601   0.83630      2130\n",
      "weighted avg    0.85946   0.86009   0.85974      2130\n",
      "\n",
      "24\n",
      "684\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.553571Z",
     "start_time": "2025-01-07T17:41:22.508067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "ca60df3365fc055c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69668   0.69340   0.69504       424\n",
      "        GSVT    0.81481   0.82158   0.81818       482\n",
      "          SB    0.97698   0.98327   0.98012       777\n",
      "          SR    0.88636   0.87248   0.87937       447\n",
      "\n",
      "    accuracy                        0.86573      2130\n",
      "   macro avg    0.84371   0.84268   0.84318      2130\n",
      "weighted avg    0.86547   0.86573   0.86558      2130\n",
      "\n",
      "24\n",
      "600\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.602008Z",
     "start_time": "2025-01-07T17:41:22.561372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "4681bff9f38fd52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72236   0.69340   0.70758       424\n",
      "        GSVT    0.82136   0.82988   0.82559       482\n",
      "          SB    0.97832   0.98713   0.98270       777\n",
      "          SR    0.88938   0.89933   0.89433       447\n",
      "\n",
      "    accuracy                        0.87465      2130\n",
      "   macro avg    0.85285   0.85243   0.85255      2130\n",
      "weighted avg    0.87318   0.87465   0.87384      2130\n",
      "\n",
      "23\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.645784Z",
     "start_time": "2025-01-07T17:41:22.609812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=24, max_leaf_nodes=200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "2161589aa5a1fd4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73012   0.71462   0.72229       424\n",
      "        GSVT    0.84906   0.84025   0.84463       482\n",
      "          SB    0.97821   0.98198   0.98009       777\n",
      "          SR    0.89083   0.91275   0.90166       447\n",
      "\n",
      "    accuracy                        0.88216      2130\n",
      "   macro avg    0.86205   0.86240   0.86217      2130\n",
      "weighted avg    0.88126   0.88216   0.88166      2130\n",
      "\n",
      "20\n",
      "200\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.705781Z",
     "start_time": "2025-01-07T17:41:22.654887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "9bb2b2511246651d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79878   0.81535   0.80698       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.88435   0.87248   0.87838       447\n",
      "\n",
      "    accuracy                        0.86056      2130\n",
      "   macro avg    0.83724   0.83614   0.83663      2130\n",
      "weighted avg    0.85966   0.86056   0.86005      2130\n",
      "\n",
      "20\n",
      "654\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.765040Z",
     "start_time": "2025-01-07T17:41:22.713881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n"
   ],
   "id": "1741a758262bdf26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79878   0.81535   0.80698       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.88435   0.87248   0.87838       447\n",
      "\n",
      "    accuracy                        0.86056      2130\n",
      "   macro avg    0.83724   0.83614   0.83663      2130\n",
      "weighted avg    0.85966   0.86056   0.86005      2130\n",
      "\n",
      "20\n",
      "654\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.831434Z",
     "start_time": "2025-01-07T17:41:22.780279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "696991a524d3d5e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69007   0.67217   0.68100       424\n",
      "        GSVT    0.79878   0.81535   0.80698       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.88435   0.87248   0.87838       447\n",
      "\n",
      "    accuracy                        0.86056      2130\n",
      "   macro avg    0.83724   0.83614   0.83663      2130\n",
      "weighted avg    0.85966   0.86056   0.86005      2130\n",
      "\n",
      "20\n",
      "654\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.888247Z",
     "start_time": "2025-01-07T17:41:22.840499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n"
   ],
   "id": "6f3c57911f403807",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80041   0.81535   0.80781       482\n",
      "          SB    0.97577   0.98456   0.98014       777\n",
      "          SR    0.89066   0.87472   0.88262       447\n",
      "\n",
      "    accuracy                        0.86244      2130\n",
      "   macro avg    0.83979   0.83847   0.83907      2130\n",
      "weighted avg    0.86180   0.86244   0.86207      2130\n",
      "\n",
      "20\n",
      "600\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:22.941628Z",
     "start_time": "2025-01-07T17:41:22.900086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=20, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "32b49e1c81ca4e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.71776   0.69575   0.70659       424\n",
      "        GSVT    0.82062   0.82573   0.82316       482\n",
      "          SB    0.97832   0.98713   0.98270       777\n",
      "          SR    0.89333   0.89933   0.89632       447\n",
      "\n",
      "    accuracy                        0.87418      2130\n",
      "   macro avg    0.85251   0.85198   0.85219      2130\n",
      "weighted avg    0.87293   0.87418   0.87351      2130\n",
      "\n",
      "20\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:23.186209Z",
     "start_time": "2025-01-07T17:41:22.952621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=18, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "7565f26f75b40bf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "617\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "617\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "617\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.69231   0.67925   0.68571       424\n",
      "        GSVT    0.80287   0.81120   0.80702       482\n",
      "          SB    0.97946   0.98198   0.98072       777\n",
      "          SR    0.87723   0.87919   0.87821       447\n",
      "\n",
      "    accuracy                        0.86150      2130\n",
      "   macro avg    0.83797   0.83791   0.83792      2130\n",
      "weighted avg    0.86089   0.86150   0.86118      2130\n",
      "\n",
      "18\n",
      "600\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.71566   0.70047   0.70799       424\n",
      "        GSVT    0.81875   0.81535   0.81705       482\n",
      "          SB    0.97957   0.98713   0.98333       777\n",
      "          SR    0.88938   0.89933   0.89433       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.85084   0.85057   0.85067      2130\n",
      "weighted avg    0.87172   0.87277   0.87221      2130\n",
      "\n",
      "18\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:23.428221Z",
     "start_time": "2025-01-07T17:41:23.195824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=16, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "7c9d16908dd09a60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.70660   0.68160   0.69388       424\n",
      "        GSVT    0.80453   0.81120   0.80785       482\n",
      "          SB    0.98072   0.98198   0.98135       777\n",
      "          SR    0.87965   0.89933   0.88938       447\n",
      "\n",
      "    accuracy                        0.86620      2130\n",
      "   macro avg    0.84287   0.84353   0.84311      2130\n",
      "weighted avg    0.86507   0.86620   0.86556      2130\n",
      "\n",
      "16\n",
      "559\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72222   0.70519   0.71360       424\n",
      "        GSVT    0.82947   0.81743   0.82341       482\n",
      "          SB    0.97954   0.98584   0.98268       777\n",
      "          SR    0.89325   0.91723   0.90508       447\n",
      "\n",
      "    accuracy                        0.87746      2130\n",
      "   macro avg    0.85612   0.85642   0.85619      2130\n",
      "weighted avg    0.87625   0.87746   0.87679      2130\n",
      "\n",
      "16\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:23.660022Z",
     "start_time": "2025-01-07T17:41:23.436620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=14, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "b15849f97c68e638",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.72449   0.66981   0.69608       424\n",
      "        GSVT    0.82121   0.81950   0.82035       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.87898   0.92617   0.90196       447\n",
      "\n",
      "    accuracy                        0.87277      2130\n",
      "   macro avg    0.84981   0.85033   0.84964      2130\n",
      "weighted avg    0.87002   0.87277   0.87104      2130\n",
      "\n",
      "14\n",
      "478\n",
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73183   0.68868   0.70960       424\n",
      "        GSVT    0.82672   0.82158   0.82414       482\n",
      "          SB    0.97455   0.98584   0.98017       777\n",
      "          SR    0.88841   0.92617   0.90690       447\n",
      "\n",
      "    accuracy                        0.87700      2130\n",
      "   macro avg    0.85538   0.85557   0.85520      2130\n",
      "weighted avg    0.87471   0.87700   0.87562      2130\n",
      "\n",
      "14\n",
      "400\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=1200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=1000)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=800)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=600)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=400)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=200)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=100)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=12, max_leaf_nodes=50)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))\n",
    "print(dt_classifier.get_depth())\n",
    "print(dt_classifier.get_n_leaves())"
   ],
   "id": "1806803ac0a5786a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
