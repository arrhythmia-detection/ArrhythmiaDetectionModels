{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:39:17.030070Z",
     "start_time": "2024-11-25T21:39:14.502270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "# noinspection PyUnresolvedReferences\n",
    "from tensorflow.keras.models import Sequential\n",
    "# noinspection PyUnresolvedReferences\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Constants\n",
    "ecg_folder = \"../../../../Datasets/12-lead electrocardiogram database/ECGData\"\n",
    "diagnostics_file = \"../../../../Datasets/12-lead electrocardiogram database/Diagnostics.xlsx\"\n",
    "\n",
    "# Label mapping\n",
    "rhythm_mapping = {\n",
    "    'AFIB': 'AFIB',\n",
    "    'AF': 'AFIB',\n",
    "    'SVT': 'GSVT',\n",
    "    'AT': 'GSVT',\n",
    "    'SAAWR': 'GSVT',\n",
    "    'ST': 'GSVT',\n",
    "    'AVNRT': 'GSVT',\n",
    "    'AVRT': 'GSVT',\n",
    "    'SB': 'SB',\n",
    "    'SR': 'SR',\n",
    "    'SA': 'SR'\n",
    "}\n",
    "\n",
    "# Load diagnostics data\n",
    "diagnostics_df = pd.read_excel(diagnostics_file)\n",
    "diagnostics_df['Rhythm'] = diagnostics_df['Rhythm'].map(rhythm_mapping)"
   ],
   "id": "7abfed95cfee07a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 03:39:15.058041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-26 03:39:15.068935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-26 03:39:15.072281: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-26 03:39:15.081394: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 03:39:15.614193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:39:17.048073Z",
     "start_time": "2024-11-25T21:39:17.038632Z"
    }
   },
   "cell_type": "code",
   "source": "diagnostics_df",
   "id": "533d3ceac7ff1561",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         FileName Rhythm       Beat  PatientAge  Gender  \\\n",
       "0      MUSE_20180113_171327_27000   AFIB   RBBB TWC          85    MALE   \n",
       "1      MUSE_20180112_073319_29000     SB        TWC          59  FEMALE   \n",
       "2      MUSE_20180111_165520_97000     SR       NONE          20  FEMALE   \n",
       "3      MUSE_20180113_121940_44000     SB       NONE          66    MALE   \n",
       "4      MUSE_20180112_122850_57000   AFIB  STDD STTC          73  FEMALE   \n",
       "...                           ...    ...        ...         ...     ...   \n",
       "10641  MUSE_20181222_204306_99000   GSVT       NONE          80  FEMALE   \n",
       "10642  MUSE_20181222_204309_22000   GSVT       NONE          81  FEMALE   \n",
       "10643  MUSE_20181222_204310_31000   GSVT       NONE          39    MALE   \n",
       "10644  MUSE_20181222_204312_58000   GSVT       NONE          76    MALE   \n",
       "10645  MUSE_20181222_204314_78000   GSVT       NONE          75    MALE   \n",
       "\n",
       "       VentricularRate  AtrialRate  QRSDuration  QTInterval  QTCorrected  \\\n",
       "0                  117         234          114         356          496   \n",
       "1                   52          52           92         432          401   \n",
       "2                   67          67           82         382          403   \n",
       "3                   53          53           96         456          427   \n",
       "4                  162         162          114         252          413   \n",
       "...                ...         ...          ...         ...          ...   \n",
       "10641              196          73          168         284          513   \n",
       "10642              162          81          162         294          482   \n",
       "10643              152          92          152         340          540   \n",
       "10644              175         178          128         310          529   \n",
       "10645              117         104          140         312          435   \n",
       "\n",
       "       RAxis  TAxis  QRSCount  QOnset  QOffset  TOffset  \n",
       "0         81    -27        19     208      265      386  \n",
       "1         76     42         8     215      261      431  \n",
       "2         88     20        11     224      265      415  \n",
       "3         34      3         9     219      267      447  \n",
       "4         68    -40        26     228      285      354  \n",
       "...      ...    ...       ...     ...      ...      ...  \n",
       "10641    258    244        32     177      261      319  \n",
       "10642    110    -75        27     173      254      320  \n",
       "10643    250     38        25     208      284      378  \n",
       "10644     98    -83        29     205      269      360  \n",
       "10645    263    144        19     208      278      364  \n",
       "\n",
       "[10646 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Beat</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>Gender</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>RAxis</th>\n",
       "      <th>TAxis</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QOnset</th>\n",
       "      <th>QOffset</th>\n",
       "      <th>TOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_27000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>RBBB TWC</td>\n",
       "      <td>85</td>\n",
       "      <td>MALE</td>\n",
       "      <td>117</td>\n",
       "      <td>234</td>\n",
       "      <td>114</td>\n",
       "      <td>356</td>\n",
       "      <td>496</td>\n",
       "      <td>81</td>\n",
       "      <td>-27</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>265</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_29000</td>\n",
       "      <td>SB</td>\n",
       "      <td>TWC</td>\n",
       "      <td>59</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>92</td>\n",
       "      <td>432</td>\n",
       "      <td>401</td>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>215</td>\n",
       "      <td>261</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180111_165520_97000</td>\n",
       "      <td>SR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>20</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>382</td>\n",
       "      <td>403</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>224</td>\n",
       "      <td>265</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180113_121940_44000</td>\n",
       "      <td>SB</td>\n",
       "      <td>NONE</td>\n",
       "      <td>66</td>\n",
       "      <td>MALE</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>96</td>\n",
       "      <td>456</td>\n",
       "      <td>427</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>219</td>\n",
       "      <td>267</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180112_122850_57000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>STDD STTC</td>\n",
       "      <td>73</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>114</td>\n",
       "      <td>252</td>\n",
       "      <td>413</td>\n",
       "      <td>68</td>\n",
       "      <td>-40</td>\n",
       "      <td>26</td>\n",
       "      <td>228</td>\n",
       "      <td>285</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>MUSE_20181222_204306_99000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>80</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>196</td>\n",
       "      <td>73</td>\n",
       "      <td>168</td>\n",
       "      <td>284</td>\n",
       "      <td>513</td>\n",
       "      <td>258</td>\n",
       "      <td>244</td>\n",
       "      <td>32</td>\n",
       "      <td>177</td>\n",
       "      <td>261</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10642</th>\n",
       "      <td>MUSE_20181222_204309_22000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>81</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>162</td>\n",
       "      <td>81</td>\n",
       "      <td>162</td>\n",
       "      <td>294</td>\n",
       "      <td>482</td>\n",
       "      <td>110</td>\n",
       "      <td>-75</td>\n",
       "      <td>27</td>\n",
       "      <td>173</td>\n",
       "      <td>254</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>MUSE_20181222_204310_31000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>39</td>\n",
       "      <td>MALE</td>\n",
       "      <td>152</td>\n",
       "      <td>92</td>\n",
       "      <td>152</td>\n",
       "      <td>340</td>\n",
       "      <td>540</td>\n",
       "      <td>250</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>208</td>\n",
       "      <td>284</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10644</th>\n",
       "      <td>MUSE_20181222_204312_58000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>76</td>\n",
       "      <td>MALE</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>128</td>\n",
       "      <td>310</td>\n",
       "      <td>529</td>\n",
       "      <td>98</td>\n",
       "      <td>-83</td>\n",
       "      <td>29</td>\n",
       "      <td>205</td>\n",
       "      <td>269</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10645</th>\n",
       "      <td>MUSE_20181222_204314_78000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>75</td>\n",
       "      <td>MALE</td>\n",
       "      <td>117</td>\n",
       "      <td>104</td>\n",
       "      <td>140</td>\n",
       "      <td>312</td>\n",
       "      <td>435</td>\n",
       "      <td>263</td>\n",
       "      <td>144</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>278</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10646 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:39:17.112686Z",
     "start_time": "2024-11-25T21:39:17.108935Z"
    }
   },
   "cell_type": "code",
   "source": "diagnostics_df = diagnostics_df.dropna(subset=['Rhythm'])  # Drop unmapped rows",
   "id": "12f58ac573c09420",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:39:17.158695Z",
     "start_time": "2024-11-25T21:39:17.151260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define functions for preprocessing and feature extraction\n",
    "def preprocess_signal(signal: np.ndarray, sampling_rate: int = 500) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess ECG signal with filtering and normalization\n",
    "    \"\"\"\n",
    "    nyquist = sampling_rate / 2\n",
    "    low = 0.5 / nyquist\n",
    "    high = 45 / nyquist\n",
    "    b, a = butter(2, [low, high], btype='band')\n",
    "    filtered = filtfilt(b, a, signal)\n",
    "    normalized = (filtered - np.mean(filtered)) / np.std(filtered)\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def detect_r_peaks(signal: np.ndarray, sampling_rate: int = 500) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect R-peaks in the signal using find_peaks\n",
    "    \"\"\"\n",
    "    peaks, _ = find_peaks(signal, distance=sampling_rate // 2, height=0.5)  # Adjust threshold as needed\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def extract_features(signal: np.ndarray, sampling_rate: int = 500) -> dict:\n",
    "    \"\"\"\n",
    "    Extract features from the ECG signal\n",
    "    \"\"\"\n",
    "    r_peaks = detect_r_peaks(signal, sampling_rate)\n",
    "    rr_intervals = np.diff(r_peaks) / sampling_rate  # Convert to seconds\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Basic RR interval-based features\n",
    "    features['ventricular_rate'] = 60 / np.mean(rr_intervals) if len(rr_intervals) > 0 else 0\n",
    "    features['mean_rr_interval'] = np.mean(rr_intervals) if len(rr_intervals) > 0 else 0\n",
    "    features['variance_rr_interval'] = np.var(rr_intervals) if len(rr_intervals) > 0 else 0\n",
    "    features['qrs_count'] = len(r_peaks)\n",
    "    features['rr_interval_count'] = len(rr_intervals)\n",
    "\n",
    "    # QRS Duration\n",
    "    qrs_durations = []\n",
    "    for i, r_peak in enumerate(r_peaks):\n",
    "        # Look for the Q and S points around the R peak\n",
    "        left_idx = max(0, r_peak - int(0.1 * sampling_rate))  # 100 ms window before\n",
    "        right_idx = min(len(signal), r_peak + int(0.1 * sampling_rate))  # 100 ms window after\n",
    "        segment = signal[left_idx:right_idx]\n",
    "\n",
    "        if len(segment) > 1:\n",
    "            # Approximate QRS width as the duration of the segment above a threshold\n",
    "            threshold = 0.5 * np.max(segment)  # 50% of the max amplitude\n",
    "            significant_points = np.where(segment > threshold)[0]\n",
    "            if len(significant_points) > 1:\n",
    "                qrs_duration = (significant_points[-1] - significant_points[0]) / sampling_rate\n",
    "                qrs_durations.append(qrs_duration)\n",
    "\n",
    "    features['qrs_duration'] = np.mean(qrs_durations) if len(qrs_durations) > 0 else 0.1\n",
    "\n",
    "    # QT Interval\n",
    "    qt_intervals = []\n",
    "    for i, r_peak in enumerate(r_peaks):\n",
    "        # Approximate T wave as a prominent feature after the R peak\n",
    "        left_idx = r_peak\n",
    "        right_idx = min(len(signal), r_peak + int(0.4 * sampling_rate))  # Up to 400 ms after R peak\n",
    "        segment = signal[left_idx:right_idx]\n",
    "\n",
    "        if len(segment) > 1:\n",
    "            # Find the max point (T peak) and use it to approximate QT interval\n",
    "            t_peak_idx = np.argmax(segment)\n",
    "            qt_interval = (t_peak_idx + left_idx - r_peak) / sampling_rate\n",
    "            qt_intervals.append(qt_interval)\n",
    "\n",
    "    features['qt_interval'] = np.mean(qt_intervals) if len(qt_intervals) > 0 else 0.35\n",
    "\n",
    "    # R and T Axes (Placeholder, lead-specific calculations)\n",
    "    features['r_axis'] = np.sum(signal[r_peaks])  # Sum of R peak amplitudes as a proxy\n",
    "    features['t_axis'] = np.mean(signal[r_peaks])  # Mean T wave amplitude as a proxy\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def load_and_extract_features(ecg_folder: str, diagnostics_df: pd.DataFrame, selected_leads: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ECG signals and extract features\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, row in tqdm(diagnostics_df.iterrows(), total=len(diagnostics_df), desc=\"Processing ECG files\"):\n",
    "        file_path = os.path.join(ecg_folder, f\"{row['FileName']}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                signal = pd.read_csv(file_path).values[:, selected_leads - 1]  # Extract selected lead\n",
    "                signal = preprocess_signal(signal)\n",
    "                features = extract_features(signal)\n",
    "                feature_list.append(features)\n",
    "                labels.append(row['Rhythm'])  # Assuming 'Rhythm' column contains target labels\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    features_df = pd.DataFrame(feature_list)\n",
    "    features_df['label'] = labels\n",
    "    return features_df\n"
   ],
   "id": "daa6294b0a0add62",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:40:16.504806Z",
     "start_time": "2024-11-25T21:39:17.183353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data and extract features\n",
    "features_df = load_and_extract_features(ecg_folder, diagnostics_df)\n",
    "\n",
    "features_df"
   ],
   "id": "f1ea098fe2a85cbd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ECG files: 100%|██████████| 10646/10646 [00:59<00:00, 179.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       ventricular_rate  mean_rr_interval  variance_rr_interval  qrs_count  \\\n",
       "0             91.145833          0.658286              0.020302         15   \n",
       "1             53.499777          1.121500              0.011444          9   \n",
       "2             67.803575          0.884909              0.010797         12   \n",
       "3             53.309640          1.125500              0.000257          9   \n",
       "4             81.081081          0.740000              0.032294         14   \n",
       "...                 ...               ...                   ...        ...   \n",
       "10641         82.122552          0.730615              0.027474         14   \n",
       "10642         64.864865          0.925000              0.090102         11   \n",
       "10643         85.089141          0.705143              0.009654         15   \n",
       "10644         68.550062          0.875273              0.029908         12   \n",
       "10645        116.635973          0.514421              0.000029         20   \n",
       "\n",
       "       rr_interval_count  qrs_duration  qt_interval     r_axis    t_axis label  \n",
       "0                     14      0.068667     0.017333  32.343690  2.156246  AFIB  \n",
       "1                      8      0.027556     0.000000  56.863504  6.318167    SB  \n",
       "2                     11      0.085500     0.000000  30.735576  2.561298    SR  \n",
       "3                      8      0.022667     0.000000  57.205732  6.356192    SB  \n",
       "4                     13      0.022000     0.129857  49.035667  3.502548  AFIB  \n",
       "...                  ...           ...          ...        ...       ...   ...  \n",
       "10641                 13      0.098857     0.050000  22.607509  1.614822  GSVT  \n",
       "10642                 10      0.137455     0.072364  14.568783  1.324435  GSVT  \n",
       "10643                 14      0.068133     0.120533  21.165194  1.411013  GSVT  \n",
       "10644                 11      0.079167     0.029333  18.627008  1.552251  GSVT  \n",
       "10645                 19      0.066700     0.019900  25.515046  1.275752  GSVT  \n",
       "\n",
       "[10646 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ventricular_rate</th>\n",
       "      <th>mean_rr_interval</th>\n",
       "      <th>variance_rr_interval</th>\n",
       "      <th>qrs_count</th>\n",
       "      <th>rr_interval_count</th>\n",
       "      <th>qrs_duration</th>\n",
       "      <th>qt_interval</th>\n",
       "      <th>r_axis</th>\n",
       "      <th>t_axis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.145833</td>\n",
       "      <td>0.658286</td>\n",
       "      <td>0.020302</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>32.343690</td>\n",
       "      <td>2.156246</td>\n",
       "      <td>AFIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.499777</td>\n",
       "      <td>1.121500</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.863504</td>\n",
       "      <td>6.318167</td>\n",
       "      <td>SB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.803575</td>\n",
       "      <td>0.884909</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.735576</td>\n",
       "      <td>2.561298</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.309640</td>\n",
       "      <td>1.125500</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.205732</td>\n",
       "      <td>6.356192</td>\n",
       "      <td>SB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.081081</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.032294</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.129857</td>\n",
       "      <td>49.035667</td>\n",
       "      <td>3.502548</td>\n",
       "      <td>AFIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>82.122552</td>\n",
       "      <td>0.730615</td>\n",
       "      <td>0.027474</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>22.607509</td>\n",
       "      <td>1.614822</td>\n",
       "      <td>GSVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10642</th>\n",
       "      <td>64.864865</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.090102</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.137455</td>\n",
       "      <td>0.072364</td>\n",
       "      <td>14.568783</td>\n",
       "      <td>1.324435</td>\n",
       "      <td>GSVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>85.089141</td>\n",
       "      <td>0.705143</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0.068133</td>\n",
       "      <td>0.120533</td>\n",
       "      <td>21.165194</td>\n",
       "      <td>1.411013</td>\n",
       "      <td>GSVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10644</th>\n",
       "      <td>68.550062</td>\n",
       "      <td>0.875273</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>18.627008</td>\n",
       "      <td>1.552251</td>\n",
       "      <td>GSVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10645</th>\n",
       "      <td>116.635973</td>\n",
       "      <td>0.514421</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>25.515046</td>\n",
       "      <td>1.275752</td>\n",
       "      <td>GSVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10646 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:40:16.681672Z",
     "start_time": "2024-11-25T21:40:16.674543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "features_df['label'] = le.fit_transform(features_df['label'])\n",
    "features_df"
   ],
   "id": "dec32afc20042da5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       ventricular_rate  mean_rr_interval  variance_rr_interval  qrs_count  \\\n",
       "0             91.145833          0.658286              0.020302         15   \n",
       "1             53.499777          1.121500              0.011444          9   \n",
       "2             67.803575          0.884909              0.010797         12   \n",
       "3             53.309640          1.125500              0.000257          9   \n",
       "4             81.081081          0.740000              0.032294         14   \n",
       "...                 ...               ...                   ...        ...   \n",
       "10641         82.122552          0.730615              0.027474         14   \n",
       "10642         64.864865          0.925000              0.090102         11   \n",
       "10643         85.089141          0.705143              0.009654         15   \n",
       "10644         68.550062          0.875273              0.029908         12   \n",
       "10645        116.635973          0.514421              0.000029         20   \n",
       "\n",
       "       rr_interval_count  qrs_duration  qt_interval     r_axis    t_axis  \\\n",
       "0                     14      0.068667     0.017333  32.343690  2.156246   \n",
       "1                      8      0.027556     0.000000  56.863504  6.318167   \n",
       "2                     11      0.085500     0.000000  30.735576  2.561298   \n",
       "3                      8      0.022667     0.000000  57.205732  6.356192   \n",
       "4                     13      0.022000     0.129857  49.035667  3.502548   \n",
       "...                  ...           ...          ...        ...       ...   \n",
       "10641                 13      0.098857     0.050000  22.607509  1.614822   \n",
       "10642                 10      0.137455     0.072364  14.568783  1.324435   \n",
       "10643                 14      0.068133     0.120533  21.165194  1.411013   \n",
       "10644                 11      0.079167     0.029333  18.627008  1.552251   \n",
       "10645                 19      0.066700     0.019900  25.515046  1.275752   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          2  \n",
       "2          3  \n",
       "3          2  \n",
       "4          0  \n",
       "...      ...  \n",
       "10641      1  \n",
       "10642      1  \n",
       "10643      1  \n",
       "10644      1  \n",
       "10645      1  \n",
       "\n",
       "[10646 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ventricular_rate</th>\n",
       "      <th>mean_rr_interval</th>\n",
       "      <th>variance_rr_interval</th>\n",
       "      <th>qrs_count</th>\n",
       "      <th>rr_interval_count</th>\n",
       "      <th>qrs_duration</th>\n",
       "      <th>qt_interval</th>\n",
       "      <th>r_axis</th>\n",
       "      <th>t_axis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.145833</td>\n",
       "      <td>0.658286</td>\n",
       "      <td>0.020302</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>32.343690</td>\n",
       "      <td>2.156246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.499777</td>\n",
       "      <td>1.121500</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.863504</td>\n",
       "      <td>6.318167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.803575</td>\n",
       "      <td>0.884909</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.735576</td>\n",
       "      <td>2.561298</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.309640</td>\n",
       "      <td>1.125500</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.205732</td>\n",
       "      <td>6.356192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.081081</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.032294</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.129857</td>\n",
       "      <td>49.035667</td>\n",
       "      <td>3.502548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>82.122552</td>\n",
       "      <td>0.730615</td>\n",
       "      <td>0.027474</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>22.607509</td>\n",
       "      <td>1.614822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10642</th>\n",
       "      <td>64.864865</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.090102</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.137455</td>\n",
       "      <td>0.072364</td>\n",
       "      <td>14.568783</td>\n",
       "      <td>1.324435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>85.089141</td>\n",
       "      <td>0.705143</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0.068133</td>\n",
       "      <td>0.120533</td>\n",
       "      <td>21.165194</td>\n",
       "      <td>1.411013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10644</th>\n",
       "      <td>68.550062</td>\n",
       "      <td>0.875273</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>18.627008</td>\n",
       "      <td>1.552251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10645</th>\n",
       "      <td>116.635973</td>\n",
       "      <td>0.514421</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>25.515046</td>\n",
       "      <td>1.275752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10646 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:40:16.728433Z",
     "start_time": "2024-11-25T21:40:16.722931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data\n",
    "X = features_df.drop(columns=['label'])\n",
    "y = features_df['label']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ],
   "id": "1d1b4aefe6a58e20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8516, 9) (2130, 9) (8516,) (2130,)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:40:37.678950Z",
     "start_time": "2024-11-25T21:40:16.832553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_mlp_model(input_dim, num_classes):\n",
    "    mlp = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "mlp_model = create_mlp_model(X_train.shape[1], num_classes)\n",
    "\n",
    "# Train MLP\n",
    "mlp_model.fit(X_train, y_train, epochs=150, batch_size=128, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate MLP\n",
    "mlp_loss, mlp_accuracy = mlp_model.evaluate(X_test, y_test, verbose=0)\n",
    "mlp_y_pred = np.argmax(mlp_model.predict(X_test), axis=1)\n",
    "\n",
    "print(\"\\nTensorFlow MLP Classifier Results\")\n",
    "print(f\"Accuracy: {mlp_accuracy:.4f}\")\n",
    "print(classification_report(y_test, mlp_y_pred, target_names=le.classes_, digits=5))\n"
   ],
   "id": "dad41bace545817e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732570817.041528  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.073748  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.074992  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.077458  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.078648  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.079718  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.176317  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.177444  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732570817.178629  254178 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-26 03:40:17.179714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5673 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732570817.792824  254888 service.cc:146] XLA service 0x7522a800c550 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732570817.792858  254888 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-26 03:40:17.818017: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-26 03:40:17.898337: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m47/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4515 - loss: 1.1814 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732570818.973103  254888 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 64ms/step - accuracy: 0.4694 - loss: 1.1505 - val_accuracy: 0.7424 - val_loss: 0.7000\n",
      "Epoch 2/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7607 - loss: 0.6619 - val_accuracy: 0.7917 - val_loss: 0.5500\n",
      "Epoch 3/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7992 - loss: 0.5585 - val_accuracy: 0.8181 - val_loss: 0.4869\n",
      "Epoch 4/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8173 - loss: 0.5087 - val_accuracy: 0.8357 - val_loss: 0.4635\n",
      "Epoch 5/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8135 - loss: 0.5098 - val_accuracy: 0.8363 - val_loss: 0.4555\n",
      "Epoch 6/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8253 - loss: 0.4913 - val_accuracy: 0.8292 - val_loss: 0.4524\n",
      "Epoch 7/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8294 - loss: 0.4749 - val_accuracy: 0.8415 - val_loss: 0.4431\n",
      "Epoch 8/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 993us/step - accuracy: 0.8379 - loss: 0.4576 - val_accuracy: 0.8415 - val_loss: 0.4340\n",
      "Epoch 9/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8403 - loss: 0.4549 - val_accuracy: 0.8439 - val_loss: 0.4273\n",
      "Epoch 10/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8427 - loss: 0.4524 - val_accuracy: 0.8480 - val_loss: 0.4214\n",
      "Epoch 11/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8388 - loss: 0.4450 - val_accuracy: 0.8521 - val_loss: 0.4167\n",
      "Epoch 12/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8500 - loss: 0.4160 - val_accuracy: 0.8533 - val_loss: 0.4141\n",
      "Epoch 13/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8410 - loss: 0.4413 - val_accuracy: 0.8509 - val_loss: 0.4117\n",
      "Epoch 14/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8520 - loss: 0.4203 - val_accuracy: 0.8597 - val_loss: 0.4066\n",
      "Epoch 15/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8565 - loss: 0.4050 - val_accuracy: 0.8533 - val_loss: 0.4076\n",
      "Epoch 16/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8510 - loss: 0.4147 - val_accuracy: 0.8568 - val_loss: 0.4057\n",
      "Epoch 17/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8571 - loss: 0.4104 - val_accuracy: 0.8603 - val_loss: 0.4018\n",
      "Epoch 18/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8517 - loss: 0.4191 - val_accuracy: 0.8550 - val_loss: 0.4007\n",
      "Epoch 19/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8569 - loss: 0.4069 - val_accuracy: 0.8586 - val_loss: 0.3959\n",
      "Epoch 20/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8484 - loss: 0.4142 - val_accuracy: 0.8580 - val_loss: 0.3936\n",
      "Epoch 21/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8567 - loss: 0.3931 - val_accuracy: 0.8592 - val_loss: 0.3933\n",
      "Epoch 22/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8663 - loss: 0.3857 - val_accuracy: 0.8656 - val_loss: 0.3904\n",
      "Epoch 23/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8540 - loss: 0.4060 - val_accuracy: 0.8568 - val_loss: 0.3918\n",
      "Epoch 24/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8622 - loss: 0.3941 - val_accuracy: 0.8638 - val_loss: 0.3877\n",
      "Epoch 25/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8610 - loss: 0.3871 - val_accuracy: 0.8656 - val_loss: 0.3868\n",
      "Epoch 26/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8652 - loss: 0.3883 - val_accuracy: 0.8621 - val_loss: 0.3866\n",
      "Epoch 27/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8593 - loss: 0.3949 - val_accuracy: 0.8603 - val_loss: 0.3846\n",
      "Epoch 28/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8651 - loss: 0.3765 - val_accuracy: 0.8633 - val_loss: 0.3857\n",
      "Epoch 29/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8678 - loss: 0.3888 - val_accuracy: 0.8691 - val_loss: 0.3846\n",
      "Epoch 30/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8686 - loss: 0.3793 - val_accuracy: 0.8621 - val_loss: 0.3875\n",
      "Epoch 31/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8656 - loss: 0.3944 - val_accuracy: 0.8668 - val_loss: 0.3801\n",
      "Epoch 32/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8587 - loss: 0.3862 - val_accuracy: 0.8644 - val_loss: 0.3815\n",
      "Epoch 33/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8681 - loss: 0.3747 - val_accuracy: 0.8650 - val_loss: 0.3815\n",
      "Epoch 34/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8633 - loss: 0.3897 - val_accuracy: 0.8644 - val_loss: 0.3800\n",
      "Epoch 35/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8664 - loss: 0.3775 - val_accuracy: 0.8592 - val_loss: 0.3812\n",
      "Epoch 36/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8722 - loss: 0.3757 - val_accuracy: 0.8633 - val_loss: 0.3830\n",
      "Epoch 37/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8652 - loss: 0.3855 - val_accuracy: 0.8633 - val_loss: 0.3784\n",
      "Epoch 38/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8690 - loss: 0.3837 - val_accuracy: 0.8656 - val_loss: 0.3784\n",
      "Epoch 39/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8771 - loss: 0.3634 - val_accuracy: 0.8633 - val_loss: 0.3779\n",
      "Epoch 40/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8631 - loss: 0.3770 - val_accuracy: 0.8615 - val_loss: 0.3788\n",
      "Epoch 41/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8711 - loss: 0.3770 - val_accuracy: 0.8691 - val_loss: 0.3736\n",
      "Epoch 42/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8698 - loss: 0.3591 - val_accuracy: 0.8674 - val_loss: 0.3727\n",
      "Epoch 43/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8656 - loss: 0.3793 - val_accuracy: 0.8674 - val_loss: 0.3726\n",
      "Epoch 44/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8737 - loss: 0.3660 - val_accuracy: 0.8674 - val_loss: 0.3728\n",
      "Epoch 45/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8713 - loss: 0.3679 - val_accuracy: 0.8644 - val_loss: 0.3763\n",
      "Epoch 46/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8708 - loss: 0.3753 - val_accuracy: 0.8674 - val_loss: 0.3724\n",
      "Epoch 47/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8742 - loss: 0.3640 - val_accuracy: 0.8674 - val_loss: 0.3717\n",
      "Epoch 48/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8763 - loss: 0.3608 - val_accuracy: 0.8691 - val_loss: 0.3700\n",
      "Epoch 49/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8715 - loss: 0.3643 - val_accuracy: 0.8656 - val_loss: 0.3741\n",
      "Epoch 50/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8628 - loss: 0.3802 - val_accuracy: 0.8685 - val_loss: 0.3716\n",
      "Epoch 51/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8747 - loss: 0.3591 - val_accuracy: 0.8709 - val_loss: 0.3714\n",
      "Epoch 52/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8686 - loss: 0.3702 - val_accuracy: 0.8680 - val_loss: 0.3749\n",
      "Epoch 53/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8678 - loss: 0.3700 - val_accuracy: 0.8721 - val_loss: 0.3743\n",
      "Epoch 54/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8771 - loss: 0.3487 - val_accuracy: 0.8674 - val_loss: 0.3726\n",
      "Epoch 55/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8684 - loss: 0.3710 - val_accuracy: 0.8680 - val_loss: 0.3714\n",
      "Epoch 56/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8696 - loss: 0.3608 - val_accuracy: 0.8691 - val_loss: 0.3717\n",
      "Epoch 57/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8645 - loss: 0.3766 - val_accuracy: 0.8650 - val_loss: 0.3715\n",
      "Epoch 58/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8773 - loss: 0.3577 - val_accuracy: 0.8697 - val_loss: 0.3698\n",
      "Epoch 59/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8687 - loss: 0.3510 - val_accuracy: 0.8680 - val_loss: 0.3708\n",
      "Epoch 60/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8656 - loss: 0.3737 - val_accuracy: 0.8709 - val_loss: 0.3743\n",
      "Epoch 61/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8775 - loss: 0.3572 - val_accuracy: 0.8656 - val_loss: 0.3702\n",
      "Epoch 62/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8693 - loss: 0.3622 - val_accuracy: 0.8680 - val_loss: 0.3711\n",
      "Epoch 63/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8752 - loss: 0.3520 - val_accuracy: 0.8697 - val_loss: 0.3721\n",
      "Epoch 64/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8660 - loss: 0.3609 - val_accuracy: 0.8709 - val_loss: 0.3706\n",
      "Epoch 65/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8731 - loss: 0.3570 - val_accuracy: 0.8674 - val_loss: 0.3694\n",
      "Epoch 66/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8730 - loss: 0.3604 - val_accuracy: 0.8668 - val_loss: 0.3693\n",
      "Epoch 67/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8778 - loss: 0.3431 - val_accuracy: 0.8691 - val_loss: 0.3662\n",
      "Epoch 68/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8731 - loss: 0.3486 - val_accuracy: 0.8685 - val_loss: 0.3691\n",
      "Epoch 69/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8756 - loss: 0.3470 - val_accuracy: 0.8685 - val_loss: 0.3684\n",
      "Epoch 70/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8728 - loss: 0.3569 - val_accuracy: 0.8697 - val_loss: 0.3676\n",
      "Epoch 71/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8743 - loss: 0.3489 - val_accuracy: 0.8703 - val_loss: 0.3683\n",
      "Epoch 72/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8758 - loss: 0.3410 - val_accuracy: 0.8674 - val_loss: 0.3680\n",
      "Epoch 73/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8747 - loss: 0.3584 - val_accuracy: 0.8668 - val_loss: 0.3676\n",
      "Epoch 74/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8775 - loss: 0.3463 - val_accuracy: 0.8685 - val_loss: 0.3685\n",
      "Epoch 75/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8751 - loss: 0.3535 - val_accuracy: 0.8697 - val_loss: 0.3707\n",
      "Epoch 76/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8738 - loss: 0.3456 - val_accuracy: 0.8668 - val_loss: 0.3674\n",
      "Epoch 77/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8763 - loss: 0.3499 - val_accuracy: 0.8727 - val_loss: 0.3682\n",
      "Epoch 78/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8732 - loss: 0.3579 - val_accuracy: 0.8721 - val_loss: 0.3663\n",
      "Epoch 79/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8728 - loss: 0.3499 - val_accuracy: 0.8697 - val_loss: 0.3688\n",
      "Epoch 80/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8815 - loss: 0.3349 - val_accuracy: 0.8697 - val_loss: 0.3660\n",
      "Epoch 81/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8740 - loss: 0.3547 - val_accuracy: 0.8732 - val_loss: 0.3660\n",
      "Epoch 82/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8771 - loss: 0.3484 - val_accuracy: 0.8697 - val_loss: 0.3708\n",
      "Epoch 83/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8763 - loss: 0.3492 - val_accuracy: 0.8732 - val_loss: 0.3663\n",
      "Epoch 84/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8746 - loss: 0.3604 - val_accuracy: 0.8732 - val_loss: 0.3645\n",
      "Epoch 85/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8782 - loss: 0.3586 - val_accuracy: 0.8727 - val_loss: 0.3666\n",
      "Epoch 86/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8746 - loss: 0.3496 - val_accuracy: 0.8697 - val_loss: 0.3675\n",
      "Epoch 87/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8806 - loss: 0.3403 - val_accuracy: 0.8732 - val_loss: 0.3663\n",
      "Epoch 88/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8769 - loss: 0.3359 - val_accuracy: 0.8691 - val_loss: 0.3684\n",
      "Epoch 89/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8751 - loss: 0.3453 - val_accuracy: 0.8738 - val_loss: 0.3663\n",
      "Epoch 90/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8754 - loss: 0.3578 - val_accuracy: 0.8703 - val_loss: 0.3691\n",
      "Epoch 91/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8741 - loss: 0.3464 - val_accuracy: 0.8685 - val_loss: 0.3710\n",
      "Epoch 92/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8736 - loss: 0.3527 - val_accuracy: 0.8680 - val_loss: 0.3673\n",
      "Epoch 93/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8737 - loss: 0.3594 - val_accuracy: 0.8738 - val_loss: 0.3687\n",
      "Epoch 94/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8745 - loss: 0.3446 - val_accuracy: 0.8697 - val_loss: 0.3712\n",
      "Epoch 95/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8781 - loss: 0.3409 - val_accuracy: 0.8709 - val_loss: 0.3691\n",
      "Epoch 96/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8871 - loss: 0.3325 - val_accuracy: 0.8709 - val_loss: 0.3658\n",
      "Epoch 97/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8724 - loss: 0.3523 - val_accuracy: 0.8727 - val_loss: 0.3687\n",
      "Epoch 98/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8764 - loss: 0.3461 - val_accuracy: 0.8715 - val_loss: 0.3659\n",
      "Epoch 99/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8847 - loss: 0.3310 - val_accuracy: 0.8715 - val_loss: 0.3671\n",
      "Epoch 100/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8722 - loss: 0.3526 - val_accuracy: 0.8697 - val_loss: 0.3742\n",
      "Epoch 101/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8821 - loss: 0.3342 - val_accuracy: 0.8703 - val_loss: 0.3683\n",
      "Epoch 102/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8727 - loss: 0.3440 - val_accuracy: 0.8715 - val_loss: 0.3700\n",
      "Epoch 103/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8771 - loss: 0.3511 - val_accuracy: 0.8715 - val_loss: 0.3682\n",
      "Epoch 104/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8788 - loss: 0.3344 - val_accuracy: 0.8750 - val_loss: 0.3649\n",
      "Epoch 105/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8820 - loss: 0.3448 - val_accuracy: 0.8732 - val_loss: 0.3645\n",
      "Epoch 106/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8784 - loss: 0.3463 - val_accuracy: 0.8721 - val_loss: 0.3645\n",
      "Epoch 107/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8754 - loss: 0.3469 - val_accuracy: 0.8691 - val_loss: 0.3657\n",
      "Epoch 108/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8808 - loss: 0.3374 - val_accuracy: 0.8721 - val_loss: 0.3671\n",
      "Epoch 109/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8786 - loss: 0.3441 - val_accuracy: 0.8697 - val_loss: 0.3718\n",
      "Epoch 110/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8796 - loss: 0.3349 - val_accuracy: 0.8721 - val_loss: 0.3650\n",
      "Epoch 111/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8735 - loss: 0.3484 - val_accuracy: 0.8697 - val_loss: 0.3664\n",
      "Epoch 112/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8775 - loss: 0.3274 - val_accuracy: 0.8738 - val_loss: 0.3654\n",
      "Epoch 113/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8886 - loss: 0.3243 - val_accuracy: 0.8715 - val_loss: 0.3652\n",
      "Epoch 114/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8797 - loss: 0.3432 - val_accuracy: 0.8762 - val_loss: 0.3696\n",
      "Epoch 115/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8831 - loss: 0.3377 - val_accuracy: 0.8732 - val_loss: 0.3688\n",
      "Epoch 116/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8822 - loss: 0.3351 - val_accuracy: 0.8715 - val_loss: 0.3662\n",
      "Epoch 117/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8800 - loss: 0.3431 - val_accuracy: 0.8691 - val_loss: 0.3678\n",
      "Epoch 118/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8806 - loss: 0.3429 - val_accuracy: 0.8738 - val_loss: 0.3636\n",
      "Epoch 119/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8809 - loss: 0.3405 - val_accuracy: 0.8697 - val_loss: 0.3681\n",
      "Epoch 120/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8796 - loss: 0.3454 - val_accuracy: 0.8721 - val_loss: 0.3683\n",
      "Epoch 121/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8740 - loss: 0.3446 - val_accuracy: 0.8703 - val_loss: 0.3687\n",
      "Epoch 122/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8809 - loss: 0.3351 - val_accuracy: 0.8721 - val_loss: 0.3680\n",
      "Epoch 123/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8705 - loss: 0.3561 - val_accuracy: 0.8721 - val_loss: 0.3705\n",
      "Epoch 124/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8787 - loss: 0.3376 - val_accuracy: 0.8750 - val_loss: 0.3639\n",
      "Epoch 125/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8791 - loss: 0.3330 - val_accuracy: 0.8721 - val_loss: 0.3680\n",
      "Epoch 126/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8854 - loss: 0.3347 - val_accuracy: 0.8738 - val_loss: 0.3664\n",
      "Epoch 127/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8801 - loss: 0.3340 - val_accuracy: 0.8750 - val_loss: 0.3683\n",
      "Epoch 128/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8779 - loss: 0.3362 - val_accuracy: 0.8762 - val_loss: 0.3658\n",
      "Epoch 129/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8846 - loss: 0.3306 - val_accuracy: 0.8738 - val_loss: 0.3659\n",
      "Epoch 130/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8838 - loss: 0.3348 - val_accuracy: 0.8744 - val_loss: 0.3679\n",
      "Epoch 131/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8766 - loss: 0.3430 - val_accuracy: 0.8732 - val_loss: 0.3665\n",
      "Epoch 132/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8750 - loss: 0.3540 - val_accuracy: 0.8685 - val_loss: 0.3676\n",
      "Epoch 133/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8786 - loss: 0.3338 - val_accuracy: 0.8727 - val_loss: 0.3664\n",
      "Epoch 134/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8791 - loss: 0.3407 - val_accuracy: 0.8732 - val_loss: 0.3675\n",
      "Epoch 135/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8768 - loss: 0.3416 - val_accuracy: 0.8697 - val_loss: 0.3682\n",
      "Epoch 136/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8862 - loss: 0.3324 - val_accuracy: 0.8738 - val_loss: 0.3677\n",
      "Epoch 137/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8870 - loss: 0.3238 - val_accuracy: 0.8732 - val_loss: 0.3664\n",
      "Epoch 138/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8830 - loss: 0.3345 - val_accuracy: 0.8691 - val_loss: 0.3685\n",
      "Epoch 139/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8724 - loss: 0.3371 - val_accuracy: 0.8721 - val_loss: 0.3678\n",
      "Epoch 140/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8849 - loss: 0.3355 - val_accuracy: 0.8727 - val_loss: 0.3665\n",
      "Epoch 141/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8794 - loss: 0.3424 - val_accuracy: 0.8691 - val_loss: 0.3688\n",
      "Epoch 142/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8777 - loss: 0.3470 - val_accuracy: 0.8703 - val_loss: 0.3663\n",
      "Epoch 143/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8793 - loss: 0.3332 - val_accuracy: 0.8727 - val_loss: 0.3734\n",
      "Epoch 144/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8861 - loss: 0.3236 - val_accuracy: 0.8738 - val_loss: 0.3693\n",
      "Epoch 145/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8881 - loss: 0.3209 - val_accuracy: 0.8703 - val_loss: 0.3675\n",
      "Epoch 146/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8785 - loss: 0.3401 - val_accuracy: 0.8691 - val_loss: 0.3687\n",
      "Epoch 147/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8859 - loss: 0.3195 - val_accuracy: 0.8727 - val_loss: 0.3682\n",
      "Epoch 148/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8804 - loss: 0.3352 - val_accuracy: 0.8721 - val_loss: 0.3659\n",
      "Epoch 149/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8775 - loss: 0.3472 - val_accuracy: 0.8744 - val_loss: 0.3657\n",
      "Epoch 150/150\n",
      "\u001B[1m54/54\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8740 - loss: 0.3424 - val_accuracy: 0.8727 - val_loss: 0.3651\n",
      "\u001B[1m67/67\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "\n",
      "TensorFlow MLP Classifier Results\n",
      "Accuracy: 0.8676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.73634   0.73113   0.73373       424\n",
      "        GSVT    0.84783   0.80913   0.82803       482\n",
      "          SB    0.93449   0.97297   0.95334       777\n",
      "          SR    0.89091   0.87696   0.88388       447\n",
      "\n",
      "    accuracy                        0.86761      2130\n",
      "   macro avg    0.85239   0.84755   0.84974      2130\n",
      "weighted avg    0.86629   0.86761   0.86669      2130\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:40:37.808399Z",
     "start_time": "2024-11-25T21:40:37.747099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"\\nDecision Tree Classifier Results\")\n",
    "print(f\"Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Max Depth: {dt.get_depth()}\")\n",
    "print(f\"Max Leaf Nodes: {dt.get_n_leaves()}\")\n",
    "print(classification_report(y_test, dt_y_pred, target_names=le.classes_, digits=5))"
   ],
   "id": "9c8b2f14bb688549",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier Results\n",
      "Accuracy: 0.8178\n",
      "Max Depth: 35\n",
      "Max Leaf Nodes: 1050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.63920   0.67689   0.65750       424\n",
      "        GSVT    0.78788   0.75519   0.77119       482\n",
      "          SB    0.92159   0.92278   0.92219       777\n",
      "          SR    0.84807   0.83669   0.84234       447\n",
      "\n",
      "    accuracy                        0.81784      2130\n",
      "   macro avg    0.79919   0.79789   0.79830      2130\n",
      "weighted avg    0.81969   0.81784   0.81857      2130\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:43:33.652708Z",
     "start_time": "2024-11-25T21:43:32.461571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=28, max_leaf_nodes=2400)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"\\nRandom Forest Classifier Results\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Max Depth: {rf_model.max_depth}\")\n",
    "print(f\"Max Leaf Nodes: {rf_model.max_leaf_nodes}\")\n",
    "print(classification_report(y_test, rf_y_pred, target_names=le.classes_, digits=5))"
   ],
   "id": "cffb412fcb60aa06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier Results\n",
      "Accuracy: 0.8657\n",
      "Max Depth: 28\n",
      "Max Leaf Nodes: 2400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.71106   0.74292   0.72664       424\n",
      "        GSVT    0.85806   0.82780   0.84266       482\n",
      "          SB    0.93844   0.96139   0.94978       777\n",
      "          SR    0.89906   0.85682   0.87743       447\n",
      "\n",
      "    accuracy                        0.86573      2130\n",
      "   macro avg    0.85166   0.84723   0.84913      2130\n",
      "weighted avg    0.86673   0.86573   0.86594      2130\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a81176abd418cc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
