{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-09T11:05:45.286255Z",
     "start_time": "2025-01-09T11:05:44.187045Z"
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Diagnostics.xlsx data\n",
    "diagnostics_file = \"../../../../Datasets/12-lead electrocardiogram database/Diagnostics.xlsx\"\n",
    "diagnostics_df = pd.read_excel(diagnostics_file)\n",
    "\n",
    "# Rename \"SA\" to \"SI\" in the \"Rhythm\" column\n",
    "diagnostics_df[\"Rhythm\"] = diagnostics_df[\"Rhythm\"].replace(\"SA\", \"SI\")\n",
    "\n",
    "# Drop rows with any missing values\n",
    "diagnostics_df = diagnostics_df.dropna()\n",
    "\n",
    "# Encode \"Gender\" column: 0 for \"MALE\" and 1 for \"FEMALE\"\n",
    "diagnostics_df[\"Gender\"] = diagnostics_df[\"Gender\"].map({\"MALE\": 0, \"FEMALE\": 1})\n",
    "\n",
    "# Merge specified labels\n",
    "merge_mapping = {\n",
    "    \"AF\": \"AFIB\", \"AFIB\": \"AFIB\",\n",
    "    \"SVT\": \"GSVT\", \"AT\": \"GSVT\", \"SAAWR\": \"GSVT\", \"ST\": \"GSVT\", \"AVNRT\": \"GSVT\", \"AVRT\": \"GSVT\",\n",
    "    \"SB\": \"SB\",\n",
    "    \"SR\": \"SR\", \"SI\": \"SR\"\n",
    "}\n",
    "diagnostics_df[\"Rhythm\"] = diagnostics_df[\"Rhythm\"].map(merge_mapping)\n",
    "\n",
    "# Separate features and labels\n",
    "features = diagnostics_df.drop(columns=[\"FileName\", \"Rhythm\", \"Beat\"]).values\n",
    "labels = diagnostics_df[\"Rhythm\"].values  # Using \"Rhythm\" as the target variable\n",
    "\n",
    "# Convert features to float32\n",
    "features = features.astype(\"float32\")\n",
    "\n",
    "# Encode labels as one-hot with merged classes\n",
    "unique_labels = np.unique(labels)\n",
    "label_map = {label: index for index, label in enumerate(unique_labels)}\n",
    "labels_encoded = np.array([label_map[label] for label in labels])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_encoded, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:05:45.296084Z",
     "start_time": "2025-01-09T11:05:45.292997Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_test[1])",
   "id": "c515d459fd66a3cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 68.   0.  67. 250.  76. 482. 509.  75.  82.  11. 219. 257. 460.]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:05:45.398589Z",
     "start_time": "2025-01-09T11:05:45.343666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42, max_depth=10, max_leaf_nodes=50)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Map back to original labels for a readable report\n",
    "label_names = [label for label, index in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Evaluate and print classification report\n",
    "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, digits=5))"
   ],
   "id": "61a4ead506f4fd5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Decision Tree):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB    0.81096   0.69811   0.75032       424\n",
      "        GSVT    0.83826   0.88174   0.85945       482\n",
      "          SB    0.97959   0.98842   0.98398       777\n",
      "          SR    0.90084   0.95526   0.92725       447\n",
      "\n",
      "    accuracy                        0.89953      2130\n",
      "   macro avg    0.88241   0.88088   0.88025      2130\n",
      "weighted avg    0.89752   0.89953   0.89738      2130\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:05:45.410587Z",
     "start_time": "2025-01-09T11:05:45.408169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dt.get_depth())\n",
    "print(dt.get_n_leaves())"
   ],
   "id": "a94d4057c2fb42da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "50\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:05:45.473762Z",
     "start_time": "2025-01-09T11:05:45.451731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Time  to Generating cpp header file\n",
    "\n",
    "from micromlgen import port\n",
    "\n",
    "converted_c_code = port(dt)\n",
    "\n",
    "# Now you can save the code\n",
    "with open(\"MicroGencode/optimized_author_provided_feat_dt_v1.h\",\n",
    "          \"w\") as modelFile:\n",
    "    modelFile.write(converted_c_code)"
   ],
   "id": "9f4f9d76e83dc3fe",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:05:45.868073Z",
     "start_time": "2025-01-09T11:05:45.497842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create Plots directory if it doesn't exist\n",
    "os.makedirs('Plots', exist_ok=True)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create figure with transparent background\n",
    "plt.figure(figsize=(10, 8), facecolor='none')\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('none')\n",
    "\n",
    "# Create heatmap using seaborn\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            square=True,  # Make cells square\n",
    "            cbar_kws={'label': 'Number of Samples'})\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold', labelpad=10)\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold', labelpad=10)\n",
    "plt.title('Confusion Matrix - Decision Tree Classification\\n'\n",
    "          f'(Depth: {dt.get_depth()}, Leaves: {dt.get_n_leaves()})',\n",
    "          fontsize=14,\n",
    "          fontweight='bold',\n",
    "          pad=20)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot with transparency\n",
    "timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'Plots/dt_confusion_matrix_{timestamp}.png'\n",
    "plt.savefig(filename,\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            transparent=True)\n",
    "plt.close()\n",
    "\n",
    "# Print normalized confusion matrix (as percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(\"\\nNormalized Confusion Matrix (%):\")\n",
    "for i, row in enumerate(cm_normalized):\n",
    "    print(f\"\\n{label_names[i]}: \", end=\"\")\n",
    "    print(\" \".join([f\"{x:6.2f}\" for x in row * 100]))\n",
    "\n",
    "# Calculate and print the overall accuracy\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f}\")"
   ],
   "id": "4802071b9e8a4a38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized Confusion Matrix (%):\n",
      "\n",
      "AFIB:  69.81  19.10   1.65   9.43\n",
      "\n",
      "GSVT:   9.75  88.17   0.83   1.24\n",
      "\n",
      "SB:   1.03   0.00  98.84   0.13\n",
      "\n",
      "SR:   3.13   0.22   1.12  95.53\n",
      "\n",
      "Overall Accuracy: 0.8995\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
