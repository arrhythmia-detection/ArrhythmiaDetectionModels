{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T10:14:45.500856Z",
     "start_time": "2024-10-29T10:14:44.040342Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('GeneratedTfLiteFiles', exist_ok=True)\n",
    "os.makedirs('GeneratedCHeaderFiles', exist_ok=True)\n",
    "\n",
    "# Generate a synthetic multi-class dataset\n",
    "X, y = make_classification(n_samples=2000,\n",
    "                           n_features=10,\n",
    "                           n_classes=5,\n",
    "                           n_clusters_per_class=1,\n",
    "                           n_informative=8,\n",
    "                           random_state=42)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test)\n",
    "print(X_train.shape, y_train.shape)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 16:14:44.237074: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-29 16:14:44.247923: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-29 16:14:44.251172: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 16:14:44.260272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 16:14:44.764787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10) (1600,)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:14:53.795590Z",
     "start_time": "2024-10-29T10:14:45.505347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a simple MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(10,)),\n",
    "    tf.keras.layers.BatchNormalization(), # training only\n",
    "    tf.keras.layers.Dropout(0.3), # training only\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Total two ops -> Dense (FULLY_CONNECTED: Composite ops)\n",
    "# Finally SOFTMAX\n",
    "\n",
    "# Number of Input -> 10, output -> 4 (total 5)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the original model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"\\nOriginal Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, digits=5))"
   ],
   "id": "67a95f9eca4863eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730196885.643328  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.676547  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.679787  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.683783  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.686520  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.689176  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.796539  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.797662  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730196885.798804  583478 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-29 16:14:45.799818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5573 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730196886.970322  583619 service.cc:146] XLA service 0x35f8fbe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730196886.970347  583619 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-10-29 16:14:47.003031: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-29 16:14:47.162013: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.3345 - loss: 1.5437 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730196888.395599  583619 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - accuracy: 0.3363 - loss: 1.5404 - val_accuracy: 0.6187 - val_loss: 1.4102\n",
      "Epoch 2/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5868 - loss: 1.0645 - val_accuracy: 0.7094 - val_loss: 1.1654\n",
      "Epoch 3/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6771 - loss: 0.8812 - val_accuracy: 0.7656 - val_loss: 0.9492\n",
      "Epoch 4/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7112 - loss: 0.7871 - val_accuracy: 0.7781 - val_loss: 0.7928\n",
      "Epoch 5/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7120 - loss: 0.7322 - val_accuracy: 0.7844 - val_loss: 0.6846\n",
      "Epoch 6/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7518 - loss: 0.6895 - val_accuracy: 0.8000 - val_loss: 0.6114\n",
      "Epoch 7/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7662 - loss: 0.6377 - val_accuracy: 0.8125 - val_loss: 0.5526\n",
      "Epoch 8/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7431 - loss: 0.6384 - val_accuracy: 0.8094 - val_loss: 0.5155\n",
      "Epoch 9/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7940 - loss: 0.5522 - val_accuracy: 0.8219 - val_loss: 0.4789\n",
      "Epoch 10/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7763 - loss: 0.5491 - val_accuracy: 0.8344 - val_loss: 0.4413\n",
      "Epoch 11/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7967 - loss: 0.5424 - val_accuracy: 0.8281 - val_loss: 0.4258\n",
      "Epoch 12/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8056 - loss: 0.5253 - val_accuracy: 0.8438 - val_loss: 0.4036\n",
      "Epoch 13/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8101 - loss: 0.5063 - val_accuracy: 0.8500 - val_loss: 0.3939\n",
      "Epoch 14/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8294 - loss: 0.4866 - val_accuracy: 0.8469 - val_loss: 0.3830\n",
      "Epoch 15/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8322 - loss: 0.4399 - val_accuracy: 0.8687 - val_loss: 0.3636\n",
      "Epoch 16/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8160 - loss: 0.5047 - val_accuracy: 0.8719 - val_loss: 0.3511\n",
      "Epoch 17/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8335 - loss: 0.4522 - val_accuracy: 0.8687 - val_loss: 0.3420\n",
      "Epoch 18/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8510 - loss: 0.4200 - val_accuracy: 0.8844 - val_loss: 0.3249\n",
      "Epoch 19/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8472 - loss: 0.4037 - val_accuracy: 0.9000 - val_loss: 0.3172\n",
      "Epoch 20/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8520 - loss: 0.4013 - val_accuracy: 0.8906 - val_loss: 0.3145\n",
      "Epoch 21/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8748 - loss: 0.3812 - val_accuracy: 0.8906 - val_loss: 0.3047\n",
      "Epoch 22/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8485 - loss: 0.3903 - val_accuracy: 0.8875 - val_loss: 0.3027\n",
      "Epoch 23/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8525 - loss: 0.3819 - val_accuracy: 0.8938 - val_loss: 0.2841\n",
      "Epoch 24/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8483 - loss: 0.3796 - val_accuracy: 0.9031 - val_loss: 0.3032\n",
      "Epoch 25/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8644 - loss: 0.3580 - val_accuracy: 0.8938 - val_loss: 0.2838\n",
      "Epoch 26/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8588 - loss: 0.3586 - val_accuracy: 0.9031 - val_loss: 0.2802\n",
      "Epoch 27/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8832 - loss: 0.3199 - val_accuracy: 0.9062 - val_loss: 0.2760\n",
      "Epoch 28/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8830 - loss: 0.3304 - val_accuracy: 0.9062 - val_loss: 0.2912\n",
      "Epoch 29/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8742 - loss: 0.3767 - val_accuracy: 0.9062 - val_loss: 0.2791\n",
      "Epoch 30/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8843 - loss: 0.3350 - val_accuracy: 0.9031 - val_loss: 0.2738\n",
      "Epoch 31/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8650 - loss: 0.3607 - val_accuracy: 0.9281 - val_loss: 0.2533\n",
      "Epoch 32/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8822 - loss: 0.3457 - val_accuracy: 0.9312 - val_loss: 0.2472\n",
      "Epoch 33/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8897 - loss: 0.3028 - val_accuracy: 0.9125 - val_loss: 0.2583\n",
      "Epoch 34/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8849 - loss: 0.3228 - val_accuracy: 0.9125 - val_loss: 0.2602\n",
      "Epoch 35/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8834 - loss: 0.3061 - val_accuracy: 0.9187 - val_loss: 0.2424\n",
      "Epoch 36/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8948 - loss: 0.3043 - val_accuracy: 0.9031 - val_loss: 0.2507\n",
      "Epoch 37/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8831 - loss: 0.3395 - val_accuracy: 0.9156 - val_loss: 0.2435\n",
      "Epoch 38/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8587 - loss: 0.3435 - val_accuracy: 0.9156 - val_loss: 0.2400\n",
      "Epoch 39/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8795 - loss: 0.3141 - val_accuracy: 0.9125 - val_loss: 0.2388\n",
      "Epoch 40/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8751 - loss: 0.3199 - val_accuracy: 0.9187 - val_loss: 0.2404\n",
      "Epoch 41/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8817 - loss: 0.3285 - val_accuracy: 0.9219 - val_loss: 0.2367\n",
      "Epoch 42/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8873 - loss: 0.3019 - val_accuracy: 0.9312 - val_loss: 0.2143\n",
      "Epoch 43/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9071 - loss: 0.2685 - val_accuracy: 0.9187 - val_loss: 0.2340\n",
      "Epoch 44/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8851 - loss: 0.3280 - val_accuracy: 0.9156 - val_loss: 0.2359\n",
      "Epoch 45/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8936 - loss: 0.2998 - val_accuracy: 0.9312 - val_loss: 0.2099\n",
      "Epoch 46/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9000 - loss: 0.2702 - val_accuracy: 0.9281 - val_loss: 0.2142\n",
      "Epoch 47/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8976 - loss: 0.2639 - val_accuracy: 0.9375 - val_loss: 0.2038\n",
      "Epoch 48/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8838 - loss: 0.3074 - val_accuracy: 0.9375 - val_loss: 0.2115\n",
      "Epoch 49/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8783 - loss: 0.3064 - val_accuracy: 0.9187 - val_loss: 0.2153\n",
      "Epoch 50/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9009 - loss: 0.2935 - val_accuracy: 0.9156 - val_loss: 0.2258\n",
      "Epoch 51/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8937 - loss: 0.2592 - val_accuracy: 0.9312 - val_loss: 0.2188\n",
      "Epoch 52/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9074 - loss: 0.2634 - val_accuracy: 0.9312 - val_loss: 0.2171\n",
      "Epoch 53/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9189 - loss: 0.2251 - val_accuracy: 0.9281 - val_loss: 0.2139\n",
      "Epoch 54/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8949 - loss: 0.2967 - val_accuracy: 0.9312 - val_loss: 0.2145\n",
      "Epoch 55/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8899 - loss: 0.2784 - val_accuracy: 0.9375 - val_loss: 0.2023\n",
      "Epoch 56/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9000 - loss: 0.2615 - val_accuracy: 0.9438 - val_loss: 0.1919\n",
      "Epoch 57/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9012 - loss: 0.2511 - val_accuracy: 0.9406 - val_loss: 0.2154\n",
      "Epoch 58/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9023 - loss: 0.2409 - val_accuracy: 0.9469 - val_loss: 0.1992\n",
      "Epoch 59/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8978 - loss: 0.2496 - val_accuracy: 0.9312 - val_loss: 0.1990\n",
      "Epoch 60/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9253 - loss: 0.2352 - val_accuracy: 0.9406 - val_loss: 0.1940\n",
      "Epoch 61/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9093 - loss: 0.2545 - val_accuracy: 0.9438 - val_loss: 0.1980\n",
      "Epoch 62/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9007 - loss: 0.2581 - val_accuracy: 0.9375 - val_loss: 0.2118\n",
      "Epoch 63/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9238 - loss: 0.2175 - val_accuracy: 0.9406 - val_loss: 0.2043\n",
      "Epoch 64/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8966 - loss: 0.2666 - val_accuracy: 0.9344 - val_loss: 0.1931\n",
      "Epoch 65/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9082 - loss: 0.2712 - val_accuracy: 0.9344 - val_loss: 0.1819\n",
      "Epoch 66/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9178 - loss: 0.2468 - val_accuracy: 0.9375 - val_loss: 0.1956\n",
      "Epoch 67/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9179 - loss: 0.2337 - val_accuracy: 0.9563 - val_loss: 0.1778\n",
      "Epoch 68/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9195 - loss: 0.2054 - val_accuracy: 0.9344 - val_loss: 0.2057\n",
      "Epoch 69/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9228 - loss: 0.2130 - val_accuracy: 0.9375 - val_loss: 0.1894\n",
      "Epoch 70/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9346 - loss: 0.2018 - val_accuracy: 0.9406 - val_loss: 0.1927\n",
      "Epoch 71/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9188 - loss: 0.2219 - val_accuracy: 0.9187 - val_loss: 0.2233\n",
      "Epoch 72/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9054 - loss: 0.2474 - val_accuracy: 0.9469 - val_loss: 0.1882\n",
      "Epoch 73/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9211 - loss: 0.2129 - val_accuracy: 0.9406 - val_loss: 0.1935\n",
      "Epoch 74/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9184 - loss: 0.2168 - val_accuracy: 0.9406 - val_loss: 0.2048\n",
      "Epoch 75/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9157 - loss: 0.2180 - val_accuracy: 0.9438 - val_loss: 0.1932\n",
      "Epoch 76/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9140 - loss: 0.2135 - val_accuracy: 0.9438 - val_loss: 0.1990\n",
      "Epoch 77/100\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9169 - loss: 0.2372 - val_accuracy: 0.9406 - val_loss: 0.2027\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "\n",
      "Original Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92063   0.84058   0.87879        69\n",
      "           1    0.92222   0.96512   0.94318        86\n",
      "           2    0.85882   0.90123   0.87952        81\n",
      "           3    0.87013   0.85897   0.86452        78\n",
      "           4    0.89412   0.88372   0.88889        86\n",
      "\n",
      "    accuracy                        0.89250       400\n",
      "   macro avg    0.89319   0.88993   0.89098       400\n",
      "weighted avg    0.89291   0.89250   0.89217       400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:14:54.466445Z",
     "start_time": "2024-10-29T10:14:53.831747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate input statistics for quantization\n",
    "def get_input_statistics():\n",
    "    \"\"\"Calculate input statistics for quantization calibration\"\"\"\n",
    "    # Use training data to compute input statistics\n",
    "    input_data = X_train.astype(np.float32)\n",
    "\n",
    "    # Calculate min, max, and mean for each feature\n",
    "    input_min = np.min(input_data, axis=0)\n",
    "    input_max = np.max(input_data, axis=0)\n",
    "    input_mean = np.mean(input_data, axis=0)\n",
    "    input_std = np.std(input_data, axis=0)\n",
    "\n",
    "    return input_min, input_max, input_mean, input_std\n",
    "\n",
    "input_min, input_max, input_mean, input_std = get_input_statistics()\n",
    "\n",
    "# Representative dataset generator with input statistics\n",
    "def representative_dataset():\n",
    "    \"\"\"Generate representative dataset for quantization with input statistics\"\"\"\n",
    "    for i in range(500):  # Using 500 samples for calibration\n",
    "        data = X_train[i:i+1].astype(np.float32)\n",
    "        # Ensure the data is within the calculated ranges\n",
    "        data = np.clip(data, input_min, input_max)\n",
    "        yield [data]\n",
    "\n",
    "# Convert to TensorFlow Lite with proper quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Set input/output statistics for quantization\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "tflite_model_path = os.path.join('GeneratedTfLiteFiles', 'model.tflite')\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Convert TFLite model to C header using xxd\n",
    "header_file = os.path.join('GeneratedCHeaderFiles', 'model.h')\n",
    "subprocess.run(['xxd', '-i', tflite_model_path, header_file])\n",
    "\n",
    "# Read and modify the header file\n",
    "with open(header_file, 'r') as f:\n",
    "    header_content = f.read()\n",
    "\n",
    "# Modify header content\n",
    "header_content = header_content.replace(\n",
    "    'unsigned char GeneratedTfLiteFiles_model_tflite[] = {',\n",
    "    'const unsigned char g_model[] = {'\n",
    ")\n",
    "header_content = header_content.replace(\n",
    "    'unsigned int GeneratedTfLiteFiles_model_tflite_len',\n",
    "    'const unsigned int g_model_len'\n",
    ")\n",
    "\n",
    "# Write the modified header file with added input statistics\n",
    "with open(header_file, 'w') as f:\n",
    "    f.write(\"// Generated TensorFlow Lite model header for multi-class classification\\n\")\n",
    "    f.write(\"#ifndef MODEL_H_\\n#define MODEL_H_\\n\\n\")\n",
    "\n",
    "    # Add input statistics as constants\n",
    "    f.write(\"// Input statistics for quantization\\n\")\n",
    "    for i in range(len(input_mean)):\n",
    "        f.write(f\"#define INPUT_MEAN_{i} {input_mean[i]}f\\n\")\n",
    "        f.write(f\"#define INPUT_STD_{i} {input_std[i]}f\\n\")\n",
    "\n",
    "    f.write(\"\\n\")\n",
    "    f.write(header_content)\n",
    "    f.write(\"\\n#endif  // MODEL_H_\")\n"
   ],
   "id": "cf17716396ad7834",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprj1j5kof/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprj1j5kof/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmprj1j5kof'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138495738814608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738818304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738955200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738953968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738822000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738955552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738958896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738961184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738959424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738961888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738956080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738960480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738959776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738965936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738965760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738966640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738959600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738965232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738967520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738964352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738967696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138495738968928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1730196894.339288  583478 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1730196894.339302  583478 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-10-29 16:14:54.339512: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmprj1j5kof\n",
      "2024-10-29 16:14:54.340400: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-29 16:14:54.340409: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmprj1j5kof\n",
      "2024-10-29 16:14:54.347218: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-10-29 16:14:54.348414: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-29 16:14:54.384197: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmprj1j5kof\n",
      "2024-10-29 16:14:54.394162: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 54652 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:14:54.499523Z",
     "start_time": "2024-10-29T10:14:54.474995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get quantization parameters\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "output_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "# Test the TFLite model with proper quantization\n",
    "y_tflite_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    # Quantize the input using the calculated statistics\n",
    "    input_data = X_test[i].reshape(1, 10)\n",
    "    # Clip input data to the range used during calibration\n",
    "    input_data = np.clip(input_data, input_min, input_max)\n",
    "    input_data_quantized = np.round(input_data / input_scale + input_zero_point)\n",
    "    input_data_quantized = input_data_quantized.astype(np.int8)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data_quantized)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output and dequantize it\n",
    "    # Only need to do it here. TFLM not needed, we can use the max value to find the class.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data_dequantized = (output_data.astype(np.float32) - output_zero_point) * output_scale\n",
    "\n",
    "    y_tflite_pred.append(np.argmax(output_data_dequantized))\n",
    "\n",
    "y_tflite_pred = np.array(y_tflite_pred)\n",
    "\n",
    "print(\"\\nTFLite Model Classification Report:\")\n",
    "print(classification_report(y_test, y_tflite_pred, digits=5))\n",
    "\n",
    "# Save detailed results including input statistics\n",
    "results_file = os.path.join('GeneratedTfLiteFiles', 'model_evaluation.txt')\n",
    "with open(results_file, 'w') as f:\n",
    "    f.write(\"Multi-class Classification Model Evaluation\\n\")\n",
    "    f.write(\"=========================================\\n\\n\")\n",
    "\n",
    "    f.write(\"Input Statistics:\\n\")\n",
    "    f.write(f\"Mean: {input_mean}\\n\")\n",
    "    f.write(f\"Std: {input_std}\\n\")\n",
    "    f.write(f\"Min: {input_min}\\n\")\n",
    "    f.write(f\"Max: {input_max}\\n\\n\")\n",
    "\n",
    "    f.write(\"Quantization Parameters:\\n\")\n",
    "    f.write(f\"Input Scale: {input_scale}\\n\")\n",
    "    f.write(f\"Input Zero Point: {input_zero_point}\\n\")\n",
    "    f.write(f\"Output Scale: {output_scale}\\n\")\n",
    "    f.write(f\"Output Zero Point: {output_zero_point}\\n\\n\")\n",
    "\n",
    "    f.write(\"Original Model Classification Report:\\n\")\n",
    "    f.write(classification_report(y_test, y_pred_classes, digits=5))\n",
    "\n",
    "    f.write(\"\\nTFLite Model Classification Report:\\n\")\n",
    "    f.write(classification_report(y_test, y_tflite_pred, digits=5))\n",
    "\n",
    "print(f\"\\nDetailed evaluation results saved to: {results_file}\")\n",
    "\n",
    "# Print summary of quantization parameters\n",
    "print(\"\\nQuantization Parameters Summary:\")\n",
    "print(f\"Input Scale: {input_scale}\")\n",
    "print(f\"Input Zero Point: {input_zero_point}\")\n",
    "print(f\"Output Scale: {output_scale}\")\n",
    "print(f\"Output Zero Point: {output_zero_point}\")\n",
    "\n",
    "# Print input statistics summary\n",
    "print(\"\\nInput Statistics Summary:\")\n",
    "print(f\"Mean Range: [{np.min(input_mean):.4f}, {np.max(input_mean):.4f}]\")\n",
    "print(f\"Std Range: [{np.min(input_std):.4f}, {np.max(input_std):.4f}]\")\n",
    "print(f\"Input Range: [{np.min(input_min):.4f}, {np.max(input_max):.4f}]\")"
   ],
   "id": "ab0bfe25596302c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TFLite Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.91935   0.82609   0.87023        69\n",
      "           1    0.92222   0.96512   0.94318        86\n",
      "           2    0.84884   0.90123   0.87425        81\n",
      "           3    0.87013   0.85897   0.86452        78\n",
      "           4    0.89412   0.88372   0.88889        86\n",
      "\n",
      "    accuracy                        0.89000       400\n",
      "   macro avg    0.89093   0.88703   0.88821       400\n",
      "weighted avg    0.89067   0.89000   0.88963       400\n",
      "\n",
      "\n",
      "Detailed evaluation results saved to: GeneratedTfLiteFiles/model_evaluation.txt\n",
      "\n",
      "Quantization Parameters Summary:\n",
      "Input Scale: 0.028471175581216812\n",
      "Input Zero Point: 2\n",
      "Output Scale: 0.00390625\n",
      "Output Zero Point: -128\n",
      "\n",
      "Input Statistics Summary:\n",
      "Mean Range: [-0.0118, 0.0335]\n",
      "Std Range: [0.9939, 1.0103]\n",
      "Input Range: [-4.0525, 3.9369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
