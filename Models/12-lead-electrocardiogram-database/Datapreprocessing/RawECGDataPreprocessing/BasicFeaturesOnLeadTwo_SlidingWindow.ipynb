{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:36.722995Z",
     "start_time": "2024-11-27T05:53:34.035778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "# noinspection PyUnresolvedReferences\n",
    "from tensorflow.keras.models import Sequential\n",
    "# noinspection PyUnresolvedReferences\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "\n",
    "# Constants\n",
    "SAMPLING_RATE = 500  # Hz\n",
    "WINDOW_SIZE = 4 * SAMPLING_RATE\n",
    "STEP_SIZE = 2 * SAMPLING_RATE\n",
    "ecg_folder = \"../../../../Datasets/12-lead electrocardiogram database/ECGData\"\n",
    "diagnostics_file = \"../../../../Datasets/12-lead electrocardiogram database/Diagnostics.xlsx\"\n",
    "\n",
    "# Label mapping\n",
    "rhythm_mapping = {\n",
    "    'AFIB': 'AFIB',\n",
    "    'AF': 'AFIB',\n",
    "    'SVT': 'GSVT',\n",
    "    'AT': 'GSVT',\n",
    "    'SAAWR': 'GSVT',\n",
    "    'ST': 'GSVT',\n",
    "    'AVNRT': 'GSVT',\n",
    "    'AVRT': 'GSVT',\n",
    "    'SB': 'SB',\n",
    "    'SR': 'SR',\n",
    "    'SA': 'SR'\n",
    "}\n",
    "\n",
    "# Load diagnostics data\n",
    "diagnostics_df = pd.read_excel(diagnostics_file)\n",
    "diagnostics_df['Rhythm'] = diagnostics_df['Rhythm'].map(rhythm_mapping)"
   ],
   "id": "7abfed95cfee07a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 11:53:34.600836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-27 11:53:34.611933: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-27 11:53:34.615328: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 11:53:34.624441: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 11:53:35.165395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:36.741856Z",
     "start_time": "2024-11-27T05:53:36.732592Z"
    }
   },
   "cell_type": "code",
   "source": "diagnostics_df",
   "id": "533d3ceac7ff1561",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         FileName Rhythm       Beat  PatientAge  Gender  \\\n",
       "0      MUSE_20180113_171327_27000   AFIB   RBBB TWC          85    MALE   \n",
       "1      MUSE_20180112_073319_29000     SB        TWC          59  FEMALE   \n",
       "2      MUSE_20180111_165520_97000     SR       NONE          20  FEMALE   \n",
       "3      MUSE_20180113_121940_44000     SB       NONE          66    MALE   \n",
       "4      MUSE_20180112_122850_57000   AFIB  STDD STTC          73  FEMALE   \n",
       "...                           ...    ...        ...         ...     ...   \n",
       "10641  MUSE_20181222_204306_99000   GSVT       NONE          80  FEMALE   \n",
       "10642  MUSE_20181222_204309_22000   GSVT       NONE          81  FEMALE   \n",
       "10643  MUSE_20181222_204310_31000   GSVT       NONE          39    MALE   \n",
       "10644  MUSE_20181222_204312_58000   GSVT       NONE          76    MALE   \n",
       "10645  MUSE_20181222_204314_78000   GSVT       NONE          75    MALE   \n",
       "\n",
       "       VentricularRate  AtrialRate  QRSDuration  QTInterval  QTCorrected  \\\n",
       "0                  117         234          114         356          496   \n",
       "1                   52          52           92         432          401   \n",
       "2                   67          67           82         382          403   \n",
       "3                   53          53           96         456          427   \n",
       "4                  162         162          114         252          413   \n",
       "...                ...         ...          ...         ...          ...   \n",
       "10641              196          73          168         284          513   \n",
       "10642              162          81          162         294          482   \n",
       "10643              152          92          152         340          540   \n",
       "10644              175         178          128         310          529   \n",
       "10645              117         104          140         312          435   \n",
       "\n",
       "       RAxis  TAxis  QRSCount  QOnset  QOffset  TOffset  \n",
       "0         81    -27        19     208      265      386  \n",
       "1         76     42         8     215      261      431  \n",
       "2         88     20        11     224      265      415  \n",
       "3         34      3         9     219      267      447  \n",
       "4         68    -40        26     228      285      354  \n",
       "...      ...    ...       ...     ...      ...      ...  \n",
       "10641    258    244        32     177      261      319  \n",
       "10642    110    -75        27     173      254      320  \n",
       "10643    250     38        25     208      284      378  \n",
       "10644     98    -83        29     205      269      360  \n",
       "10645    263    144        19     208      278      364  \n",
       "\n",
       "[10646 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Beat</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>Gender</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>RAxis</th>\n",
       "      <th>TAxis</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QOnset</th>\n",
       "      <th>QOffset</th>\n",
       "      <th>TOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_27000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>RBBB TWC</td>\n",
       "      <td>85</td>\n",
       "      <td>MALE</td>\n",
       "      <td>117</td>\n",
       "      <td>234</td>\n",
       "      <td>114</td>\n",
       "      <td>356</td>\n",
       "      <td>496</td>\n",
       "      <td>81</td>\n",
       "      <td>-27</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>265</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_29000</td>\n",
       "      <td>SB</td>\n",
       "      <td>TWC</td>\n",
       "      <td>59</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>92</td>\n",
       "      <td>432</td>\n",
       "      <td>401</td>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>215</td>\n",
       "      <td>261</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180111_165520_97000</td>\n",
       "      <td>SR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>20</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>382</td>\n",
       "      <td>403</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>224</td>\n",
       "      <td>265</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180113_121940_44000</td>\n",
       "      <td>SB</td>\n",
       "      <td>NONE</td>\n",
       "      <td>66</td>\n",
       "      <td>MALE</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>96</td>\n",
       "      <td>456</td>\n",
       "      <td>427</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>219</td>\n",
       "      <td>267</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180112_122850_57000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>STDD STTC</td>\n",
       "      <td>73</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>114</td>\n",
       "      <td>252</td>\n",
       "      <td>413</td>\n",
       "      <td>68</td>\n",
       "      <td>-40</td>\n",
       "      <td>26</td>\n",
       "      <td>228</td>\n",
       "      <td>285</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>MUSE_20181222_204306_99000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>80</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>196</td>\n",
       "      <td>73</td>\n",
       "      <td>168</td>\n",
       "      <td>284</td>\n",
       "      <td>513</td>\n",
       "      <td>258</td>\n",
       "      <td>244</td>\n",
       "      <td>32</td>\n",
       "      <td>177</td>\n",
       "      <td>261</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10642</th>\n",
       "      <td>MUSE_20181222_204309_22000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>81</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>162</td>\n",
       "      <td>81</td>\n",
       "      <td>162</td>\n",
       "      <td>294</td>\n",
       "      <td>482</td>\n",
       "      <td>110</td>\n",
       "      <td>-75</td>\n",
       "      <td>27</td>\n",
       "      <td>173</td>\n",
       "      <td>254</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>MUSE_20181222_204310_31000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>39</td>\n",
       "      <td>MALE</td>\n",
       "      <td>152</td>\n",
       "      <td>92</td>\n",
       "      <td>152</td>\n",
       "      <td>340</td>\n",
       "      <td>540</td>\n",
       "      <td>250</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>208</td>\n",
       "      <td>284</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10644</th>\n",
       "      <td>MUSE_20181222_204312_58000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>76</td>\n",
       "      <td>MALE</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>128</td>\n",
       "      <td>310</td>\n",
       "      <td>529</td>\n",
       "      <td>98</td>\n",
       "      <td>-83</td>\n",
       "      <td>29</td>\n",
       "      <td>205</td>\n",
       "      <td>269</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10645</th>\n",
       "      <td>MUSE_20181222_204314_78000</td>\n",
       "      <td>GSVT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>75</td>\n",
       "      <td>MALE</td>\n",
       "      <td>117</td>\n",
       "      <td>104</td>\n",
       "      <td>140</td>\n",
       "      <td>312</td>\n",
       "      <td>435</td>\n",
       "      <td>263</td>\n",
       "      <td>144</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>278</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10646 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:54:32.936641Z",
     "start_time": "2024-11-27T05:53:36.804585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_ecg_data(ecg_folder, diagnostics_df):\n",
    "    segments = []\n",
    "    segment_labels = []\n",
    "\n",
    "    for _, row in tqdm(diagnostics_df.iterrows(), total=diagnostics_df.shape[0]):\n",
    "        file_name = row['FileName']\n",
    "        rhythm_label = row['Rhythm']\n",
    "\n",
    "        # Skip if rhythm label is invalid\n",
    "        if pd.isnull(rhythm_label) or rhythm_label not in rhythm_mapping.values():\n",
    "            print(\"Invalid rhythm label\", rhythm_label)\n",
    "            continue\n",
    "\n",
    "        # Load ECG file\n",
    "        ecg_file = os.path.join(ecg_folder, f\"{file_name}.csv\")\n",
    "        if not os.path.exists(ecg_file):\n",
    "            print(\"File not found\", ecg_file)\n",
    "            continue\n",
    "\n",
    "        ecg_data = pd.read_csv(ecg_file, header=0).iloc[:, 1].values\n",
    "        ecg_data = ecg_data.astype(float)\n",
    "        # print(ecg_data.shape)\n",
    "\n",
    "        # Normalize the signal\n",
    "        # ecg_data = (ecg_data - np.mean(ecg_data)) / np.std(ecg_data)\n",
    "        # print(len(ecg_data))\n",
    "        # Segment the data using sliding window\n",
    "        for start in range(0, len(ecg_data) - WINDOW_SIZE + 1, STEP_SIZE):\n",
    "            segment = ecg_data[start:start + WINDOW_SIZE]\n",
    "            segments.append(segment)\n",
    "            segment_labels.append(rhythm_label)\n",
    "\n",
    "    return np.array(segments), np.array(segment_labels)\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "segments, segment_labels = preprocess_ecg_data(ecg_folder, diagnostics_df)\n",
    "segments"
   ],
   "id": "de948c12d0a08b58",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10646/10646 [00:56<00:00, 189.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 263.52,  263.52,  263.52, ...,    0.  ,  -19.52,  -14.64],\n",
       "       [ -68.32,  -58.56,  -53.68, ...,  -53.68,  -53.68,  -78.08],\n",
       "       [   0.  ,  -14.64,  -19.52, ...,  112.24,  126.88,  141.52],\n",
       "       ...,\n",
       "       [ 136.64,  131.76,  136.64, ...,  -14.64,   -4.88,    4.88],\n",
       "       [  73.2 ,   68.32,   73.2 , ..., -107.36,  -97.6 ,  -97.6 ],\n",
       "       [   4.88,    4.88,    9.76, ..., -214.72, -224.48, -234.24]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:55:32.465230Z",
     "start_time": "2024-11-27T05:54:32.956695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "segment_labels_encoded = label_encoder.fit_transform(segment_labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(segments, segment_labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "y_pred_dt = dt.predict(X_test.reshape(X_test.shape[0], -1))\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_))\n",
    "print(\"Depth of the tree\", dt.get_depth())\n",
    "print(\"Leaf nodes of the tree\", dt.get_n_leaves())"
   ],
   "id": "85b00569a096dca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB       0.29      0.30      0.29      1740\n",
      "        GSVT       0.51      0.47      0.49      1868\n",
      "          SB       0.66      0.67      0.66      3100\n",
      "          SR       0.40      0.39      0.40      1809\n",
      "\n",
      "    accuracy                           0.49      8517\n",
      "   macro avg       0.46      0.46      0.46      8517\n",
      "weighted avg       0.49      0.49      0.49      8517\n",
      "\n",
      "Depth of the tree 98\n",
      "Leaf nodes of the tree 5361\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:55:55.399614Z",
     "start_time": "2024-11-27T05:55:32.563532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MLP\n",
    "mlp = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))\n",
    "y_pred_mlp = np.argmax(mlp.predict(X_test), axis=1)\n",
    "print(\"MLP Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mlp, target_names=label_encoder.classes_))"
   ],
   "id": "3e8c69446c706ece",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732686932.751535  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.791939  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.799561  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.806400  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.809565  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.814926  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.923748  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.924850  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1732686932.925887  146919 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-27 11:55:32.926894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5740 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732686934.292837  149296 service.cc:146] XLA service 0x705ce8002da0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732686934.292875  149296 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-27 11:55:34.329007: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-27 11:55:34.442135: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-11-27 11:55:35.013468: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1481', 408 bytes spill stores, 440 bytes spill loads\n",
      "\n",
      "2024-11-27 11:55:35.022696: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1481', 2852 bytes spill stores, 2760 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m21/34\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.2547 - loss: 2.1497 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732686935.985014  149296 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-27 11:55:36.539127: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1481', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 75ms/step - accuracy: 0.2736 - loss: 2.0485 - val_accuracy: 0.4086 - val_loss: 1.8751\n",
      "Epoch 2/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.4123 - loss: 1.4548 - val_accuracy: 0.5530 - val_loss: 1.1695\n",
      "Epoch 3/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4781 - loss: 1.2791 - val_accuracy: 0.6015 - val_loss: 1.0106\n",
      "Epoch 4/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5167 - loss: 1.1629 - val_accuracy: 0.6319 - val_loss: 0.9427\n",
      "Epoch 5/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5467 - loss: 1.1003 - val_accuracy: 0.6541 - val_loss: 0.8887\n",
      "Epoch 6/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5725 - loss: 1.0378 - val_accuracy: 0.6663 - val_loss: 0.8543\n",
      "Epoch 7/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5888 - loss: 0.9933 - val_accuracy: 0.6792 - val_loss: 0.8332\n",
      "Epoch 8/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6095 - loss: 0.9558 - val_accuracy: 0.6864 - val_loss: 0.8167\n",
      "Epoch 9/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6196 - loss: 0.9312 - val_accuracy: 0.6884 - val_loss: 0.8012\n",
      "Epoch 10/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6327 - loss: 0.8980 - val_accuracy: 0.6906 - val_loss: 0.7884\n",
      "Epoch 11/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6448 - loss: 0.8774 - val_accuracy: 0.6952 - val_loss: 0.7752\n",
      "Epoch 12/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6519 - loss: 0.8651 - val_accuracy: 0.6979 - val_loss: 0.7667\n",
      "Epoch 13/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6569 - loss: 0.8492 - val_accuracy: 0.7000 - val_loss: 0.7568\n",
      "Epoch 14/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6600 - loss: 0.8371 - val_accuracy: 0.7032 - val_loss: 0.7460\n",
      "Epoch 15/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6680 - loss: 0.8246 - val_accuracy: 0.7074 - val_loss: 0.7381\n",
      "Epoch 16/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6758 - loss: 0.8053 - val_accuracy: 0.7078 - val_loss: 0.7309\n",
      "Epoch 17/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6788 - loss: 0.7975 - val_accuracy: 0.7083 - val_loss: 0.7248\n",
      "Epoch 18/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6776 - loss: 0.7949 - val_accuracy: 0.7094 - val_loss: 0.7215\n",
      "Epoch 19/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6850 - loss: 0.7784 - val_accuracy: 0.7088 - val_loss: 0.7193\n",
      "Epoch 20/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6845 - loss: 0.7791 - val_accuracy: 0.7128 - val_loss: 0.7116\n",
      "Epoch 21/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6903 - loss: 0.7629 - val_accuracy: 0.7152 - val_loss: 0.7091\n",
      "Epoch 22/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6898 - loss: 0.7586 - val_accuracy: 0.7155 - val_loss: 0.7058\n",
      "Epoch 23/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6878 - loss: 0.7606 - val_accuracy: 0.7163 - val_loss: 0.7033\n",
      "Epoch 24/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7015 - loss: 0.7418 - val_accuracy: 0.7183 - val_loss: 0.6979\n",
      "Epoch 25/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6990 - loss: 0.7387 - val_accuracy: 0.7222 - val_loss: 0.6954\n",
      "Epoch 26/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7028 - loss: 0.7318 - val_accuracy: 0.7211 - val_loss: 0.6943\n",
      "Epoch 27/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7046 - loss: 0.7300 - val_accuracy: 0.7214 - val_loss: 0.6925\n",
      "Epoch 28/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7013 - loss: 0.7320 - val_accuracy: 0.7236 - val_loss: 0.6894\n",
      "Epoch 29/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7063 - loss: 0.7274 - val_accuracy: 0.7235 - val_loss: 0.6888\n",
      "Epoch 30/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7091 - loss: 0.7163 - val_accuracy: 0.7244 - val_loss: 0.6850\n",
      "Epoch 31/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7057 - loss: 0.7243 - val_accuracy: 0.7243 - val_loss: 0.6843\n",
      "Epoch 32/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7106 - loss: 0.7226 - val_accuracy: 0.7284 - val_loss: 0.6823\n",
      "Epoch 33/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7116 - loss: 0.7126 - val_accuracy: 0.7287 - val_loss: 0.6815\n",
      "Epoch 34/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7156 - loss: 0.7082 - val_accuracy: 0.7304 - val_loss: 0.6782\n",
      "Epoch 35/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7135 - loss: 0.7079 - val_accuracy: 0.7336 - val_loss: 0.6741\n",
      "Epoch 36/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7138 - loss: 0.7048 - val_accuracy: 0.7323 - val_loss: 0.6725\n",
      "Epoch 37/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7194 - loss: 0.6978 - val_accuracy: 0.7305 - val_loss: 0.6735\n",
      "Epoch 38/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7221 - loss: 0.6980 - val_accuracy: 0.7332 - val_loss: 0.6712\n",
      "Epoch 39/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7250 - loss: 0.6937 - val_accuracy: 0.7359 - val_loss: 0.6732\n",
      "Epoch 40/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7194 - loss: 0.7012 - val_accuracy: 0.7318 - val_loss: 0.6726\n",
      "Epoch 41/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7200 - loss: 0.6913 - val_accuracy: 0.7307 - val_loss: 0.6703\n",
      "Epoch 42/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7213 - loss: 0.6852 - val_accuracy: 0.7324 - val_loss: 0.6717\n",
      "Epoch 43/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7228 - loss: 0.6837 - val_accuracy: 0.7314 - val_loss: 0.6694\n",
      "Epoch 44/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7243 - loss: 0.6788 - val_accuracy: 0.7308 - val_loss: 0.6684\n",
      "Epoch 45/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7279 - loss: 0.6774 - val_accuracy: 0.7372 - val_loss: 0.6647\n",
      "Epoch 46/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7294 - loss: 0.6716 - val_accuracy: 0.7372 - val_loss: 0.6636\n",
      "Epoch 47/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7256 - loss: 0.6854 - val_accuracy: 0.7349 - val_loss: 0.6665\n",
      "Epoch 48/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7260 - loss: 0.6852 - val_accuracy: 0.7356 - val_loss: 0.6652\n",
      "Epoch 49/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7318 - loss: 0.6657 - val_accuracy: 0.7339 - val_loss: 0.6659\n",
      "Epoch 50/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7369 - loss: 0.6679 - val_accuracy: 0.7366 - val_loss: 0.6640\n",
      "Epoch 51/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7303 - loss: 0.6764 - val_accuracy: 0.7397 - val_loss: 0.6600\n",
      "Epoch 52/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7330 - loss: 0.6711 - val_accuracy: 0.7361 - val_loss: 0.6608\n",
      "Epoch 53/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7408 - loss: 0.6591 - val_accuracy: 0.7382 - val_loss: 0.6585\n",
      "Epoch 54/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7322 - loss: 0.6633 - val_accuracy: 0.7362 - val_loss: 0.6604\n",
      "Epoch 55/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7377 - loss: 0.6591 - val_accuracy: 0.7390 - val_loss: 0.6585\n",
      "Epoch 56/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7369 - loss: 0.6512 - val_accuracy: 0.7382 - val_loss: 0.6564\n",
      "Epoch 57/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7381 - loss: 0.6578 - val_accuracy: 0.7373 - val_loss: 0.6576\n",
      "Epoch 58/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7388 - loss: 0.6573 - val_accuracy: 0.7365 - val_loss: 0.6572\n",
      "Epoch 59/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7402 - loss: 0.6538 - val_accuracy: 0.7357 - val_loss: 0.6564\n",
      "Epoch 60/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7382 - loss: 0.6507 - val_accuracy: 0.7403 - val_loss: 0.6538\n",
      "Epoch 61/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7424 - loss: 0.6404 - val_accuracy: 0.7415 - val_loss: 0.6540\n",
      "Epoch 62/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7428 - loss: 0.6508 - val_accuracy: 0.7386 - val_loss: 0.6545\n",
      "Epoch 63/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7368 - loss: 0.6547 - val_accuracy: 0.7408 - val_loss: 0.6537\n",
      "Epoch 64/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7411 - loss: 0.6497 - val_accuracy: 0.7391 - val_loss: 0.6538\n",
      "Epoch 65/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7457 - loss: 0.6410 - val_accuracy: 0.7405 - val_loss: 0.6536\n",
      "Epoch 66/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7439 - loss: 0.6447 - val_accuracy: 0.7408 - val_loss: 0.6522\n",
      "Epoch 67/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7408 - loss: 0.6511 - val_accuracy: 0.7403 - val_loss: 0.6533\n",
      "Epoch 68/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7456 - loss: 0.6451 - val_accuracy: 0.7411 - val_loss: 0.6497\n",
      "Epoch 69/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7498 - loss: 0.6369 - val_accuracy: 0.7427 - val_loss: 0.6489\n",
      "Epoch 70/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7469 - loss: 0.6317 - val_accuracy: 0.7386 - val_loss: 0.6531\n",
      "Epoch 71/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7496 - loss: 0.6315 - val_accuracy: 0.7423 - val_loss: 0.6482\n",
      "Epoch 72/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7500 - loss: 0.6321 - val_accuracy: 0.7430 - val_loss: 0.6497\n",
      "Epoch 73/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7497 - loss: 0.6389 - val_accuracy: 0.7432 - val_loss: 0.6489\n",
      "Epoch 74/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7504 - loss: 0.6325 - val_accuracy: 0.7445 - val_loss: 0.6478\n",
      "Epoch 75/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7423 - loss: 0.6488 - val_accuracy: 0.7391 - val_loss: 0.6520\n",
      "Epoch 76/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7511 - loss: 0.6284 - val_accuracy: 0.7397 - val_loss: 0.6479\n",
      "Epoch 77/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7480 - loss: 0.6354 - val_accuracy: 0.7398 - val_loss: 0.6489\n",
      "Epoch 78/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7525 - loss: 0.6226 - val_accuracy: 0.7384 - val_loss: 0.6482\n",
      "Epoch 79/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7520 - loss: 0.6241 - val_accuracy: 0.7386 - val_loss: 0.6479\n",
      "Epoch 80/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7531 - loss: 0.6268 - val_accuracy: 0.7403 - val_loss: 0.6487\n",
      "Epoch 81/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7512 - loss: 0.6265 - val_accuracy: 0.7386 - val_loss: 0.6483\n",
      "Epoch 82/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7569 - loss: 0.6195 - val_accuracy: 0.7437 - val_loss: 0.6464\n",
      "Epoch 83/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7563 - loss: 0.6190 - val_accuracy: 0.7429 - val_loss: 0.6438\n",
      "Epoch 84/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7554 - loss: 0.6180 - val_accuracy: 0.7431 - val_loss: 0.6444\n",
      "Epoch 85/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7529 - loss: 0.6189 - val_accuracy: 0.7400 - val_loss: 0.6489\n",
      "Epoch 86/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7554 - loss: 0.6210 - val_accuracy: 0.7425 - val_loss: 0.6443\n",
      "Epoch 87/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7526 - loss: 0.6217 - val_accuracy: 0.7451 - val_loss: 0.6419\n",
      "Epoch 88/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7570 - loss: 0.6150 - val_accuracy: 0.7473 - val_loss: 0.6400\n",
      "Epoch 89/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7549 - loss: 0.6233 - val_accuracy: 0.7458 - val_loss: 0.6429\n",
      "Epoch 90/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7503 - loss: 0.6256 - val_accuracy: 0.7439 - val_loss: 0.6412\n",
      "Epoch 91/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7619 - loss: 0.6109 - val_accuracy: 0.7416 - val_loss: 0.6423\n",
      "Epoch 92/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7550 - loss: 0.6189 - val_accuracy: 0.7429 - val_loss: 0.6439\n",
      "Epoch 93/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7542 - loss: 0.6197 - val_accuracy: 0.7452 - val_loss: 0.6407\n",
      "Epoch 94/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7602 - loss: 0.6064 - val_accuracy: 0.7438 - val_loss: 0.6398\n",
      "Epoch 95/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7570 - loss: 0.6132 - val_accuracy: 0.7406 - val_loss: 0.6426\n",
      "Epoch 96/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7582 - loss: 0.6196 - val_accuracy: 0.7424 - val_loss: 0.6442\n",
      "Epoch 97/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7586 - loss: 0.6143 - val_accuracy: 0.7399 - val_loss: 0.6404\n",
      "Epoch 98/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7631 - loss: 0.6099 - val_accuracy: 0.7397 - val_loss: 0.6427\n",
      "Epoch 99/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7561 - loss: 0.6094 - val_accuracy: 0.7427 - val_loss: 0.6393\n",
      "Epoch 100/100\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7583 - loss: 0.6039 - val_accuracy: 0.7480 - val_loss: 0.6366\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "MLP Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB       0.50      0.61      0.55      1740\n",
      "        GSVT       0.80      0.67      0.73      1868\n",
      "          SB       0.89      0.90      0.90      3100\n",
      "          SR       0.75      0.69      0.72      1809\n",
      "\n",
      "    accuracy                           0.75      8517\n",
      "   macro avg       0.73      0.72      0.72      8517\n",
      "weighted avg       0.76      0.75      0.75      8517\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:59:55.346575Z",
     "start_time": "2024-11-27T05:55:55.806200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardize input shape for CNN\n",
    "X_train_cnn = X_train[..., np.newaxis]\n",
    "X_test_cnn = X_test[..., np.newaxis]\n",
    "\n",
    "# CNN\n",
    "cnn = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(X_train_cnn, y_train, epochs=50, batch_size=64, validation_data=(X_test_cnn, y_test))\n",
    "y_pred_cnn = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_cnn, target_names=label_encoder.classes_))"
   ],
   "id": "3908fd6642b00db0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 13ms/step - accuracy: 0.3443 - loss: 19.2226 - val_accuracy: 0.6377 - val_loss: 0.8850\n",
      "Epoch 2/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.6349 - loss: 0.8731 - val_accuracy: 0.7605 - val_loss: 0.6604\n",
      "Epoch 3/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.7381 - loss: 0.6722 - val_accuracy: 0.7793 - val_loss: 0.5950\n",
      "Epoch 4/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.7777 - loss: 0.5839 - val_accuracy: 0.7890 - val_loss: 0.5737\n",
      "Epoch 5/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.7954 - loss: 0.5235 - val_accuracy: 0.7789 - val_loss: 0.6052\n",
      "Epoch 6/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8141 - loss: 0.4849 - val_accuracy: 0.7903 - val_loss: 0.5989\n",
      "Epoch 7/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8371 - loss: 0.4257 - val_accuracy: 0.7856 - val_loss: 0.6276\n",
      "Epoch 8/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8524 - loss: 0.3898 - val_accuracy: 0.7887 - val_loss: 0.6606\n",
      "Epoch 9/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8728 - loss: 0.3366 - val_accuracy: 0.7808 - val_loss: 0.6588\n",
      "Epoch 10/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8786 - loss: 0.3224 - val_accuracy: 0.7709 - val_loss: 0.8942\n",
      "Epoch 11/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8951 - loss: 0.2834 - val_accuracy: 0.7791 - val_loss: 0.7685\n",
      "Epoch 12/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 10ms/step - accuracy: 0.8946 - loss: 0.2945 - val_accuracy: 0.7791 - val_loss: 0.8280\n",
      "Epoch 13/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.8955 - loss: 0.2847 - val_accuracy: 0.7776 - val_loss: 0.8677\n",
      "Epoch 14/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.9109 - loss: 0.2552 - val_accuracy: 0.7840 - val_loss: 0.8740\n",
      "Epoch 15/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.9148 - loss: 0.2419 - val_accuracy: 0.7850 - val_loss: 0.8911\n",
      "Epoch 16/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.9194 - loss: 0.2326 - val_accuracy: 0.7719 - val_loss: 0.9469\n",
      "Epoch 17/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 13ms/step - accuracy: 0.9248 - loss: 0.2064 - val_accuracy: 0.7837 - val_loss: 1.0307\n",
      "Epoch 18/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.9327 - loss: 0.1862 - val_accuracy: 0.7754 - val_loss: 1.0118\n",
      "Epoch 19/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.9353 - loss: 0.1785 - val_accuracy: 0.7791 - val_loss: 1.0017\n",
      "Epoch 20/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.9398 - loss: 0.1755 - val_accuracy: 0.7683 - val_loss: 1.1951\n",
      "Epoch 21/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.9378 - loss: 0.1669 - val_accuracy: 0.7787 - val_loss: 1.2227\n",
      "Epoch 22/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 11ms/step - accuracy: 0.9423 - loss: 0.1623 - val_accuracy: 0.7840 - val_loss: 1.3390\n",
      "Epoch 23/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 11ms/step - accuracy: 0.9479 - loss: 0.1490 - val_accuracy: 0.7769 - val_loss: 1.2607\n",
      "Epoch 24/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9455 - loss: 0.1560 - val_accuracy: 0.7716 - val_loss: 1.2516\n",
      "Epoch 25/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 9ms/step - accuracy: 0.9511 - loss: 0.1402 - val_accuracy: 0.7682 - val_loss: 1.1835\n",
      "Epoch 26/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9502 - loss: 0.1368 - val_accuracy: 0.7761 - val_loss: 1.3130\n",
      "Epoch 27/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9533 - loss: 0.1315 - val_accuracy: 0.7820 - val_loss: 1.1511\n",
      "Epoch 28/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9492 - loss: 0.1369 - val_accuracy: 0.7729 - val_loss: 1.3461\n",
      "Epoch 29/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9530 - loss: 0.1346 - val_accuracy: 0.7814 - val_loss: 1.3247\n",
      "Epoch 30/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9531 - loss: 0.1385 - val_accuracy: 0.7775 - val_loss: 1.3280\n",
      "Epoch 31/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9583 - loss: 0.1225 - val_accuracy: 0.7799 - val_loss: 1.2826\n",
      "Epoch 32/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9619 - loss: 0.1074 - val_accuracy: 0.7747 - val_loss: 1.3743\n",
      "Epoch 33/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9576 - loss: 0.1198 - val_accuracy: 0.7655 - val_loss: 1.4989\n",
      "Epoch 34/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9640 - loss: 0.1059 - val_accuracy: 0.7783 - val_loss: 1.4030\n",
      "Epoch 35/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9654 - loss: 0.0996 - val_accuracy: 0.7707 - val_loss: 1.5019\n",
      "Epoch 36/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9622 - loss: 0.1122 - val_accuracy: 0.7686 - val_loss: 1.5309\n",
      "Epoch 37/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9658 - loss: 0.1020 - val_accuracy: 0.7828 - val_loss: 1.3920\n",
      "Epoch 38/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9635 - loss: 0.1104 - val_accuracy: 0.7750 - val_loss: 1.5187\n",
      "Epoch 39/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9652 - loss: 0.0976 - val_accuracy: 0.7836 - val_loss: 1.5942\n",
      "Epoch 40/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9639 - loss: 0.1053 - val_accuracy: 0.7665 - val_loss: 1.5028\n",
      "Epoch 41/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9638 - loss: 0.1017 - val_accuracy: 0.7779 - val_loss: 1.5271\n",
      "Epoch 42/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9674 - loss: 0.0915 - val_accuracy: 0.7761 - val_loss: 1.5282\n",
      "Epoch 43/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9644 - loss: 0.1135 - val_accuracy: 0.7768 - val_loss: 1.7388\n",
      "Epoch 44/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9694 - loss: 0.0905 - val_accuracy: 0.7520 - val_loss: 1.7152\n",
      "Epoch 45/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9664 - loss: 0.1037 - val_accuracy: 0.7745 - val_loss: 1.6977\n",
      "Epoch 46/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9713 - loss: 0.0843 - val_accuracy: 0.7737 - val_loss: 1.7071\n",
      "Epoch 47/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9738 - loss: 0.0779 - val_accuracy: 0.7665 - val_loss: 1.7905\n",
      "Epoch 48/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9746 - loss: 0.0787 - val_accuracy: 0.7736 - val_loss: 1.6953\n",
      "Epoch 49/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9712 - loss: 0.0866 - val_accuracy: 0.7747 - val_loss: 1.7130\n",
      "Epoch 50/50\n",
      "\u001B[1m533/533\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9668 - loss: 0.1011 - val_accuracy: 0.7729 - val_loss: 1.7321\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFIB       0.55      0.41      0.47      1740\n",
      "        GSVT       0.78      0.79      0.79      1868\n",
      "          SB       0.88      0.96      0.92      3100\n",
      "          SR       0.73      0.78      0.75      1809\n",
      "\n",
      "    accuracy                           0.77      8517\n",
      "   macro avg       0.73      0.74      0.73      8517\n",
      "weighted avg       0.76      0.77      0.76      8517\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
